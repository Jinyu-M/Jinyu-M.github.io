<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://jinyu-m.github.io</id>
    <title>年少万兜鍪</title>
    <updated>2020-11-28T07:27:18.988Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://jinyu-m.github.io"/>
    <link rel="self" href="https://jinyu-m.github.io/atom.xml"/>
    <subtitle>少年吔
尘世恰好，有诗有酒刚好吐槽</subtitle>
    <logo>https://jinyu-m.github.io/images/avatar.png</logo>
    <icon>https://jinyu-m.github.io/favicon.ico</icon>
    <rights>All rights reserved 2020, 年少万兜鍪</rights>
    <entry>
        <title type="html"><![CDATA[Incremental/Automatic Loop Closure]]></title>
        <id>https://jinyu-m.github.io/post/incrementalautomatic-loop-closure/</id>
        <link href="https://jinyu-m.github.io/post/incrementalautomatic-loop-closure/">
        </link>
        <updated>2020-11-25T01:16:04.000Z</updated>
        <summary type="html"><![CDATA[<p>基于static vocabulary的回环检测在词典训练时很难保证词典中的视觉单词具有普适性，所以在训练完成后，在一些未曾见过的场景中会表现较差，所以增量式的词典构建或者增量式的检索图像很值得关注一下。</p>
]]></summary>
        <content type="html"><![CDATA[<p>基于static vocabulary的回环检测在词典训练时很难保证词典中的视觉单词具有普适性，所以在训练完成后，在一些未曾见过的场景中会表现较差，所以增量式的词典构建或者增量式的检索图像很值得关注一下。</p>
<!-- more -->
<h1 id="fast-and-incremental-loop-closure-detection-with-deep-features-and-proximity-graphs-pdf-code">Fast and Incremental Loop Closure Detection with Deep Features and Proximity Graphs <a href="https://arxiv.org/abs/1911.10752">pdf</a> <a href="https://github.com/AnshanTJU/FILD">code</a></h1>
<h2 id="abstract"><em>Abstract</em></h2>
<p>这篇论文中，作者提出了一个FILD++算法，当相机采集到新的图像，算法通过一个神经网络的两个分支分别得到全局特征和局部特征。接着，一个层次化可导航的small-world graph增量式的利用全局特征构建了一个视觉数据库，来表示机器人的移动轨迹。给定检索的传感器数据，可以通过这些表征来检索轨迹中相同地点，并且得益于局部特征提供的空间信息，图像到图像的匹配也可以进一步得到。</p>
<h2 id="introduction"><em>Introduction</em></h2>
<p>这篇论文中，作者着手于建立一个增量式的数据库（地图），来利用视觉信息实现快速、scalable回环检测。算法利用一个神经网络提取图像的deep features，在机器人移动过程中，一个modified hierarchical navigable small world (HNSW) graph被构建。因此，可以采用一种更快的最近邻搜索来减少计算检索的消耗。</p>
<h2 id="image-representation"><em>Image Representation</em></h2>
<p><img src="https://jinyu-m.github.io/post-images/1606269122126.png" alt="" loading="lazy"><br>
作者设计的特征提取网络包括两个部分，当图像输入后，将其缩放为两个不同的尺寸，第一个尺寸的图像通过backbone (ResNet-50)后，得到的特征图经global average pooling得到全局描述子；第二个尺寸的图像通过backbone后，得到的特征图，经过一个attention机制的筛选，得到合适的局部特征，经过特征降维，得到最后的局部特征。</p>
<h3 id="global-features">Global Features</h3>
<p>全局特征通过Global Average Pooling得到，将<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>w</mi><mo>×</mo><mi>h</mi><mo>×</mo><mi>c</mi></mrow><annotation encoding="application/x-tex">w \times h \times c</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.66666em;vertical-align:-0.08333em;"></span><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.77777em;vertical-align:-0.08333em;"></span><span class="mord mathdefault">h</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault">c</span></span></span></span>的特征图pooling为<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>1</mn><mo>×</mo><mn>1</mn><mo>×</mo><mi>c</mi></mrow><annotation encoding="application/x-tex">1 \times 1 \times c</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault">c</span></span></span></span>的全局描述子。</p>
<h3 id="attention-based-local-features">Attention-based Local Features</h3>
<p>attention层由两层1x1卷积构成，目的为学习每个局部特征的分数。具有高于阈值<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>δ</mi></mrow><annotation encoding="application/x-tex">\delta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.03785em;">δ</span></span></span></span>的分数的局部特征被挑选出来，来避免无用特征的干扰。在第二层中，使用softplus激活函数来保证分数非负。最后，得到一个<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>w</mi><mo>×</mo><mi>h</mi><mo>×</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">w \times h \times 1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.66666em;vertical-align:-0.08333em;"></span><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.77777em;vertical-align:-0.08333em;"></span><span class="mord mathdefault">h</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span>的score map。</p>
<h3 id="local-features-dimensionality-reduction">Local Features' Dimensionality Reduction</h3>
<p>为了缩小特征空间，作者对得到的局部特征进行L2-normalization后，使用PCA进行降维，产生的40维特征再次用L2-normalization处理。</p>
<h3 id="features-scales">Features' Scales</h3>
<p>为了获得有代表性的特征，作者选择在提取阶段使用不同尺寸的图像，为了减少图像金字塔消耗的时间，需要作者只选择了两个尺寸的图像，第一个用于生成全局描述子，第二个用于提取局部特征。</p>
<h2 id="hierarchical-navigable-small-world-graph-database"><em>Hierarchical Navigable Small World Graph Database</em></h2>
<h3 id="hierarchical-navigable-small-world">Hierarchical Navigable Small World</h3>
<p><img src="https://jinyu-m.github.io/post-images/1606271629868.png" alt="" loading="lazy"><br>
一个图<strong>G=(V,E)<strong>由一组节点</strong>V</strong>和一组连接他们的边<strong>E</strong>组成。HNSW来源于NSW，基于增量式的k-NN结构来构建一个图。在这篇论文中，节点由全局描述子表示，边用于连接节点。节点的邻域定义为与该节点直接相连的点的集合，节点的度表示了这个集合的大小。首选的检索策略是先对其父节点进行选择，这样可以避免其他邻近图的主要缺点，并且在面对低维聚类数据时也可以解决表现退化的问题。在NSW方案中，在单次贪婪搜索中跳步的数量和节点的度都呈多重对数变化。另一方面，作者提出的算法为了选择特定节点、分开不同尺度的连接和利用一种启发式的方法选择邻近点，而使用了不同的策略。根据不同层中连接的长度，可以获得一个鲁棒的划分，然后，在一个允许对数级可伸缩的层次化多层图中，搜索过程可以实现。</p>
<h3 id="database-construction-and-exploration">Database Construction and Exploration</h3>
<p>与基于BoW模型的方法不同（基于BoW的方法需要离线训练视觉词典），本文提出的算法在机器人探索过程中构建它的数据库，不需要事先获得先验数据。对于每个插入的元素q，根据一个指数衰减的概率分布随机选择整数最大层l。从高到低遍历图，每一层的ef个最近邻点被视为下一层的进入点。继续这一过程，直到插入元素的M个连接达到底层。归一化的乘积（向量间的cosine距离）被选作对应全局描述子间的距离度量。<br>
<img src="https://jinyu-m.github.io/post-images/1606273183336.png" alt="" loading="lazy"><br>
为了构建一个低计算消耗的系统，作者使用了<a href="https://software.intel.com/en-us/articles/introduction-to-intel-advanced-vector-extensions/">Advanced Vector Extensions</a>指令来加速算法过程。</p>
<h2 id="detection-pipeline"><em>Detection Pipeline</em></h2>
<h3 id="system-overall">System Overall</h3>
<p>在本算法中，全局描述子用于HNSW图构建和检索，局部特征用于几何验证。算法采用时序一致性来防止false positive的情况。算法伪代码如下：<br>
<img src="https://jinyu-m.github.io/post-images/1606273548877.png" alt="" loading="lazy"></p>
<h3 id="non-search-area-definition">Non-Search Area Definition</h3>
<p>由于相邻图像一定具有很高的相似性，所以作者设计了一个FIFO队列来存储全局描述子。全局描述子先存入队列，直到机器人离开non-search区域，描述子才会用于插入HNSW图中。这一区域由时间常数<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>ψ</mi></mrow><annotation encoding="application/x-tex">\psi</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">ψ</span></span></span></span>,相机帧率<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>ϕ</mi></mrow><annotation encoding="application/x-tex">\phi</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathdefault">ϕ</span></span></span></span>定义。因此，对于当前图像，算法只搜索<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>N</mi><mo>−</mo><mi>ψ</mi><mo>×</mo><mi>ϕ</mi></mrow><annotation encoding="application/x-tex">N-\psi \times \phi</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.76666em;vertical-align:-0.08333em;"></span><span class="mord mathdefault" style="margin-right:0.10903em;">N</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">ψ</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathdefault">ϕ</span></span></span></span>区域中的图像。其中N是直到当前时刻的所有图像数据。</p>
<h3 id="image-matching">Image Matching</h3>
<p>在检索过程中，进行如前文所述的搜索过程，主要区别在于底层获得的最近邻将返回作为结果。搜索的质量由ef控制。作者使用暴力匹配法进行局部特征匹配，因为特征描述子维度很低。算法还加入了distance raio test来检查匹配，阈值为<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>ε</mi></mrow><annotation encoding="application/x-tex">\varepsilon</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault">ε</span></span></span></span>.</p>
<h3 id="geometrical-verification">Geometrical Verification</h3>
<p>算法加入了几何一致性的验证，用RANSAC计算匹配图像的F矩阵，如果计算成功，则用最高的内点数量来作为分数。</p>
<h3 id="temporal-consistency-check">Temporal Consistency Check</h3>
<p>最后，算法加入时间一致性检验来保证检测的正确性，当连续<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>β</mi></mrow><annotation encoding="application/x-tex">\beta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.05278em;">β</span></span></span></span>帧是回环，验证通过。这样虽然会丢失回环序列中的前几个回环，但是作者更希望保证算法的准确性（回环检测对准确性要求更高）。</p>
<h2 id="performance"><em>Performance</em></h2>
<p><img src="https://jinyu-m.github.io/post-images/1606275615688.png" alt="" loading="lazy"><br>
<img src="https://jinyu-m.github.io/post-images/1606275618541.png" alt="" loading="lazy"></p>
<hr>
<h1 id="ibow-lcd-an-appearance-based-loop-closure-detection-approach-using-incremental-bags-of-binary-words-pdf-code">iBoW-LCD: An Appearance-based Loop Closure Detection Approach using incremental Bags of Binary Words <a href="https://arxiv.org/abs/1802.05909v2">pdf</a> <a href="https://github.com/emiliofidalgo/ibow-lcd">code</a></h1>
<h2 id="abstract-2"><em>Abstract</em></h2>
<p>这篇论文提出了iBoW-LCD算法，使用一个基于二进制描述子的增量式的BoW方法来检测回环，不需要传统BoW模型的离线训练阶段。除此之外，该算法建立在dynamic islands这一概念上，这是一个简单但有效的将时间上相邻的相似图像聚成一组的方法，可以减少Bayesian框架的计算时间。</p>
<h2 id="introduction-2"><em>Introduction</em></h2>
<p>这篇论文，作者提出了一个有效的appearance-based回环检测算法，称为iBoW-LCD （Incremental Bag-of-Words Loop Closure Detection)，该算法使用增量式的二进制词典，可以在线构建视觉词典，避免了离线训练的各种弊端。这一方法，与inverted index结构结合，可以很有效的检索到回环图像。接着，一个鲁棒回环检测方法被提出。它拓展并加强了island的概念，来防止将相邻图像检索为回环候选。<br>
关于BoW模型，之前的一些工作只添加视觉单词，而没有遗忘（删除）无用的视觉单词，在这篇工作中，优化的词典不光添加单词，在单词被认为无用时也删除单词。实验证明，这样的处理可以用更少的词典达到相似的表现。关于回环检测，作者之前的工作是基于贝叶斯滤波的，但是随着图像数量的增多，处理时间会不断增加。所以这篇工作中，作者用一个简单但有效的基于dynamic island概念的机制来代替滤波器，可以用更少的时间来实现相似的表现。这篇论文提出的算法没有使用FLANN算法。</p>
<h2 id="incremental-bow-for-image-indexing"><strong>Incremental BoW for Image Indexing</strong></h2>
<h3 id="overview-of-mujas-approach">Overview of Muja's Approach</h3>
<p>作者参考了Muja and Lowe提出的方法，该方法引入一种高效的层次化结构来检索和匹配二进制特征，需要很少的内存空间并且比一般的hashing方法scale better。这一结构由一个树构成，非叶节点包含着聚类中心，叶节点存储着要匹配的视觉描述子。也就是增量式词典树的视觉单词被储存在叶节点中。<br>
在构建过程中，算法先随机从初始点集中挑选K个描述子作为聚类中心。然后，余下的每个输入描述子根据hamming距离被分配到最近的聚类中心上。这一过程递归的重复进行，直到一个聚类中的描述子数量小于阈值S。Muja et al.也提出构建多个树T，在搜索过程中并行的使用它们会带来更好的效果。<br>
<img src="https://jinyu-m.github.io/post-images/1606290151915.png" alt="" loading="lazy"><br>
为了并行的利用这些树来搜索描述子，算法对于每个树，从根节点到叶节点遍历树，每步中挑选与检索描述子最相近的节点，并把未被探索过的节点加入一个优先级队列中。当达到叶节点时，该节点中的所有点被线性搜索。当每个树被搜索过一次后，从优先级队列中最近的节点开始继续搜索。直到一定数量的描述子被检查过（在本文中，设为64），这一过程结束。</p>
<h3 id="visual-vocabulary-update">Visual Vocabulary Update</h3>
<p>Muja的方法最初是设计用于检索一个静态的描述子集合。在本文的方法中，作者需要处理一个增量式的视觉词典，所以作者引入了需要改进。首先，在探索过程中，二进制描述子被匹配和合并，以一种合并的政策来更新词典的视觉单词。作者用bitwise AND operation来实现合并：<br>
<img src="https://jinyu-m.github.io/post-images/1606290905303.png" alt="" loading="lazy"><br>
这一策略被实验证明不会导致描述子退化（几乎所有位都变为0）。<br>
其次，在检索过程中没有匹配的描述子将被包含入词典中，作为一个新的视觉单词。为此，每个描述子从根节点到叶节点被搜索。接着，评估将对应的新描述子加入被选定的节点中是否会超过最大叶尺寸S。如果是，则将该描述子加入最初的描述子，递归的重建这个节点。否则，直接将这个描述子加入该节点。<br>
<img src="https://jinyu-m.github.io/post-images/1606291269472.png" alt="" loading="lazy"><br>
然后，算法保留了一个inverted index结构，对于每个视觉单词，它储存了该单词出现过的图像。最初，视觉词典通过把第一幅图像的二进制描述子作为视觉单词的集合来完成构建。当一幅图像输入，它的描述子与检索的视觉单词利用ratio test进行匹配。匹配到的描述子合并到对应视觉单词上。未匹配的描述子被临时当做新的视觉单词加入词典。为了减少检索的复杂度，这些临时的视觉单词只有在连续<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>P</mi><mi>f</mi></msub></mrow><annotation encoding="application/x-tex">P_f</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.969438em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.10764em;">f</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span>帧被匹配到至少<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>P</mi><mi>o</mi></msub></mrow><annotation encoding="application/x-tex">P_o</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">o</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>次，才会保留下来。inverted index相应地更新。这一策略的主要目的在于，挑选那些当机器人达到回环位置时更有可能被观察到的视觉单词。<br>
最后，作者用一种删除视觉单词的机制来保证词典支持上述的更新策略。当从词典中删除一个描述子后，它所加入的节点和其父节点都将被递归地修改来评估它们是否包含子节点。一个没有子节点的节点将不再需要，因此要删除。如果要删除的描述最与聚类中心一致，则重新选择一个新的中心。<br>
<img src="https://jinyu-m.github.io/post-images/1606292138825.png" alt="" loading="lazy"></p>
<h3 id="retrieval-of-similar-images">Retrieval of Similar Images</h3>
<p>inverted index结构可以让搜索范围缩小为与当前图像具有共同视觉单词的历史图像。对于k个之前见过的帧，初始化其相似分数<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>s</mi><mo>(</mo><msub><mi>I</mi><mi>t</mi></msub><mo separator="true">,</mo><msub><mi>I</mi><mi>k</mi></msub><mo>)</mo></mrow><annotation encoding="application/x-tex">s(I_t, I_k)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault">s</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07847em;">I</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07847em;">I</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>为0。令<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>z</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">z_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.04398em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>为从当前图像<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>I</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">I_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07847em;">I</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>中提取出的二进制描述子集合，我们在词典中对于<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>z</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">z_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.04398em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>中每个描述子搜索其最靠近的视觉单词，然后我们根据inverted index来获得具有共同视觉单词的历史图像，并且对于每个检索到的图像的相似度加一个权重。该权重用tf-idf权重来度量视觉单词在词典树和当前图像中的重要性。当处理完所有<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>z</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">z_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.04398em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>中的描述子，可以获得一个对于当前图像<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>I</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">I_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07847em;">I</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>的最相似的图像及其对应相似分数的列表。图像检索的开源代码在<a href="http://github.com/emiliofidalgo/obindex">OBIndex2</a></p>
<h2 id="loop-closure-detection"><strong>Loop Closure Detection</strong></h2>
<h3 id="searching-for-previous-images">Searching for Previous Images</h3>
<p>当在t时刻输入一张图像<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>I</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">I_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07847em;">I</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>，开始检索相似图像。利用一个缓存器来储存最近p张图像，因此防止它们被检索成为回环候选。搜索的结果可以用一个列表来表示，有j个最相似的图像，记为<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>C</mi><mi>t</mi></msub><mo>=</mo><mrow><msub><mi>I</mi><msub><mi>s</mi><mn>1</mn></msub></msub><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo separator="true">,</mo><msub><mi>I</mi><msub><mi>s</mi><mi>j</mi></msub></msub></mrow></mrow><annotation encoding="application/x-tex">C_t={I_{s_1}, ..., I_{s_j}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.07153em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.03065em;vertical-align:-0.34731999999999996em;"></span><span class="mord"><span class="mord"><span class="mord mathdefault" style="margin-right:0.07847em;">I</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139199999999997em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathdefault mtight">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31731428571428577em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2501em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07847em;">I</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathdefault mtight">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3280857142857143em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2818857142857143em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.34731999999999996em;"><span></span></span></span></span></span></span></span></span></span></span>，利用它们的相似分数来排序。相似分数的范围很大程度上决定于视觉单词的分布，在相邻图像与相似图像间变化很大，因此对于相似分数利用min-max策略进行归一化：<br>
<img src="https://jinyu-m.github.io/post-images/1606356566574.png" alt="" loading="lazy"><br>
其中<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>s</mi><mo>(</mo><msub><mi>I</mi><mi>t</mi></msub><mo separator="true">,</mo><msub><mi>I</mi><msub><mi>s</mi><mn>1</mn></msub></msub><mo separator="true">,</mo><mi>s</mi><mo>(</mo><msub><mi>I</mi><mi>t</mi></msub><mo separator="true">,</mo><msub><mi>I</mi><msub><mi>s</mi><mi>j</mi></msub></msub><mo>)</mo></mrow><annotation encoding="application/x-tex">s(I_t, I_{s_1}, s(I_t, I_{s_j})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0973199999999999em;vertical-align:-0.34731999999999996em;"></span><span class="mord mathdefault">s</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07847em;">I</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07847em;">I</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139199999999997em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathdefault mtight">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31731428571428577em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2501em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">s</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07847em;">I</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07847em;">I</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathdefault mtight">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3280857142857143em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2818857142857143em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.34731999999999996em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>是对应的最小和最大的相似分数。这一过程可以让相似分数归一化到[0,1]之间。接着，作者丢弃了一些相似分数小于预设阈值<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>τ</mi><mrow><mi>i</mi><mi>m</mi></mrow></msub></mrow><annotation encoding="application/x-tex">\tau_{im}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.1132em;">τ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.1132em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mord mathdefault mtight">m</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>的图像，产生一个最终的有序匹配图像列表<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mover accent="true"><mi>C</mi><mo>~</mo></mover><mi>t</mi></msub><mo>⊂</mo><msub><mi>C</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">\tilde{C}_{t} \subset {C}_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0701899999999998em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9201899999999998em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07153em;">C</span></span></span><span style="top:-3.6023300000000003em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.16666em;">~</span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">⊂</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord"><span class="mord mathdefault" style="margin-right:0.07153em;">C</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>.</p>
<h3 id="dynamic-islands-computation">Dynamic Islands Computation</h3>
<p>iBoW-LCD算法使用dynamic island的概念，来局部适应图像组的尺寸。这一改进与原本island的区别在于两方面：1.iBoW-LCD不是使用全部过去的图像来计算island，而是根据前一步获得的相似图像集合<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mover accent="true"><mi>C</mi><mo>~</mo></mover><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">\tilde{C}_{t}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0701899999999998em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9201899999999998em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07153em;">C</span></span></span><span style="top:-3.6023300000000003em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.16666em;">~</span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>；2.island的尺寸不是固定的，而是根据相邻图像的相似度和相机移动速度来决定的，可以根据图像流来调整islands。<br>
<img src="https://jinyu-m.github.io/post-images/1606358470060.png" alt="" loading="lazy"><br>
这篇工作中，一个island被定义为一组时间戳在两个时刻间的相似图像，这一准则可以使得算法将时间上接近的图像聚成一组，避免被检索为回环候选。记<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msubsup><mi mathvariant="normal">Υ</mi><mi>n</mi><mi>m</mi></msubsup></mrow><annotation encoding="application/x-tex">{\Upsilon}^{m}_{n}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.93033em;vertical-align:-0.247em;"></span><span class="mord"><span class="mord"><span class="mord">Υ</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.664392em;"><span style="top:-2.4530000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">n</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">m</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span></span></span></span>为一个包含时间戳在m和n之间图像的island。另外，每个island中挑选一个具有最高相似分数的图像作为代表性图像。为了管理islands，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mover accent="true"><mi>C</mi><mo>~</mo></mover><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">\tilde{C}_{t}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0701899999999998em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9201899999999998em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07153em;">C</span></span></span><span style="top:-3.6023300000000003em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.16666em;">~</span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>中的图像被如下处理：对于每张图像<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>I</mi><mi>c</mi></msub><mo>∈</mo><msub><mover accent="true"><mi>C</mi><mo>~</mo></mover><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">I_c \in \tilde{C}_{t}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07847em;">I</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">c</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.0701899999999998em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9201899999999998em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07153em;">C</span></span></span><span style="top:-3.6023300000000003em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.16666em;">~</span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>，评估他们的时间戳是否在已经存在的island所包含的范围内，如果是，则将该图像加入这个island，并且这一island的时间间隔也随之更新来包含<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>I</mi><mi>c</mi></msub></mrow><annotation encoding="application/x-tex">I_c</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07847em;">I</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">c</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>和<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>I</mi><mi>c</mi></msub></mrow><annotation encoding="application/x-tex">I_c</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07847em;">I</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">c</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>前后b张图像；如果不是，则建立一个新的island，并且将island的时间间隔初始化为c时刻周围的2b+1个时刻（前后b个时刻），将<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>I</mi><mi>c</mi></msub></mrow><annotation encoding="application/x-tex">I_c</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07847em;">I</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">c</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>加入新的island。当处理完左右<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mover accent="true"><mi>C</mi><mo>~</mo></mover><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">\tilde{C}_{t}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0701899999999998em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9201899999999998em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07153em;">C</span></span></span><span style="top:-3.6023300000000003em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.16666em;">~</span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>中的图像，产生的island被修改和缩短，如果有必要，让island之间相互不想交，避免有重叠部分。对于每个island，计算一个全局的分数，得到island的匹配列表<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi mathvariant="normal">Γ</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">{\Gamma}_{t}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord"><span class="mord">Γ</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>：<br>
<img src="https://jinyu-m.github.io/post-images/1606358504898.png" alt="" loading="lazy"><br>
构建dynamic island的伪代码如下：<br>
<img src="https://jinyu-m.github.io/post-images/1606358592315.png" alt="" loading="lazy"></p>
<h3 id="island-selection">Island Selection</h3>
<p>在这一步，iBoW-LCD挑选最佳匹配island，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi mathvariant="normal">Υ</mi><mo>∗</mo></msup><mo>(</mo><mi>t</mi><mo>)</mo><mo>∈</mo><msub><mi mathvariant="normal">Γ</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">{\Upsilon}^{*}(t) \in {\Gamma}_{t}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord"><span class="mord">Υ</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.688696em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">∗</span></span></span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathdefault">t</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord"><span class="mord">Γ</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>。为此，算法回想起前一时刻t-1的最佳island <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi mathvariant="normal">Υ</mi><mo>∗</mo></msup><mo>(</mo><mi>t</mi><mo>−</mo><mn>1</mn><mo>)</mo></mrow><annotation encoding="application/x-tex">{\Upsilon}^*(t-1)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord"><span class="mord">Υ</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.688696em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathdefault">t</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">1</span><span class="mclose">)</span></span></span></span>，并且检查是否有<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msubsup><mi mathvariant="normal">Υ</mi><mi>n</mi><mi>m</mi></msubsup><mo>∈</mo><msub><mi mathvariant="normal">Γ</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">{\Upsilon}^{m}_{n} \in {\Gamma}_{t}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.93033em;vertical-align:-0.247em;"></span><span class="mord"><span class="mord"><span class="mord">Υ</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.664392em;"><span style="top:-2.4530000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">n</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">m</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord"><span class="mord">Γ</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>与<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi mathvariant="normal">Υ</mi><mo>∗</mo></msup><mo>(</mo><mi>t</mi><mo>−</mo><mn>1</mn><mo>)</mo></mrow><annotation encoding="application/x-tex">{\Upsilon}^*(t-1)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord"><span class="mord">Υ</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.688696em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathdefault">t</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">1</span><span class="mclose">)</span></span></span></span>重叠。重叠的island被命名为priority islands，这一想法是受“连续图像应当匹配到与之前图像相匹配的island”这一思路的启发。如果priority islands被找到，具有最大全局分数G的被挑选出来，为了下一步处理。否则，算法直接挑选与当前图像最相似的island，也就是<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi mathvariant="normal">Γ</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">{\Gamma}_{t}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord"><span class="mord">Γ</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>中第一个island。</p>
<h3 id="loop-closure-decision">Loop Closure Decision</h3>
<p>在这一步中，算法首先挑选island中的代表图像来作为最终的回环候选<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>I</mi><mi>f</mi></msub></mrow><annotation encoding="application/x-tex">I_f</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.969438em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07847em;">I</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.10764em;">f</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span>。用极线分析来验证<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>I</mi><mi>f</mi></msub></mrow><annotation encoding="application/x-tex">I_f</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.969438em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07847em;">I</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.10764em;">f</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span>和当前图像<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>I</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">I_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07847em;">I</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>是否是同一场景经过相机转动和平移得到的。为此，作者先用ratio test得到一系列假定的匹配，然后用RANSAC来计算F矩阵，如果内点足够多（F矩阵有意义）则认为这一回环候选是正确的。<br>
这样的集合验证可以提高准确性，但是对每幅图像进行一次检验，势必消耗大量时间。所以，iBoW-LCD采用了一个时间上一致性的特性来避免计算消耗。算法记录着在t时刻，连续的回环数量，当priority island存在并且t时刻的连续回环数量大于阈值<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>τ</mi><mi>c</mi></msub></mrow><annotation encoding="application/x-tex">{\tau}_{c}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord"><span class="mord mathdefault" style="margin-right:0.1132em;">τ</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">c</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>，则接受这一回环，不需要计算F矩阵。</p>
<h2 id="experimental-results"><em>Experimental Results</em></h2>
<p><img src="https://jinyu-m.github.io/post-images/1606548242057.png" alt="" loading="lazy"><br>
<img src="https://jinyu-m.github.io/post-images/1606548266958.png" alt="" loading="lazy"><br>
<img src="https://jinyu-m.github.io/post-images/1606548388825.png" alt="" loading="lazy"></p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Deep Loop Closure]]></title>
        <id>https://jinyu-m.github.io/post/deep-loop-closure/</id>
        <link href="https://jinyu-m.github.io/post/deep-loop-closure/">
        </link>
        <updated>2020-11-07T02:55:58.000Z</updated>
        <summary type="html"><![CDATA[<p>利用深度学习来做回环检测的工作越来越多了，我自己也在做这方面的研究，自己的感受是用deep feature代替传统的hand-crafted feature一般来说会带来更好的表现。但是，要做研究嘛，还是要从更深入的角度的去研究的。其实用语义也是一种deep feature嘛，这里就记录一些除语义之外的基于deep learning的回环检测工作吧。</p>
]]></summary>
        <content type="html"><![CDATA[<p>利用深度学习来做回环检测的工作越来越多了，我自己也在做这方面的研究，自己的感受是用deep feature代替传统的hand-crafted feature一般来说会带来更好的表现。但是，要做研究嘛，还是要从更深入的角度的去研究的。其实用语义也是一种deep feature嘛，这里就记录一些除语义之外的基于deep learning的回环检测工作吧。</p>
<!-- more -->
<h1 id="calc-pdf-code">CALC <a href="https://arxiv.org/abs/1805.07703.pdf">pdf</a> <a href="https://github.com/rpng/calc">code</a></h1>
<h2 id="abstract"><em>Abstract</em></h2>
<p>这篇论文提出了一种无监督的神经网络，采用autoencoder的结构，但是重建的不是原始图像，而是图像的HoG描述子。</p>
<h2 id="method"><em>Method</em></h2>
<p>这篇论文作者设计了一个可以将高维的原始图像信息映射到低维特征空间的网络，对场景变化不敏感，训练方法不需要标注图像。</p>
<p>训练pipeline如下：</p>
<figure data-type="image" tabindex="1"><img src="https://jinyu-m.github.io/post-images/1604717994028.png" alt="" loading="lazy"></figure>
<p>训练集中的每张图像被缩小到120x160，灰度图。通过projective transformations获得匹配图像。</p>
<p>HOG特征对网络提供了一个先验的几何约束，网络可以获得光照不变性，通过projective transformations来获得HOG所不具备的视角不变性。</p>
<p>获得训练的方法-projective transformations过程如下：</p>
<figure data-type="image" tabindex="2"><img src="https://jinyu-m.github.io/post-images/1604717999779.png" alt="" loading="lazy"></figure>
<p>这个过程的目的是：根据一张真实图像I，通过随机的2D projective transformation获得一系列描述同场景、但视角不同的图像。</p>
<p>对于每张图像，从其四角的某一区域内各随机选一个点，作为生成图像的四个角点，获得四个点后，就可以获得从原图到生成图像的homograph，矫正之后就生成了新图像。</p>
<figure data-type="image" tabindex="3"><img src="https://jinyu-m.github.io/post-images/1604718004230.png" alt="" loading="lazy"></figure>
<h2 id="performance"><em>Performance</em></h2>
<p><img src="https://jinyu-m.github.io/post-images/1604718152085.png" alt="" loading="lazy"><br>
<img src="https://jinyu-m.github.io/post-images/1604718157400.png" alt="" loading="lazy"><br>
<img src="https://jinyu-m.github.io/post-images/1604718161861.png" alt="" loading="lazy"><br>
<img src="https://jinyu-m.github.io/post-images/1604718165648.png" alt="" loading="lazy"></p>
<h2 id="一点看法">一点看法</h2>
<p>这篇工作虽然说是无监督，但是其实用了HoG描述子去监督训练网络，算是自己制作了伪真值去训练网络，最后得到的网络效果超过了HoG，证明了数据集如果够丰富，神经网络的泛化能力还是很强的。有点像MagicPoint和SuperPoint的detector，虽然最初的annotated label是人工设置的角点，但是最后训练得到的网络却具备更泛化的能力。论文中projective transformation用于拓展数据集，让网络学习（小）视角不变性，简单有效，值得参考。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[A Comprehensive Comparison of VPR under Changing Conditions]]></title>
        <id>https://jinyu-m.github.io/post/a-comprehensive-comparison-of-vpr-under-changing-conditions/</id>
        <link href="https://jinyu-m.github.io/post/a-comprehensive-comparison-of-vpr-under-changing-conditions/">
        </link>
        <updated>2020-11-05T08:33:45.000Z</updated>
        <summary type="html"><![CDATA[<p>Zaffar, Mubariz and Khaliq, Ahmad and Ehsan, Shoaib and Milford, Michael and McDonald-Maier, Klaus. <em>Levelling the Playing Field: A Comprehensive Comparison of Visual Place Recognition Approaches under Changing Conditions</em>. ICRA 2019 Workshop on Database Generation and Benchmarking of SLAM Algorithms for Robotics and VR/AR</p>
]]></summary>
        <content type="html"><![CDATA[<p>Zaffar, Mubariz and Khaliq, Ahmad and Ehsan, Shoaib and Milford, Michael and McDonald-Maier, Klaus. <em>Levelling the Playing Field: A Comprehensive Comparison of Visual Place Recognition Approaches under Changing Conditions</em>. ICRA 2019 Workshop on Database Generation and Benchmarking of SLAM Algorithms for Robotics and VR/AR</p>
<!-- more -->
<h2 id="introduction">introduction</h2>
<p>本文是对一些VPR算法的比较。作者提出VPR的四个难点：<strong>Seasonal Variation, Viewpoint Variation, Illumination Variation, Dynamic Objects</strong>。在这篇文献中，作者从Matching Performance, Matching Time, Memory Footprint三个角度分析了10种算法。</p>
<h2 id="evaluation-datasets">Evaluation Datasets</h2>
<p>作者使用了Berilin Kudamm Dataset, Gardens Point Dataset, Nordland Dataset作为评测的数据集。<br>
<img src="https://jinyu-m.github.io/post-images/1604565916808.png" alt="" loading="lazy"><br>
<img src="https://jinyu-m.github.io/post-images/1604565943321.png" alt="" loading="lazy"><br>
<img src="https://jinyu-m.github.io/post-images/1604565945569.png" alt="" loading="lazy"><br>
<img src="https://jinyu-m.github.io/post-images/1604565947793.png" alt="" loading="lazy"></p>
<h2 id="evaluation-metrics">Evaluation Metrics</h2>
<p>作者使用AUC来评估算法的matching performance：<br>
<img src="https://jinyu-m.github.io/post-images/1604566016251.png" alt="" loading="lazy"></p>
<p>作者记录了每个算法对每张query image匹配所需的时间，包括query image的feature encoding time和利用描述子匹配R张reference image的时间。</p>
<p>作者还第一次将每个算法特征描述子所需的储存空间进行了比较。</p>
<h2 id="performance">Performance</h2>
<p><img src="https://jinyu-m.github.io/post-images/1604566230544.png" alt="" loading="lazy"><br>
在Berilin Kudamm Dataset上NetVLAD表现最好。在Gardens Point Dataset上，Cross-Region-BoW获得最佳表现，NetVLAD、HybridNet和AMOSNet也获得了相似的不错表现。在Nordland数据集上，Region-VLAD、NetVLAD和Cross-Region-BoW表现较好。<br>
<img src="https://jinyu-m.github.io/post-images/1604566387518.png" alt="" loading="lazy"><br>
<img src="https://jinyu-m.github.io/post-images/1604566402408.png" alt="" loading="lazy"><br>
<img src="https://jinyu-m.github.io/post-images/1604566416379.png" alt="" loading="lazy"></p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Semantic Localization]]></title>
        <id>https://jinyu-m.github.io/post/semantic-localization/</id>
        <link href="https://jinyu-m.github.io/post/semantic-localization/">
        </link>
        <updated>2020-11-05T02:56:52.000Z</updated>
        <summary type="html"><![CDATA[<p>一直觉得语义和图的结合可以解决localization在剧烈视角变化（cross-view，甚至opposite-view）和外观变化下表现不好的问题，有兴趣做下这方面研究，所以最近准备看一些这方面的文献。</p>
]]></summary>
        <content type="html"><![CDATA[<p>一直觉得语义和图的结合可以解决localization在剧烈视角变化（cross-view，甚至opposite-view）和外观变化下表现不好的问题，有兴趣做下这方面研究，所以最近准备看一些这方面的文献。</p>
<!-- more -->
<h1 id="improving-condition-and-enviroment-invariant-pr-with-semantic-place-categorization-iros2017-pdf">Improving Condition- and Enviroment- Invariant PR with Semantic Place Categorization -IROS2017 <a href="https://arxiv.org/abs/1706.07144">pdf</a></h1>
<h2 id="abstract"><em>Abstract</em></h2>
<p>论文提出place recognition可以分为两个子问题：特定场景识别和场景分类。这篇论文的创新点在于&quot;use place context to inform place recognition&quot;，即把两个子问题结合起来，相互补充。场景识别得到的语义信息，可以帮助PR提升在昼夜、光照、室内外变化时的表现。</p>
<h2 id="introduction"><em>Introduction</em></h2>
<p>在这篇论文中，作者分析了环境中局部条件变化对于具有全局条件不变的PR算法的影响。并提出一个可以解决这种在一次探索过程或不同探索过程中，出现条件变化情况的方法。这种方法结合了语义标签和场景分类结果，通过将场景分割来改进场景识别。一旦一个场景被分类，作者将使用SeqSLAM进行场景识别，并使用一种动态的加权策略，来控制场景匹配到具有相似场景特性的、或具有相似场景分类的场景。结果证明，不论baseline的表现如何，论文所提出的几何场景分类信息的方法都可以提升算法表现。</p>
<h2 id="method"><em>Method</em></h2>
<p>作者利用VGG16-Places365获得图像的语义标签，将物理位置划分为不同的区域。这些分割后的区域被用于PR来控制场景在特定语义区域内匹配。</p>
<h3 id="place-categorization">Place Categorization</h3>
<p>作者用CNN预测了reference database中每张图像的分类概率，称为场景属性（共102类）。</p>
<h3 id="physical-space-segmentation">Physical Space Segmentation</h3>
<p>利用语义标签去分割区域需要唯一的标签，而非场景属性。为了避免瞬时的预测错误，考虑到输入图像的时间连续性，作者引入了HMM模型，根据语义标签的分类概率，预测每张图像对应的模型参数和隐藏状态。</p>
<p>假设一段序列有T张图像，则该序列的语义标签为<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>X</mi><mo>=</mo><mo>(</mo><msub><mi>x</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>x</mi><mn>2</mn></msub><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo separator="true">,</mo><msub><mi>x</mi><mi>T</mi></msub><mo>)</mo></mrow><annotation encoding="application/x-tex">X=(x_1,x_2,...,x_T)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.07847em;">X</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">T</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>，隐藏变量记为<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>Z</mi><mo>=</mo><mo>(</mo><msub><mi>z</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>z</mi><mn>2</mn></msub><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo separator="true">,</mo><msub><mi>z</mi><mi>T</mi></msub><mo>)</mo></mrow><annotation encoding="application/x-tex">Z=(z_1,z_2,...,z_T)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.07153em;">Z</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.04398em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.04398em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.04398em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">T</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>，其中t时刻的<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>z</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">z_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.04398em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>属于N个隐藏状态中的一个。假设给定<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>z</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub></mrow><annotation encoding="application/x-tex">z_{t-1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.638891em;vertical-align:-0.208331em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.301108em;"><span style="top:-2.5500000000000003em;margin-left:-0.04398em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">t</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"><span></span></span></span></span></span></span></span></span></span>，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>z</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">z_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.04398em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>独立于之前的隐藏变量，并且当前的观测<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>x</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">x_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>只与当前的隐藏状态<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>z</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">z_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.04398em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>有关。因此，状态转移矩阵A表示为：<br>
<img src="https://jinyu-m.github.io/post-images/1604549213044.png" alt="" loading="lazy"><br>
初始状态分布<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>π</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">{\pi}_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">π</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>表示为：<br>
<img src="https://jinyu-m.github.io/post-images/1604549247983.png" alt="" loading="lazy"><br>
t时刻观测到状态i的概率为：<br>
<img src="https://jinyu-m.github.io/post-images/1604549318861.png" alt="" loading="lazy"><br>
目标为找到一个隐藏的状态序列，描述了reference images的期望语义标签。用后验概率来表示：<br>
<img src="https://jinyu-m.github.io/post-images/1604549410166.png" alt="" loading="lazy"><br>
其中<img src="https://jinyu-m.github.io/post-images/1604560965712.png" alt="" loading="lazy">是模型参数。<br>
<img src="https://jinyu-m.github.io/post-images/1604560991669.png" alt="" loading="lazy"><br>
估计了模型参数<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>θ</mi></mrow><annotation encoding="application/x-tex">\theta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span></span></span></span>后，可以获得reference image的最后语义标签<img src="https://jinyu-m.github.io/post-images/1604561172378.png" alt="" loading="lazy"><br>
输入的特征向量，即观察量<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>x</mi><mo>(</mo><mi>t</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">x(t)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault">x</span><span class="mopen">(</span><span class="mord mathdefault">t</span><span class="mclose">)</span></span></span></span>是Place Categorization的输出响应向量，是一个102维的向量，每一维的值代表了属于每个场景的可能性。在输入HMM之前，特征向量被标准化到[0,1]之间。模型参数<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>θ</mi></mrow><annotation encoding="application/x-tex">\theta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span></span></span></span>由Baum-Welch算法确定，可获得最可能的隐藏状态序列。隐藏状态的数量N由以经验决定。</p>
<h3 id="place-recognition">Place Recognition</h3>
<h4 id="sequence-based-place-matching">sequence-based place matching</h4>
<p>作者使用了SeqSLAM算法来进行场景识别。SeqSLAM通过reference和query images之间的Sum of Absolute Difference (SAD)分数D来实现场景识别。<br>
<img src="https://jinyu-m.github.io/post-images/1604562409950.png" alt="" loading="lazy"><br>
其中<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>S</mi><mi>x</mi></msub><mo separator="true">,</mo><msub><mi>S</mi><mi>y</mi></msub></mrow><annotation encoding="application/x-tex">S_x,S_y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.969438em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">x</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03588em;">y</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span>是下采样后图像尺寸，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msubsup><mi>p</mi><mrow><mi>x</mi><mo separator="true">,</mo><mi>y</mi></mrow><mi>i</mi></msubsup><mo separator="true">,</mo><msubsup><mi>p</mi><mrow><mi>x</mi><mo separator="true">,</mo><mi>y</mi></mrow><mi>j</mi></msubsup></mrow><annotation encoding="application/x-tex">p^i_{x,y},p^j_{x,y}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.2077719999999998em;vertical-align:-0.383108em;"></span><span class="mord"><span class="mord mathdefault">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.824664em;"><span style="top:-2.4530000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">x</span><span class="mpunct mtight">,</span><span class="mord mathdefault mtight" style="margin-right:0.03588em;">y</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.383108em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.824664em;"><span style="top:-2.4530000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">x</span><span class="mpunct mtight">,</span><span class="mord mathdefault mtight" style="margin-right:0.03588em;">y</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.383108em;"><span></span></span></span></span></span></span></span></span></span>是reference和query images的像素值。difference vector利用一个尺寸为R的sliding window，进行neighborhood normalization。<br>
<img src="https://jinyu-m.github.io/post-images/1604562192734.png" alt="" loading="lazy"><br>
在邻近标准化后的SAD矩阵中，在限制的速度范围内，从每个reference image开始搜索长度为<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>d</mi><mi>s</mi></msub></mrow><annotation encoding="application/x-tex">d_s</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">s</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>的局部图像序列。具有最佳分数的序列通过一个阈值来确定。</p>
<h4 id="localized-and-semantically-informed-matching">localized and semantically-informed matching</h4>
<p>place matching scores着重体现了环境中局部物理区域的匹配，而非找到一个全局最小值。sliding window的尺寸R体现了环境的跨度/范围。</p>
<p>在前文，作者利用HMM模型将数据集分割成若干带有相似环境条件的区域。作者提出用由HMM给出的<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>L</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">L_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>决定的邻近区域代替传统SeqSLAM中reference image的邻近图像。被分割出的区域可以表示为：<br>
<img src="https://jinyu-m.github.io/post-images/1604562894722.png" alt="" loading="lazy"><br>
也就是一段段具有相同语义标签<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>L</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">L_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>的序列。SAD矩阵的邻近标准化也相应变化。<br>
<img src="https://jinyu-m.github.io/post-images/1604563084024.png" alt="" loading="lazy"><br>
这样的处理使得SeqSLAM计算SAD时的sliding window随着场景条件的变化而变化，不再是一个定值，更具备condition-invariant。</p>
<h2 id="一点看法"><em>一点看法</em></h2>
<p>这篇论文究其根本，是利用语义信息来讲reference image进行划分，代替了SeqSLAM中固定尺寸的sliding window策略，借此提升了在一些跨场景数据集中的表现，这种变长的sliding window可以拓展下应用，在利用temporal consistency的算法中都可以参考借鉴的。</p>
<hr>
<h1 id="lost-appearance-invariant-place-recognition-for-opposite-viewpoints-using-visual-semantics-rss2018-pdf-code">LoST? Appearance-Invariant Place Recognition for Opposite Viewpoints using Visual Semantics -RSS2018 <a href="https://arxiv.org/abs/1804.05526">pdf</a> <a href="https://github.com/oravus/lostX">code</a></h1>
<h2 id="abstract-2"><em>Abstract</em></h2>
<p>We first propose a novel Local Semantic Tensor (LoST) descriptor of images using the convolutional feature maps from a state-of-the-art dense semantic segmentation network. Then, to verify the spatial semantic arrangement of the top matching candidates, we develop a novel approach for mining semantically-salient keypoint correspondences.</p>
<h2 id="introduction-2"><em>Introduction</em></h2>
<p><img src="https://jinyu-m.github.io/post-images/1604568457014.png" alt="" loading="lazy"><br>
作者提出现有的sota场景识别算法，在面对extreme appearance variation时的表现受到严重挑战。所以作者希望用语义信息来解决viewpoint and appearance variations问题，并且只有limited filed-of-view camera，而非全景相机或lidar。本文的贡献点在于：<br>
1.提出一个PR算法，结合了基于语义和外观的全局描述子和空间一致的局部keypoint correspondences；<br>
2.由语义标签和卷积特征图获得一种新的图像描述子，LoST；<br>
3.一种新的从匹配图像对中挖掘和筛选具有语义显著性的keypoint correspondences方法。</p>
<h2 id="method-2"><em>Method</em></h2>
<figure data-type="image" tabindex="1"><img src="https://jinyu-m.github.io/post-images/1604625876356.png" alt="" loading="lazy"></figure>
<h3 id="local-semantic-tensor">Local Semantic Tensor</h3>
<p>本文中，作者提出一种方法，利用语义标签分数和来自于稠密语义分割网络获得的卷积特征图来semantically pool features.</p>
<p>作者使用了在Cityscapes数据集上训练好的RefineNet作为语义分割网络，提取conv5层输出的卷积特征图，特征图的尺寸为<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mfrac><mn>1</mn><mn>32</mn></mfrac><mi>H</mi><mo>×</mo><mfrac><mn>1</mn><mn>32</mn></mfrac><mi>W</mi><mo>×</mo><mi>D</mi></mrow><annotation encoding="application/x-tex">\frac{1}{32}H\times \frac{1}{32}W \times D</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.190108em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.845108em;"><span style="top:-2.6550000000000002em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">3</span><span class="mord mtight">2</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mord mathdefault" style="margin-right:0.08125em;">H</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.190108em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.845108em;"><span style="top:-2.6550000000000002em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">3</span><span class="mord mtight">2</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mord mathdefault" style="margin-right:0.13889em;">W</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">D</span></span></span></span>，其中H和W都是原图的大小，D为2048维。得到的语义标签分数尺寸为<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mfrac><mn>1</mn><mn>4</mn></mfrac><mi>H</mi><mo>×</mo><mfrac><mn>1</mn><mn>4</mn></mfrac><mi>W</mi><mo>×</mo><mi>D</mi></mrow><annotation encoding="application/x-tex">\frac{1}{4}H\times \frac{1}{4}W \times D</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.190108em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.845108em;"><span style="top:-2.6550000000000002em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">4</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mord mathdefault" style="margin-right:0.08125em;">H</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.190108em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.845108em;"><span style="top:-2.6550000000000002em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">4</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mord mathdefault" style="margin-right:0.13889em;">W</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">D</span></span></span></span>，D为20，表示Cityscapes中的20类语义类别。在使用时，将语义分数缩放到与特征图一样的尺寸。</p>
<p>作者设计了语义描述子L，称为Local Semantic Tensor(LoST)。该描述子通过卷积特征图和语义标签概率计算得到：</p>
<figure data-type="image" tabindex="2"><img src="https://jinyu-m.github.io/post-images/1606215318034.png" alt="" loading="lazy"></figure>
<p>其中<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>l</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">l_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.01968em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>是特征图中在i位置的D维描述子<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>x</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">x_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>的语义标签，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>μ</mi><mi>s</mi></msub></mrow><annotation encoding="application/x-tex">{\mu}_{s}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord"><span class="mord mathdefault">μ</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">s</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>为语义类别s的平均描述子，均值是根据每个像素最可能的语义标签来计算的。图像描述子<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>L</mi><mi>s</mi></msub></mrow><annotation encoding="application/x-tex">L_s</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">s</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>是用像素i输出语义类别s的概率<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>m</mi><mrow><mi>i</mi><mi>s</mi></mrow></msub></mrow><annotation encoding="application/x-tex">m_{is}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">m</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mord mathdefault mtight">s</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>来计算的。<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>m</mi><mrow><mi>i</mi><mi>s</mi></mrow></msub></mrow><annotation encoding="application/x-tex">m_{is}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">m</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mord mathdefault mtight">s</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>是标签分数在D维上进行L1-normalization得到的。实际上，每个语义描述子<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>L</mi><mi>s</mi></msub></mrow><annotation encoding="application/x-tex">L_s</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">s</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>是特定语义类别s中residual descriptor与其他语义类别的带噪声分布的聚合，通过语义标签概率来进行加权。(与VLAD描述子很相近，这里采用语义信息进行聚类)。最后图像的描述子L是road、building和vegetation三类<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>L</mi><mi>s</mi></msub></mrow><annotation encoding="application/x-tex">L_s</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">s</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>经L2-normalization后拼接得到。</p>
<p>在reference database中，作者将公式2中计算平均值的范围从单张图像拓展到邻近15张图像。</p>
<p>在candidate search中，利用余弦距离计算query与reference images之间的距离，取10个candidates。</p>
<h3 id="correspondence-extraction">Correspondence Extraction</h3>
<p>在这篇论文中，作者将maximally-activated locations视为keypoint。作者认为，既然高层的卷积特征图可以捕获图像的语义信息而且语义信息是由相互对应关系的，那么可以合理假设，卷积特征图中包含着correspondence，并且这种correspondence可以映射到特征图中的高响应关键点位置。对于一堆图像，我们可以从高层网络中提取出D个keypoint correspondence。</p>
<p>如果匹配的图像是理想的或者完全一致的，那么correspondence会很完美。但是在实际场景中，会有一些原因造成false correspondence：1.卷积核隐形地被训练去检测特定特征，但是这些特征没有出现在当前图像中，可能会导致网络在随机位置被触发，错误的检测出特定特征；2.同一图像中多个类似物体，会导致cross-correspond；3.动态物体也会引起false corresponde</p>
<h3 id="spatial-layout-verification">Spatial Layout Verification</h3>
<p>为了限制correspondence的数量并且防止false correspondence，作者使用了基于语义一致性的先验筛选。</p>
<h4 id="semantic-label-consistency">Semantic Label consistency</h4>
<p>对于每对keypoint correspondence，作者是用语义标签去筛选，那些具有相似标签的被保留下来。这一步可以筛掉一半多的correspondence，特别是那些受原因1影响的情况。进一步地，作者用neighborhood density test来筛选剩下的correspondence，即在keypoint周围3x3的邻域内，只有一个correspondence被保留下来。这一步可以帮助减少相同语义类别的小范围内冗余的correspondence。</p>
<h4 id="weighted-keypoint-matching">Weighted Keypoint Matching</h4>
<p>对于剩余的corresponding keypoints，记为M，从conv5层提取的k和<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>k</mi><mo mathvariant="normal">′</mo></msup></mrow><annotation encoding="application/x-tex">k&#x27;</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.751892em;vertical-align:0em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03148em;">k</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.751892em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span></span></span></span>处keypoint的D维描述子<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>x</mi><mi>k</mi></msub><mo separator="true">,</mo><msubsup><mi>x</mi><mi>k</mi><mo mathvariant="normal">′</mo></msubsup></mrow><annotation encoding="application/x-tex">x_k, x_k&#x27;</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.035em;vertical-align:-0.2831079999999999em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.751892em;"><span style="top:-2.4168920000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2831079999999999em;"><span></span></span></span></span></span></span></span></span></span>。同时，将图像左右翻转(处理rear-view图像)，得到keypoint对应的翻转坐标<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>p</mi><mi>k</mi></msub><mo separator="true">,</mo><msubsup><mi>p</mi><mi>k</mi><mo mathvariant="normal">′</mo></msubsup></mrow><annotation encoding="application/x-tex">p_k, p_k&#x27;</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.035em;vertical-align:-0.2831079999999999em;"></span><span class="mord"><span class="mord mathdefault">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.751892em;"><span style="top:-2.4168920000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2831079999999999em;"><span></span></span></span></span></span></span></span></span></span><strong>(?)</strong>。然后这些keypoint的位置通过加权欧拉距离来完成匹配：<br>
<img src="https://jinyu-m.github.io/post-images/1604629856145.png" alt="" loading="lazy"><br>
其中<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>w</mi><mrow><mi>k</mi><msup><mi>k</mi><mo mathvariant="normal">′</mo></msup></mrow></msub></mrow><annotation encoding="application/x-tex">w_{kk&#x27;}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6828285714285715em;"><span style="top:-2.786em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>是对应descriptor <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>x</mi><mi>k</mi></msub><mo separator="true">,</mo><msubsup><mi>x</mi><mi>k</mi><mo mathvariant="normal">′</mo></msubsup></mrow><annotation encoding="application/x-tex">x_k, x_k&#x27;</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.035em;vertical-align:-0.2831079999999999em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.751892em;"><span style="top:-2.4168920000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2831079999999999em;"><span></span></span></span></span></span></span></span></span></span>的余弦距离，在所有匹配对M上进行normalization。<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>r</mi><mi>c</mi></msub></mrow><annotation encoding="application/x-tex">r_c</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">c</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>是候选c的匹配分数，具有最低分数的候选被认为是最终的匹配。</p>
<h4 id="我的理解">我的理解</h4>
<p>这部分看的有点懵，我的理解是，作者将D维feature map中的每一维都提取出来，找到图中最大响应值的位置，作为keypoint。这样对于query和reference image，每张图像可以提取出D个keypoint，并且两张图像的keypoint已经有了一一对应的的关系，也就是D个keypoint correspondence。对于这D个keypoint correspondence，作者对每个correspondence先用语义进行了筛选，如果每个correspondence中对应的keypoint的语义类别是相同的，那么保留这个correspondence，否则剔除。并且，为了减少同一语义类别中小邻域内存在大量keypoint，作者在3x3的区域内，只保留了一个correspondence。在计算query和reference之间的匹配分数时，由于已知了keypoint correspondence，所以只需要计算匹配误差就行。也就是加权欧拉距离，但是这里**为什么要计算翻转后keypoint坐标的欧拉距离？**还没想清楚。难道是假设了遇到的情况都是opposite-view？而且视角都在同一水平面内平移？这种情况有点局限吧。</p>
<h3 id="image-sequence-matching">Image Sequence Matching</h3>
<p>作者用OpenSeqSLAM的方法加入了temporal consistency，也就是累加序列的匹配分数，找到最优的匹配候选。</p>
<h2 id="performance"><em>Performance</em></h2>
<p>LoST是指只采用图像描述子的检测方法，LoST-X是指整个算法。<br>
sequence matching:<br>
<img src="https://jinyu-m.github.io/post-images/1604633587324.png" alt="" loading="lazy"><br>
single_frame matching:<br>
<img src="https://jinyu-m.github.io/post-images/1604633669753.png" alt="" loading="lazy"></p>
<hr>
<h1 id="dont-look-back-robustifying-place-categorization-for-viewpoint-and-condition-invariant-place-recognition-icra-2018-pdf">Don't Look Back: Robustifying Place Categorization for Viewpoint- and Condition-Invariant Place Recognition (ICRA 2018) <a href="https://arxiv.org/abs/1801.05078">pdf</a></h1>
<h2 id="abstract-3"><em>Abstract</em></h2>
<p>In this work, we develop a novel methodology for using the semantics-aware higher-order layers of deep neural networks for recognizing specific places from within a reference database. To further improve the robustness to appearance change, we develop a descriptor normalization scheme that builds on the success of normalization schemes for pure appearance-based techniques such as SeqSLAM.</p>
<h2 id="introduction-3"><em>Introduction</em></h2>
<p>作者先说了一下place categorization和place recognition之间的联系和区别。place categorization相对更简单，只是识别了当前场景的类型，如parking garage，但是place recognition还要识别出在parking garage中拍摄当前图像时相机的具体位置。<br>
在这篇论文中，作者研究了神经网络高层的语义级别的全连接层的适应性，而非依赖于视角的中层卷积层，来获得视角不变性和条件不变性的场景识别。特别调研了语义级别的图像表征在应对极端视角变化时的表现。除此之外，作者来提出一种描述子标准化方法，来获得多变环境条件下的外观鲁棒性。并且展示了上下文信息可以用于生成一个拓展的图像描述子，进一步提升场景识别的表现。最后，作者通过与场景描述子的PCA分析得到了一些有价值的观点，突出了场景识别任务中时空特性的重要性。</p>
<h2 id="method-3"><em>Method</em></h2>
<h3 id="place-representation">Place Representation</h3>
<p>作者使用了<strong>Places365</strong>网络去表征场景，高层的全连接层可以输出场景的语义描述，所以作者使用<strong>fc6</strong>输出的4096维向量来描述场景。虽然全连接层输出的特征具被视角不变性，但是缺乏外观不变性。</p>
<h3 id="feature-normalization">Feature Normalization</h3>
<p>作者为了增加场景外观不变性，对描述子进行了标准化：<br>
<img src="https://jinyu-m.github.io/post-images/1604890569771.png" alt="" loading="lazy"><br>
其中<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>μ</mi><mi>s</mi></msub></mrow><annotation encoding="application/x-tex">{\mu}_s</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord"><span class="mord mathdefault">μ</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">s</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>是数据集中所有图像描述子的均值，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>δ</mi><mi>s</mi></msub></mrow><annotation encoding="application/x-tex">{\delta}_s</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord"><span class="mord mathdefault" style="margin-right:0.03785em;">δ</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">s</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>是方差。标准化后的特征描述子集合称为Normalized Set of Descriptors (NSD)。对于reference images，由于图像可以事先获得，所以直接在全部图像中计算均值和方差。对于query image，均值和方差随着图像输入不断更新。</p>
<h3 id="sequence-search-in-cost-matrix">Sequence Search in Cost Matrix</h3>
<p>作者计算了query image和reference images之间的余弦距离（应该是1-cosine similarity），得到了一个cost matrix，利用SeqSLAM中的序列匹配方法，搜索匹配的序列：<br>
<img src="https://jinyu-m.github.io/post-images/1604890902565.png" alt="" loading="lazy"><br>
<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>S</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">S_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>是reference image i的最小序列匹配损失。k是序列匹配的斜率（参考SeqSLAM），是在cost matrix对角线±2 rad间变化。<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>D</mi><mi>T</mi></msup></mrow><annotation encoding="application/x-tex">D^T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8413309999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">D</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span></span></span></span>是时间T时的余弦距离，在时间长度为<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>l</mi></mrow><annotation encoding="application/x-tex">l</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.01968em;">l</span></span></span></span>的序列上累加。<br>
<img src="https://jinyu-m.github.io/post-images/1604891259870.png" alt="" loading="lazy"><br>
<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>I</mi><mrow><mi>m</mi><mi>i</mi><mi>n</mi></mrow></msub></mrow><annotation encoding="application/x-tex">I_{min}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07847em;">I</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">m</span><span class="mord mathdefault mtight">i</span><span class="mord mathdefault mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>是匹配的reference image</p>
<h3 id="cropped-regions">Cropped Regions</h3>
<p><img src="https://jinyu-m.github.io/post-images/1604891760942.png" alt="" loading="lazy"><br>
为了解决opposite-view的问题，作者在图像中提取左右两个region，分别提取Normalized Descriptor，得到两个4096维的描述子，在匹配时，两个描述子都计算余弦距离，取较小的作为度量。(称为NSD-CR)</p>
<h2 id="performance-2"><em>Performance</em></h2>
<h3 id="across-datasets">Across Datasets</h3>
<p><img src="https://jinyu-m.github.io/post-images/1604893224752.png" alt="" loading="lazy"><br>
<img src="https://jinyu-m.github.io/post-images/1604893228900.png" alt="" loading="lazy"><br>
<img src="https://jinyu-m.github.io/post-images/1604893232030.png" alt="" loading="lazy"><br>
证明了在front v.s. rear-view的情况下，NSD-CR算法表现最好。</p>
<h3 id="across-layers">Across Layers</h3>
<p><img src="https://jinyu-m.github.io/post-images/1604893470243.png" alt="" loading="lazy"><br>
证明了fc6是可以较好的平衡外观不变性和视角不变性的。</p>
<h3 id="across-networks">Across Networks</h3>
<p><img src="https://jinyu-m.github.io/post-images/1604893541180.png" alt="" loading="lazy"><br>
证明了提出的方法NSD对于任何网络都有效，并且通过place-centric training得到的网络p365、NetVLAD表现比object-centric training得到的网络要更好，因为它表征了场景的类别属性。</p>
<h2 id="一点看法-2"><em>一点看法</em></h2>
<p>这篇论文通过利用分类网络的高层全连接层来获得语义信息，解决视角不变性。采用cropped regions的方法来解决front v.s. rear view的问题，但是我感觉有些局限，相当于已知视角变化是相同方向或相反方向加一个小视角偏移。像X-view适用的范围更广，所以，图模型大有可为😎</p>
<hr>
<h1 id="x-view-graph-based-semantic-multi-view-localization-ral-2018-pdf">X-View: Graph-Based Semantic Multi-View Localization (RAL 2018) <a href="https://arxiv.org/abs/1709.09905">pdf</a></h1>
<h2 id="abstract-4"><em>Abstract</em></h2>
<p>在这篇论文中，作者希望利用人造环境中的语义信息来解决剧烈视角变化的问题。利用语义图的描述子来实现定位，来实现aerial-to-ground、ground-to-ground的剧烈视角变化时的定位问题。</p>
<h2 id="method-4"><em>Method</em></h2>
<figure data-type="image" tabindex="3"><img src="https://jinyu-m.github.io/post-images/1604918165507.png" alt="" loading="lazy"></figure>
<h3 id="system-input">System Input</h3>
<p>算法的输入是具有像素级别的语义或实例分割图像。并且算法假设已经有了一个额外的里程计提供的估计和之前得到的语义地图<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>G</mi><mrow><mi>d</mi><mi>b</mi></mrow></msub></mrow><annotation encoding="application/x-tex">G_{db}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">G</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">d</span><span class="mord mathdefault mtight">b</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>.</p>
<h3 id="graph-extraction-and-assembly">Graph extraction and assembly</h3>
<p>这一步中，算法将一段语义图像序列转换成一个query graph <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>G</mi><mi>q</mi></msub></mrow><annotation encoding="application/x-tex">G_q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.969438em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault">G</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03588em;">q</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span>。先对语义图进行腐蚀和膨胀获得无噪声的语义分割图，然后提取具有相同语义标签的区域，作为一个blob。提取每个blob的中心点<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>p</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">p_j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.716668em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span>，并记录。每个blob被当作一个顶点<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>v</mi><mi>j</mi></msub><mo>=</mo><mo>{</mo><msub><mi>l</mi><mi>j</mi></msub><mo separator="true">,</mo><msub><mi>p</mi><mi>j</mi></msub><mo>}</mo></mrow><annotation encoding="application/x-tex">v_j=\{l_j,p_j\}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.716668em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.036108em;vertical-align:-0.286108em;"></span><span class="mopen">{</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.01968em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mclose">}</span></span></span></span>.<br>
可以根据一幅图像构建一张二维图像内的无向图，也可以根据一段序列构建在3D空间内的无向图<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>e</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">e_j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.716668em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span>. 利用深度信息或者深度预测，可以用3D坐标来计算blobs的欧拉距离来获得3D空间内的邻近关系。一段图像中，每张图像的无向图根据欧拉距离来连接顶点。为了减少同一语义信息的重复顶点，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>G</mi><mi>q</mi></msub></mrow><annotation encoding="application/x-tex">G_q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.969438em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault">G</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03588em;">q</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span>中邻近的实例被合并成一个顶点。</p>
<h3 id="descriptors">Descriptors</h3>
<p>图匹配问题是一个NP难问题，所以作者在这篇论文中使用了random walk描述子去描述拓扑图，保证描述子的提取和匹配时间是常数或线性的。<br>
每个节点的描述子是一个<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>n</mi><mo>×</mo><mi>m</mi></mrow><annotation encoding="application/x-tex">n\times m</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.66666em;vertical-align:-0.08333em;"></span><span class="mord mathdefault">n</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault">m</span></span></span></span>的矩阵，随机游走n次，每次走m步。在每次游走过程中，从当前节点<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>v</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">v_j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.716668em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span>开始，记录经过节点的语义标签。在控制游走路径时，防止回到上一步刚经过的节点，避免出现重复的游走路径，这样可以提升描述子的表达能力。<br>
<img src="https://jinyu-m.github.io/post-images/1604971314721.png" alt="" loading="lazy"></p>
<h3 id="descriptor-matching">Descriptor matching</h3>
<p>当<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>G</mi><mi>q</mi></msub></mrow><annotation encoding="application/x-tex">G_q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.969438em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault">G</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03588em;">q</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span>和<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>G</mi><mi>d</mi></msub><mi>b</mi></mrow><annotation encoding="application/x-tex">G_db</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">G</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">d</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord mathdefault">b</span></span></span></span>都获得后，我们计算query graph中的顶点和database graph中的顶点的描述子相似度来获得associations。对于每个query graph中的顶点，我们通过语义描述子找到database中与之具有相同随机游走的顶点，相同随机游走的数量被当作相似度分数s，被标准化至0到1之间。在第二步中，具有最大相似度的k个匹配被挑选出来，来估计query image在database map中的位置。</p>
<h3 id="localization-back-end">Localization back-end</h3>
<p>query image与global graph之间的匹配、robot观察到的顶点，以及机器人的里程计估计可以构成在顶点<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>p</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">p_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathdefault">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>和机器人位姿<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>c</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">c_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>时的约束<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>θ</mi><mi>i</mi></msub><mo>∈</mo><mi mathvariant="normal">Θ</mi><mo>(</mo><msub><mi>p</mi><mi>i</mi></msub><mo separator="true">,</mo><msub><mi>c</mi><mi>i</mi></msub><mo>)</mo></mrow><annotation encoding="application/x-tex">{\theta}_i \in \Theta(p_i, c_i)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">Θ</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>，其中<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>θ</mi><mi>i</mi></msub><mo>=</mo><msubsup><mi>e</mi><mi>i</mi><mi>T</mi></msubsup><msub><mi mathvariant="normal">Ω</mi><mi>i</mi></msub><msub><mi>e</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">{\theta}_{i}=e_i^T{\Omega}_ie_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.0999949999999998em;vertical-align:-0.258664em;"></span><span class="mord"><span class="mord mathdefault">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-2.441336em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">T</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.258664em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord"><span class="mord">Ω</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathdefault">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>, <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>e</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">e_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>是测量误差，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi mathvariant="normal">Ω</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">{\Omega}_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord"><span class="mord">Ω</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>是associated information matrix。这三种形式的约束，可以分别记为<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi mathvariant="normal">Θ</mi><mi>M</mi></msub><mo>(</mo><msub><mi>p</mi><mi>i</mi></msub><mo>)</mo></mrow><annotation encoding="application/x-tex">{\Theta}_M(p_i)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord"><span class="mord">Θ</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.10903em;">M</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>、<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi mathvariant="normal">Θ</mi><mi>V</mi></msub><mo>(</mo><msub><mi>p</mi><mi>i</mi></msub><mo separator="true">,</mo><msub><mi>c</mi><mi>i</mi></msub><mo>)</mo></mrow><annotation encoding="application/x-tex">{\Theta}_V(p_i, c_i)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord"><span class="mord">Θ</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.22222em;">V</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>和<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi mathvariant="normal">Θ</mi><mi>O</mi></msub><mo>(</mo><msub><mi>c</mi><mi>i</mi></msub><mo>)</mo></mrow><annotation encoding="application/x-tex">{\Theta}_O(c_i)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord"><span class="mord">Θ</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">O</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>。<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi mathvariant="normal">Θ</mi><mi>M</mi></msub><mo>(</mo><msub><mi>p</mi><mi>i</mi></msub><mo>)</mo></mrow><annotation encoding="application/x-tex">{\Theta}_M(p_i)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord"><span class="mord">Θ</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.10903em;">M</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>来源于语义描述子的误差，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi mathvariant="normal">Θ</mi><mi>O</mi></msub><mo>(</mo><msub><mi>c</mi><mi>i</mi></msub><mo>)</mo></mrow><annotation encoding="application/x-tex">{\Theta}_O(c_i)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord"><span class="mord">Θ</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">O</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>源自在不断将机器人位姿关联到localization graph时使用的里程计的估计误差，robot-to-vertex约束内涵了每次机器人观察到结点的转换信息。<br>
利用这三种约束，作者通过Maximum a Posterior (MAP)，让负对数后验<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>E</mi><mo>=</mo><mo>∑</mo><msub><mi>θ</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">E=\sum {\theta}_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.05764em;">E</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.00001em;vertical-align:-0.25001em;"></span><span class="mop op-symbol small-op" style="position:relative;top:-0.0000050000000000050004em;">∑</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>最小，来估计机器人的位姿<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>c</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">c_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>:<br>
<img src="https://jinyu-m.github.io/post-images/1604973727388.png" alt="" loading="lazy"><br>
该问题可以通过Gauss-Newton方法来优化。在算法中，作者用匹配顶点的平均位置来初始化机器人的位置。</p>
<h2 id="performance-3"><em>Performance</em></h2>
<p><img src="https://jinyu-m.github.io/post-images/1604974955243.png" alt="" loading="lazy"><br>
<img src="https://jinyu-m.github.io/post-images/1604975150924.png" alt="" loading="lazy"><br>
<img src="https://jinyu-m.github.io/post-images/1604975210053.png" alt="" loading="lazy"></p>
<h2 id="一点看法-3"><em>一点看法</em></h2>
<p>X-view构建语义拓扑图和利用random walk描述子来表示图像的方法很新颖、高效。但是算法要求理想的分割结果，以我自己的工程经验而言，即使在KITTI这种比较理想的真实数据集上，语义分割的效果也不足以构建如X-view论文中所需的拓扑图...所以算法的实际效果有待考证，官方代码还没开源，所以只能默默等待了。</p>
<hr>
<h1 id="calc20combining-appearance-semantic-and-geometric-information-for-robust-and-efficient-visual-loop-closure-iros-2019-pdf-code">CALC2.0：Combining Appearance, Semantic and Geometric Information for Robust and Efficient Visual Loop Closure (IROS 2019) <a href="https://arxiv.org/abs/1910.14103">pdf</a> <a href="https://github.com/rpng/calc2.0">code</a></h1>
<h2 id="abstract-5"><em>Abstract</em></h2>
<p>作者认为现有的基于CNN的回环检测算法虽然使用了语义、外观或者几何特征信息，但是没有很充分的利用一张图像可以提供过的全部信息（语义、外观、几何信息等），并且需要人工设置参数去完成实际的回环检测。这篇论文中，作者提出了一个专为场景识别设计的神经网络，由semantic segmentator、Variational Autoencoder(VAE)和triplet embedding network组成。该网络用于提取一个全局特征空间来描述图像的外观和语义分布。然后从低层卷积特征图中提取最大响应的区域作为局部关键点，关键点描述子也参考hand-crafted特征的思路从这些特征图中提取。关键点被用于全局匹配搜索候选的回环，并用于最后的几何验证来提出错误回环。</p>
<h2 id="method-5"><em>Method</em></h2>
<p>这篇论文提出的方法核心思想是，尽可能充分的利用单目图像可以提供的信息，如外观、语义和几何一致性，以此实现无需人工设计参数的回环检测。</p>
<h3 id="network-design">Network Design</h3>
<p><img src="https://jinyu-m.github.io/post-images/1605669259100.png" alt="" loading="lazy"><br>
网络由三部分组成：1 VAE， 1 semantic segmentator和1 siamese triplet embedding。最后使用时，只使用encoder部分。网络的输入是RGB图像，大小为<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>H</mi><mo>×</mo><mi>W</mi></mrow><annotation encoding="application/x-tex">H\times W</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.76666em;vertical-align:-0.08333em;"></span><span class="mord mathdefault" style="margin-right:0.08125em;">H</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">W</span></span></span></span>。encoder部分由一个3x3卷积，两个residual block和四个2x2卷积+pool组成。最后用两个1x1卷积来计算隐藏变量<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>μ</mi><mo separator="true">,</mo><mi>σ</mi></mrow><annotation encoding="application/x-tex">\mu, \sigma</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathdefault">μ</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">σ</span></span></span></span>。隐藏变量是训练用于确定一个高斯分布的参数<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi mathvariant="script">N</mi><mo>(</mo><mi>μ</mi><mo separator="true">,</mo><mi>d</mi><mi>i</mi><mi>a</mi><mi>g</mi><mo>(</mo><mi>e</mi><mi>x</mi><mi>p</mi><mo>(</mo><mi>σ</mi><mo>)</mo><mo>)</mo><mo>)</mo></mrow><annotation encoding="application/x-tex">\mathcal{N}(\mu, diag(exp(\sigma)))</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathcal" style="margin-right:0.14736em;">N</span></span><span class="mopen">(</span><span class="mord mathdefault">μ</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">d</span><span class="mord mathdefault">i</span><span class="mord mathdefault">a</span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mopen">(</span><span class="mord mathdefault">e</span><span class="mord mathdefault">x</span><span class="mord mathdefault">p</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.03588em;">σ</span><span class="mclose">)</span><span class="mclose">)</span><span class="mclose">)</span></span></span></span>.取<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>σ</mi></mrow><annotation encoding="application/x-tex">\sigma</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">σ</span></span></span></span>的指数只是为了提升数值稳定性。在这种解释下，隐藏参数应该都是向量，它们通过对它们所在的<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mfrac><mi>H</mi><mn>16</mn></mfrac><mo>×</mo><mfrac><mi>W</mi><mn>16</mn></mfrac><mo>×</mo><mi>M</mi><mo>(</mo><mi>N</mi><mo>+</mo><mn>1</mn><mo>)</mo></mrow><annotation encoding="application/x-tex">\frac{H}{16} \times \frac{W}{16} \times M(N+1)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.217331em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.872331em;"><span style="top:-2.6550000000000002em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mord mtight">6</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.08125em;">H</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.217331em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.872331em;"><span style="top:-2.6550000000000002em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mord mtight">6</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">W</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.10903em;">M</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.10903em;">N</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">1</span><span class="mclose">)</span></span></span></span>的3D数组展平得到。</p>
<p>隐藏变量通过让其构建一个标准正太分布来优化，使用KL散度作为损失函数：<br>
<img src="https://jinyu-m.github.io/post-images/1605670044947.png" alt="" loading="lazy"></p>
<p>用一个符合标准正太分布的<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>ϵ</mi></mrow><annotation encoding="application/x-tex">\epsilon</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault">ϵ</span></span></span></span>来采样，隐藏变量<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>z</mi><mo>=</mo><mi>μ</mi><mo>+</mo><mi>d</mi><mi>i</mi><mi>a</mi><mi>g</mi><mo>(</mo><mi>e</mi><mi>x</mi><mi>p</mi><mo>(</mo><mi>σ</mi><mo>)</mo><msup><mo>)</mo><mfrac><mn>1</mn><mn>2</mn></mfrac></msup><mi>ϵ</mi></mrow><annotation encoding="application/x-tex">z=\mu + diag(exp(\sigma))^{\frac{1}{2}}\epsilon</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.7777700000000001em;vertical-align:-0.19444em;"></span><span class="mord mathdefault">μ</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.20402em;vertical-align:-0.25em;"></span><span class="mord mathdefault">d</span><span class="mord mathdefault">i</span><span class="mord mathdefault">a</span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mopen">(</span><span class="mord mathdefault">e</span><span class="mord mathdefault">x</span><span class="mord mathdefault">p</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.03588em;">σ</span><span class="mclose">)</span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9540200000000001em;"><span style="top:-3.363em;margin-right:0.05em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mopen nulldelimiter sizing reset-size3 size6"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8443142857142858em;"><span style="top:-2.656em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span><span style="top:-3.2255000000000003em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line mtight" style="border-bottom-width:0.049em;"></span></span><span style="top:-3.384em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.344em;"><span></span></span></span></span></span><span class="mclose nulldelimiter sizing reset-size3 size6"></span></span></span></span></span></span></span></span></span></span><span class="mord mathdefault">ϵ</span></span></span></span>被切分成N+1组特征图，对应着视觉外观和N个语义类别。</p>
<p>视觉外观部分的decoder用RGB reconstruction loss来训练：<br>
<img src="https://jinyu-m.github.io/post-images/1605670354303.png" alt="" loading="lazy"><br>
其中 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>x</mi><mrow><mi>h</mi><mo separator="true">,</mo><mi>w</mi><mo separator="true">,</mo><mi>c</mi></mrow></msub><mo separator="true">,</mo><msub><mi>r</mi><mrow><mi>h</mi><mo separator="true">,</mo><mi>w</mi><mo separator="true">,</mo><mi>c</mi></mrow></msub></mrow><annotation encoding="application/x-tex">x_{h,w,c},r_{h,w,c}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.716668em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">h</span><span class="mpunct mtight">,</span><span class="mord mathdefault mtight" style="margin-right:0.02691em;">w</span><span class="mpunct mtight">,</span><span class="mord mathdefault mtight">c</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">h</span><span class="mpunct mtight">,</span><span class="mord mathdefault mtight" style="margin-right:0.02691em;">w</span><span class="mpunct mtight">,</span><span class="mord mathdefault mtight">c</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span>分布是输入图像和重建图像在(h,w,c)处的值。</p>
<p>语义分割部分decoder的输出在channel维度拼接在一起，用一个标准的pixel-wise softmax cross entropy loss <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>L</mi><mi>s</mi></msub></mrow><annotation encoding="application/x-tex">L_s</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">s</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>来训练，用一个权重来平衡类别偏差，每个类的权重是数据集中所有当前类别的像素的百分比的倒数经标准化（最多的类别权重为1）后得到。</p>
<p>作者在COCO stuff数据集上进行训练，没有使用COCO提供的92个类别，而是构建了13个超类来更普遍的描述场景的语义信息。这样可以帮助提升模型的语义分割精度，减少所需局部描述子的数量，来获得更紧密的嵌入表示。所有动态物体都被包含在“other”类中，让模型更关注静态的物体。</p>
<p>在网络结构方面，除了计算隐藏变量和decoder最后的输出层外，所有卷积层都使用了Exponential Linear Unit（ELU）激活函数，语义分割decoder输出层和计算隐藏变量的卷积层没有激活函数，图像重建decoder加入sigmoid激活函数。在encoder层中，步长为2，卷积核尺寸为2x2的max-pooling被用于下采样特征，而subpixel convolution用于上采样特征。</p>
<p>全局图像描述子从隐藏变量<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>μ</mi></mrow><annotation encoding="application/x-tex">\mu</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathdefault">μ</span></span></span></span>中获得，其可以视作一个3D的数组，一组Mx(N+1)个D维的局部描述子，对N+1个decoder每个输入M个feature map；或者可以视为一个长度为DxMx(N+1)的向量，其中<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>D</mi><mo>=</mo><mfrac><mi>H</mi><mn>16</mn></mfrac><mo>×</mo><mfrac><mi>W</mi><mn>16</mn></mfrac></mrow><annotation encoding="application/x-tex">D=\frac{H}{16} \times \frac{W}{16}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">D</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.217331em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.872331em;"><span style="top:-2.6550000000000002em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mord mtight">6</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.08125em;">H</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.217331em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.872331em;"><span style="top:-2.6550000000000002em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mord mtight">6</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">W</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span><br>
<img src="https://jinyu-m.github.io/post-images/1606114164015.png" alt="" loading="lazy"></p>
<p>根据<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>μ</mi></mrow><annotation encoding="application/x-tex">\mu</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathdefault">μ</span></span></span></span>的第二种定义，作者计算了残差<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>μ</mi><mo>−</mo><mi>c</mi></mrow><annotation encoding="application/x-tex">\mu-c</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7777700000000001em;vertical-align:-0.19444em;"></span><span class="mord mathdefault">μ</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault">c</span></span></span></span>，其中c是由Mx(N+1)个在维度D上学习到的聚类中心在channel维度拼接而成的，它是用一个高斯分布随机初始化得到的，训练去最小化triplet embedding loss。该残差然后利用NetVLAD中的intra-normalization处理，用channel维度的L2-norm来防止描述子崩坏。然后，根据<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>μ</mi></mrow><annotation encoding="application/x-tex">\mu</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathdefault">μ</span></span></span></span>的第一种定义，作者标准化整个描述子，以适应用内积来计算cosine相似度。采用triplet embedding loss来训练：<br>
<img src="https://jinyu-m.github.io/post-images/1606114653517.png" alt="" loading="lazy"></p>
<h3 id="network-training">Network Training</h3>
<p>网络利用Adam训练，总的损失函数为<br>
<img src="https://jinyu-m.github.io/post-images/1606132490915.png" alt="" loading="lazy"><br>
作者用COCO数据集完成训练，由于没有true positive数据，所以作者用homography随机warp图像，随机将图像变黑来仿真夜视图像，随机左右翻转图像，来获得fake true positive。</p>
<h3 id="inference">Inference</h3>
<h4 id="keypoint-extraction">keypoint extraction</h4>
<p>全局描述子可以用最近邻搜索完成图像检索，但是需要阈值来确定匹配。为了解决这一问题，作者选择提取低层conv5层的卷积特征图中的最大激活区域来作为关键点。conv5层是全分辨率的，具有32维的特征图。为了获得的特征数量是有意义的，作者提取图像中每个大小为<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mfrac><mi>H</mi><msub><mi>N</mi><mi>w</mi></msub></mfrac><mo>×</mo><mfrac><mi>W</mi><msub><mi>N</mi><mi>w</mi></msub></mfrac></mrow><annotation encoding="application/x-tex">\frac{H}{N_w} \times \frac{W}{N_w}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.317431em;vertical-align:-0.44509999999999994em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.872331em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.16454285714285719em;"><span style="top:-2.357em;margin-left:-0.10903em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathdefault mtight" style="margin-right:0.02691em;">w</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.08125em;">H</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.44509999999999994em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.317431em;vertical-align:-0.44509999999999994em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.872331em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.16454285714285719em;"><span style="top:-2.357em;margin-left:-0.10903em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathdefault mtight" style="margin-right:0.02691em;">w</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">W</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.44509999999999994em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span>的划窗中的最大响应区域作为特征。重复的特征被剔除。</p>
<p>得到关键点后，作者设计了一种类似于BRIEF的描述子，在conv5层的输出特征图(32d)上，作者在关键点周围3x3的邻域内计算特征向量的残差，将这些残差拼接在一起，得到256d关键点描述子。这些描述子在匹配时直接用欧拉距离度量相似度，在匹配时，作者使用K(=2)-NN来搜索，利用传统的ratio test来确定一个有效的匹配，</p>
<h4 id="loop-closure-detection">loop closure detection</h4>
<p>作者用K(=7)-NN；来搜索可能的回环，然后用特征匹配来验证回环，只有可以通过RANSAC获得有效fundamental矩阵的匹配（也就是至少8对有效匹配）的图像才被认为是正确回环。</p>
<h2 id="performance-4"><em>Performance</em></h2>
<p><img src="https://jinyu-m.github.io/post-images/1606184275095.png" alt="" loading="lazy"><br>
作者展示了在wall、structure other、visual appearance分量上，database、positive、negative的相似度，可以看到，appearance产生了混淆，但是根据语义信息，则可以较好的分辨positive和negative。</p>
<p><img src="https://jinyu-m.github.io/post-images/1606184095059.png" alt="" loading="lazy"><br>
<img src="https://jinyu-m.github.io/post-images/1606184446819.png" alt="" loading="lazy"><br>
<img src="https://jinyu-m.github.io/post-images/1606184469105.png" alt="" loading="lazy"><br>
<img src="https://jinyu-m.github.io/post-images/1606184583667.png" alt="" loading="lazy"><br>
比NetVLAD表现好，很强了</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Deep Local Features]]></title>
        <id>https://jinyu-m.github.io/post/deep-local-features/</id>
        <link href="https://jinyu-m.github.io/post/deep-local-features/">
        </link>
        <updated>2020-10-01T01:30:16.000Z</updated>
        <summary type="html"><![CDATA[<p>最近要做一个关于deep local feature for localization的工作，所以读了一些learnt feature的论文，记录一下，作为参考。也希望自己的工作得到评委认可呀😎</p>
]]></summary>
        <content type="html"><![CDATA[<p>最近要做一个关于deep local feature for localization的工作，所以读了一些learnt feature的论文，记录一下，作为参考。也希望自己的工作得到评委认可呀😎</p>
<!-- more -->
<h1 id="magicpoint-magic-leap-pdf">MagicPoint (Magic Leap) <a href="https://arxiv.org/abs/1707.07410.pdf">pdf</a></h1>
<h2 id="abstract"><em>Abstract</em></h2>
<p>论文提出了一种基于两个DCN的point tracking system。第一个DCN就是MagicPoint，提取图像的显著二维坐标点（只有detector）；第二个DCN是MagicWrap，输入利用MagicPoint得到的一对图像中的二维坐标点信息，直接预测homography（不需要descriptor信息）。</p>
<h2 id="introduction"><em>Introduction</em></h2>
<p>作者先抛出了一个问题</p>
<blockquote>
<p>what would it take to build an ImageNet for SLAM?<br>
What would it take to build DeepSLAM?</p>
</blockquote>
<p>由于SLAM领域的真实数据往往无法获得很好的标注，而仿真数据无法囊括现实中的所有变化，所以可能引起domain adaptation issues和过拟合。所以用data-driven的深度学习方法去解决SLAM问题尚未解决。</p>
<p>作者提到了两个点，首先利用预测图像的DCN去估计ego-motion是可能得，作者没有使用直接用图像估计6DoF位姿的监督方法，而是更关注geometric consistency；其次作者发现对于SLAM系统来说，预测和对齐关键点已经足够去解算pose，那么就不用去预测整幅图像了，直接估计homography足以满足需求。</p>
<h2 id="method"><em>Method</em></h2>
<h3 id="overview">overview</h3>
<figure data-type="image" tabindex="1"><img src="https://jinyu-m.github.io/post-images/1604541682692.png" alt="" loading="lazy"></figure>
<h3 id="magicpoint">MagicPoint</h3>
<p>作者设计MagicPoint的motivation就是认为hand-crafted detector需要过多的经验和技巧，往往无法cover所有的干扰，所以就直接用DCN去估计pixel-level的显著性，提取图像关键点。</p>
<figure data-type="image" tabindex="2"><img src="https://jinyu-m.github.io/post-images/1604541717680.png" alt="" loading="lazy"></figure>
<p>结构类似于VGG。输入一个图像，得到一个同等分辨率的point response image，输出的每个pixel的值代表原图中这个位置是角点的概率。但是直接用encoder下采样-decoder上采样的结构恢复分辨率很耗算力，所以作者用网络得到了1/8大小的feature map，维度是65维（65个通道），这65个通道对应原图中不重叠的8x8的区域即一个dustbin通道（用于表示该8x8区域内无关键点），最后reshape到原本分辨率，这样decoder就没有参数了。</p>
<p>训练时使用OpenCV作了一批虚拟的几何体，几何体的角点可以直接得到，然后加入噪声、光照变化等进行数据增强。训练时对feature map上每个cell计算cross-entropy loss。</p>
<h3 id="magicwarp">MagicWarp</h3>
<p>MagicWarp输入一对图像的关键点，然后估计homography。比如两幅120x160的图像输入MagicPoint，分别得到65x15x20的feature map。输入MagicWarp后，先从channel维度上进行concatenation，得到130x15x20的feature map，然后经过一个VGG型的encoder，再通过全连接层降维，得到一个9-d的向量，恢复成3x3的homography矩阵。</p>
<figure data-type="image" tabindex="3"><img src="https://jinyu-m.github.io/post-images/1604541734864.png" alt="" loading="lazy"></figure>
<p>训练时，用虚拟数据采集虚拟三维几何体的图像，来获得训练数据，计算loss时，用估计的homography将图1的point投影到图2，然后计算投影误差，用L2-distance作为loss。</p>
<figure data-type="image" tabindex="4"><img src="https://jinyu-m.github.io/post-images/1604541741188.png" alt="" loading="lazy"></figure>
<h2 id="一些看法"><em>一些看法</em></h2>
<p>MagicPoint学习了如何检测corner，基本取决于annotated data中keypoint的标注位置。比较有意思的点在于非参数上采样过程，depth-to-space的处理方法很有借鉴意义。后续SuperPoint也采用了这样上采样的方式，在recover resolution的同时参数也比较少。</p>
<hr>
<h1 id="superpoint-magic-leap-pdf-official-code-society-code">SuperPoint (Magic Leap) <a href="https://arxiv.org/abs/1712.07629.pdf">pdf</a> <a href="https://github.com/magicleap/SuperPointPretrainedNetwork">official code</a> <a href="https://github.com/rpautrat/SuperPoint">society code</a></h1>
<h2 id="abstract-2"><em>Abstract</em></h2>
<p>作者在MagicPoint的基础上增加了提取descriptor的部分，提出了homographic adaptation的数据增强方法，用来训练detector的repeatability，并且使得训练数据可以从虚拟的仿真数据拓展到MS-COCO等真实数据。</p>
<h2 id="introduction-2"><em>Introduction</em></h2>
<p>作者认为deep feature训练的关键在于带有标签的数据，但是人工标注的数据中，关键点往往是ill-defined，所以作者提出自监督方法训练，用网络本身去标注一批伪真值关键点，在此基础上进行训练，这样做，关键点更丰富，标注成本也更低。</p>
<figure data-type="image" tabindex="5"><img src="https://jinyu-m.github.io/post-images/1604541876168.png" alt="" loading="lazy"></figure>
<p>第一步，其实就是之前提到的训练MagicPoint，先构建了一个仿真数据集Synthetic Shapes，训练了MagicPoint(b)。虽然之前的论文提到MagicPoint在应对各种干扰时重复率和准确率都很高，但是它丢失了一些潜在的关键点，为了解决这个问题，作者用Homographic Adaption去增强了MagicPoint标注的真实图像，得到了一个更符合预期的真实数据(b)，并用此去训练一个新的网络SuperPoint(c).</p>
<h2 id="architecture"><em>Architecture</em></h2>
<figure data-type="image" tabindex="6"><img src="https://jinyu-m.github.io/post-images/1604541894356.png" alt="" loading="lazy"></figure>
<p>SuperPoint由一个共享参数的encoder和两个task-specific decoders构成，采用vgg结构，图像(H x W)通过encoder，得到一个1/8大小(Hc x Wc)的feature map。</p>
<p>在<strong>interest point decoder</strong>中，网络依旧延续MagicPoint的做法，采用非参数的上采样过程，feature map通过head降维到65 x Hc x Wc维，分别代表原图中与之对应的8x8区域内每个点是关键点的概率以及一个dustbin通道，dustbin用以表示该8x8区域内无关键点。</p>
<p>在<strong>descriptor decoder</strong>中，网络先提取了Hc x Wc的semi-dense descriptor，每个descriptor代表与之对应的8x8区域内关键点的256-d descriptor（根据interest point detector，每8x8区域内只可能存在1/0个关键点），然后采用bi-cubic插值恢复到原分辨率。</p>
<h2 id="loss"><em>Loss</em></h2>
<p>训练interest point detector依旧采用对每个cell计算cross-entropy loss的方法：</p>
<figure data-type="image" tabindex="7"><img src="https://jinyu-m.github.io/post-images/1604542024924.png" alt="" loading="lazy"></figure>
<p>为了使这部分Lp降低，需要让Y中为1的位置（即该点为关键点）在X中有较大的值，即增大该点为关键点的概率。</p>
<p>训练descriptor extractor时，需要先找到匹配的点，然后用匹配点的descriptor来计算loss，所以先找判断图1(h,w)和图2(h',w')是否是一组匹配点：</p>
<figure data-type="image" tabindex="8"><img src="https://jinyu-m.github.io/post-images/1604542034183.png" alt="" loading="lazy"></figure>
<p>p是cell的中心位置，H是真值homography，所以上式就是判断两个cell在原图中中心是否是符合真值homography的，如果是，则这两个位置时一对匹配点，可以计算它们descriptor的距离了：</p>
<figure data-type="image" tabindex="9"><img src="https://jinyu-m.github.io/post-images/1604542039512.png" alt="" loading="lazy"></figure>
<p>上式中当图1和图2中两个点是匹配点时，s=1，则两个点的descriptor之间的cosine距离应该越大越好；而当两个点不匹配时，s=0，两个点的descriptor间的cosine距离越小越好。此处作者采用了hinge loss。</p>
<p>综上，SuperPoint训练使用的loss：</p>
<figure data-type="image" tabindex="10"><img src="https://jinyu-m.github.io/post-images/1604542045657.png" alt="" loading="lazy"></figure>
<p>分别计算图1和图2与真值图像的interest point loss，再计算图1与图2间的descriptor loss。</p>
<h2 id="training"><em>Training</em></h2>
<p>作者先训练了SuperPoint中提取关键点的detector pathway，其实就是MagicPoint，发现在虚拟数据集上MP表现很好，在真实数据中，当场景中有大量角点时，效果很好，但是在自然场景中，MP效果不如传统特征，所以作者提出<strong>用自监督方法在真实场景中训练网络</strong>，即Homographic Adaptation。</p>
<h2 id="homographic-adaptation"><em>Homographic Adaptation</em></h2>
<figure data-type="image" tabindex="11"><img src="https://jinyu-m.github.io/post-images/1604542062673.png" alt="" loading="lazy"></figure>
<p>可通过iterative homographic adaptation来提升效果。100次random homography效果较好。</p>
<h2 id="一些见解"><em>一些见解</em></h2>
<p>作为MagicPoint的升级版，SuperPoint我感觉其实是作者发现了MagicPoint只是单纯的去学习检测人工标注的那些点，比较局限，所以提出了homographic adaptation去进一步提升自己。并且加入了descriptor decoder，让整个系统更完整了。但是对比后续出现的特征，SuperPoint特征在训练时依旧采用监督的方法去训练detector，导致效果有待提升。在我的试验中，Bag of SuperPoint会提升loop closure的表现，但是用于SLAM系统（ORB-SLAM2）时，SuperPoint从一幅图像提取的特征过少，可能无法满足SLAM初始化的要求。</p>
<hr>
<h1 id="d2-net-pdf-code">D2-net <a href="https://arxiv.org/abs/1905.03561.pdf">pdf</a> <a href="https://github.com/mihaidusmanu/d2-net">code</a></h1>
<h2 id="abstract-3"><em>Abstract</em></h2>
<p>D2-net的主要在于提出了detect-and-describe的特征提取方法，不再是传统的detect-then-describe方法。作者认为从高层语义信息（CNN的高层conv输出的feature map）中提取的关键点位置要比从低层结构信息中提取的更稳定一些。detector和descriptor的参数实现了完全的共享。</p>
<h2 id="method-2"><em>Method</em></h2>
<p>D2的detector和descriptor是基于相同的feature map获取的。输入图像通过一个前向网络，得到C x H x W feature map，被视为得到了H x W 个C维的稠密局部特征。</p>
<figure data-type="image" tabindex="12"><img src="https://jinyu-m.github.io/post-images/1604543214624.png" alt="" loading="lazy"></figure>
<h2 id="hard-feature-detectiontest"><em>Hard feature detection(test)</em></h2>
<p>由于D2得到feature map有很多层，每一层都可以作为一个detector去检测局部最大值进而提取local feature，所以在提取特征时，D2约定（i，j）为一个特征点当且仅当在该点具有最大值的那个detector中，该点是一个局部最大值：</p>
<figure data-type="image" tabindex="13"><img src="https://jinyu-m.github.io/post-images/1604543229447.png" alt="" loading="lazy"></figure>
<p>直观地来讲，就是对于每个点，我们需要先找到该点对应C个detector中最显著的那个detector，然后验证在该detector中，当前点是否是局部最大的。</p>
<h2 id="soft-feature-detectiontraining"><em>Soft feature detection(training)</em></h2>
<p>但是上述detection方法是不可微的，所有无法用BP进行训练，为了实现end-to-end训练，作者soften了上述detection的方法。</p>
<p>首先soften筛选最显著detector的部分，计算当前detector的ratio-to-max用以表示其显著性</p>
<figure data-type="image" tabindex="14"><img src="https://jinyu-m.github.io/post-images/1604543241393.png" alt="" loading="lazy"></figure>
<p>其次soften计算局部最优值的部分，计算了9邻域内某点的soft local-max占比</p>
<figure data-type="image" tabindex="15"><img src="https://jinyu-m.github.io/post-images/1604543248965.png" alt="" loading="lazy"></figure>
<p>最后，综合两部分的分数，取最大值，并做image-level normalization得到一个用来表征像素是特征点的概率的score map。</p>
<h2 id="multiscale-detection"><em>Multiscale detection</em></h2>
<p>为了获取具有更强尺度不变性的特征，D2使用图像金字塔，在测试阶段，将图像分别缩放至0.5,1,2倍，输入D2，得到feature map，并将之前由低分辨率图像获得的feature map插值放大到当前分辨率，与当前feature map相加，获得更稳定的feature map，在此map上进行detection，之前提取的关键点也被上采样（最近邻）到当前尺度，纳入提取的特征中。</p>
<h2 id="data"><em>Data</em></h2>
<p>D2用megadepth数据集进行训练，megadepth提供了同一场景不同视角、光照、设备下的照片，以及深度信息，每个场景由COLMAP进行建图，由此获得2d-3d特征点的对应信息，利用sfm提供的信息，我们可以计算同一场景下两幅图像的overlap，在训练中，D2使用overlap&gt;0.5的图像对，并用depth信息进行验证，去除被遮挡的像素。</p>
<h2 id="loss-2"><em>Loss</em></h2>
<p>为了提升descriptor的区分度，需要让对应点的descriptor距离较小，非对应点的descriptor距离较大，所以D2使用了triplet margin loss。对于图1和图2中一对匹配点A和B，positive descriptor distance=</p>
<figure data-type="image" tabindex="16"><img src="https://jinyu-m.github.io/post-images/1604543266447.png" alt="" loading="lazy"></figure>
<p>在计算negative descriptor distance时，先挑选hardest negatives：</p>
<figure data-type="image" tabindex="17"><img src="https://jinyu-m.github.io/post-images/1604543274031.png" alt="" loading="lazy"></figure>
<p>直观理解，N1为图1中位于A的邻域之外，与B最相似的点。N2同理。</p>
<p>然后就可以分别计算A与N2，B与N1的descriptor距离，得到negative descriptor distance</p>
<figure data-type="image" tabindex="18"><img src="https://jinyu-m.github.io/post-images/1604543283391.png" alt="" loading="lazy"></figure>
<p>最后，triplet margin loss如下：</p>
<figure data-type="image" tabindex="19"><img src="https://jinyu-m.github.io/post-images/1604543289679.png" alt="" loading="lazy"></figure>
<p>通过该loss可以让descriptor的distinctiveness提升，而为了挑选去更具重复性的特征，D2在triple margin loss前加了一个权重</p>
<figure data-type="image" tabindex="20"><img src="https://jinyu-m.github.io/post-images/1604543298015.png" alt="" loading="lazy"></figure>
<p>这样的话，为了让loss降低，网络需要学习去提取区分度更高（m更小）并且可重复性更好（权重更大）的点，并且优化提取的descriptor。</p>
<h2 id="training-test"><em>Training &amp; Test</em></h2>
<p>D2采用了VGG-16网络模型（~conv4_3），加载imagenet预训练模型即可提取特征，如果进行finetune只需训练最后一层。在测试时，最后一个max-pooling改为average-pooling，并且stride改为1（不降低分辨率），conv4_1到conv4_3使用空洞卷积，这样得到的feature map是1/4大小的，D2使用SIFT中的local refinement方法去修正关键点位置，descriptor被双线性插值到矫正后的位置。</p>
<h2 id="evaluation"><em>Evaluation</em></h2>
<figure data-type="image" tabindex="21"><img src="https://jinyu-m.github.io/post-images/1604544099886.png" alt="" loading="lazy"></figure>
<p>在HPatches上，D2表现较差，threshold小于6px时的MMA很低。D2提取的特征较多，匹配数量也较多。在camera localization和3D reconstruction实验中效果较好。</p>
<h2 id="一些见解-2"><em>一些见解</em></h2>
<p>D2在strict matching上的表现较差，但是在localization和reconstruction任务上却表现不错。这其中的原因值得思考，我们一般做slam时要求特征更快更准，“更准”的要求真的必要么？</p>
<p>在inference的时候，网络的forward速度很快，~x ms，但是detection和恢复position误差的部分都需要~x00 ms。感觉可以从detection的方法上改进一下。</p>
<p>在我的试验中，发现D2其实提取的soft detection score还是很关注纹理复杂的区域的，但是这些区域很可能是dynamics，所以加入语义的方法进行筛选可能是个点。</p>
<p>D2定位精度差的原因，我觉得是因为它是在1/8的feature map上进行训练，在1/4的feature map上进行inference，所以直接插值到原分辨率造成了这种差异，因为在hpatches上threshold大于6px时D2的效果还是不错。</p>
<p>D2在训练时有考虑repeatable（因为直接用correspondence训练的）和disciminative，但是我觉得这种用triplets或者quadruplets去采样anchor、positive和negative会不会造成其实对disciminative的提升不大呢？</p>
<hr>
<h1 id="r2d2-pdf-code">R2D2 <a href="http://arxiv.org/abs/1906.06195">pdf</a> <a href="https://github.com/naver/r2d2">code</a></h1>
<h2 id="abstract-4"><em>Abstract</em></h2>
<p>作者在这篇工作中，提出一个观点：</p>
<blockquote>
<p>In this work, we argue that salient regions are not necessarily discriminative, and therefore an harm the performance of the description. Furthermore, we claim that descriptors should be learned only in regions for which matching can be performed with high confidence.</p>
</blockquote>
<p>简单来说，就是之前的训练detector的方法，都是更关注检测出的特征是否repeative，这样的特征可能不够discriminative，比如重复性的纹理。所以作者认为，这样的训练方法有弊端。并且由于提取的salient region不够discriminative，所以descriptor的训练也不够完善。所以这篇工作中，作者要提取sparse，repeative and disciminative特征，依旧使用detect-and-descibe的提取方法。</p>
<h2 id="introduction-3"><em>Introduction</em></h2>
<figure data-type="image" tabindex="22"><img src="https://jinyu-m.github.io/post-images/1604543612648.png" alt="" loading="lazy"></figure>
<p>作者先更详细直观地阐述了一下motivation，就像上面这两幅示例图。第一幅图中，对于detector来说，只有黑三角形附近的区域是有利于提取keypoint的，但是所有包含该三角形的patch都可以提取同等可靠的descriptor，所以匹配的时候会有误差。第二幅图中，对于detector，所有棋盘网格的角点都可以提取出同等可靠的keypoint，但是它们都不利于提取descriptor，因为完全重复，匹配的时候会出现混淆。</p>
<p>所以，在这篇论文，作者认为detection和description是不可分割的，要一起训练（其实就是detect-and-descibe），并且提取的特征不关要repeatable还需要reliable for matching（感觉就是discrimative）。所以R2D2会分别根据basenet输出的feature map得到两张repeatability confidence map和reliability confidence map，然后综合两张map提取特征。</p>
<h2 id="methods"><em>Methods</em></h2>
<figure data-type="image" tabindex="23"><img src="https://jinyu-m.github.io/post-images/1604543624200.png" alt="" loading="lazy"></figure>
<p>R2D2采用全卷积网络结构，输入H x W大小的图像，输出三部分：第一部分D x H x W feature map X，视作H x W个D维局部特征，每个像素对应一个局部特征；第二部分是一个H x W heatmap S，每个位置上的值代表该点特征的sparse和repeatable，值在[0,1]之间，为了获得稀疏的特征，只提取S中局部最大值作为特征；第三部分是H x W heatmap R，对应特征的reliability或者说disciminativeness.</p>
<p>网络的backbone选用L2-net（不降低分辨率），但是将最后一个8x8的卷积换做3个2x2卷积，来减少参数。D=128。为了获得S和R，在backbone后接了两个1x1卷积+softmax。</p>
<h2 id="loss-3"><em>Loss</em></h2>
<h3 id="repeatability">repeatability</h3>
<p>首先训练特征的repeatability，作者认为</p>
<blockquote>
<p>In fact, using supervision essentially boils down in this case to copying an existing detector rather than discovering better and easier keypoints.</p>
</blockquote>
<p>就是用监督学习的训练方法，只是在学习那些现成的detector的检测策略（这个意义上讲，superpoint其实也是这样的，只不过通过homographic adaptation进行了一个data augmentation，去提升性能）。所以作者希望直接训练S，让其跟随图像变换而一起变换。</p>
<p>假设图1，图2，当图像是真实图像时，用optical flow或stereo matching的方法去获得两幅图像中像素级的对应关系U，当图像是虚拟的仿真图像时，那么U可以直接获得了。分别获得两幅图像的S1和S2，利用U将S2对应到S2U。如果S是covariant to transformations，那么S1和S2U应该是一致的。</p>
<p>所以，可以直接对S1和S2U求取cosine相似度，相似度越大，说明S的表现越好，但是warp后可能会出现occlusions、warp artifacts or border effects，所以作者用了一个局部的cosine相似度，求取多个patch的cosine相似度：</p>
<figure data-type="image" tabindex="24"><img src="https://jinyu-m.github.io/post-images/1604543638431.png" alt="" loading="lazy"></figure>
<p>Lcosine只能保证S1和S2U相似，但是容易导致S1和S2U变成常值。由于最后使用S是要挑选local maxima，所以还需要让S的局部峰值变大：</p>
<figure data-type="image" tabindex="25"><img src="https://jinyu-m.github.io/post-images/1604543644970.png" alt="" loading="lazy"></figure>
<p>最后，训练repeatability的loss就是以上两部分的加权：</p>
<figure data-type="image" tabindex="26"><img src="https://jinyu-m.github.io/post-images/1604543649872.png" alt="" loading="lazy"></figure>
<h3 id="reliability-ie-discriminativeness">Reliability, i.e., Discriminativeness</h3>
<p>这部分是为了让具有得到一个可以度量discriminative的score map，让具有discriminative descriptor的区域具有较大的可信度。</p>
<p>使用Average Precision Loss进行训练descriptor，就是给一对ground-truth batch，计算batch1中每个descriptor与batch2中每个des之间的距离，然后计算batch中每个query的AP loss**(?)**，用下面公式进行训练：</p>
<figure data-type="image" tabindex="27"><img src="https://jinyu-m.github.io/post-images/1604543659256.png" alt="" loading="lazy"></figure>
<p>这篇论文中也用到了AP loss，区别在于原本AP loss使用标准的keypoint detector去提取ground-truth batch，而在这里根据前文可以知道，提供了U，所以直接用U就可以获得ground-truth batch了。</p>
<p>在这一部分，作者还提出，想要提取利于匹配的特征，不光要考虑图像纹理的丰富度，还要考虑其是否discriminative。所以作者用R去筛选discriminative region中的特征，只有这部分特征会对网络训练产生影响。</p>
<figure data-type="image" tabindex="28"><img src="https://jinyu-m.github.io/post-images/1604543707448.png" alt="" loading="lazy"></figure>
<p>使用这种loss，为了使loss减小，当AP(i,j)小于k时，即该点descriptor不够discriminative，那么Rij应当为0,；当该点descriptor足够discriminative时，Rij应当为1。</p>
<h2 id="test"><em>Test</em></h2>
<p>在测试时，也采用了图像金字塔去获取更丰富的特征，从原分辨率开始，逐渐下采样，直到图像小于128px。每次从图像中利用S的局部最大值提取特征，保存。最后从所有保存的特征中，根据SR挑选top-K特征。</p>
<h2 id="training-2"><em>Training</em></h2>
<p>R2D2需要获得图像间的ground-truth correspondence。所以作者提出两种方法，一种就是常规的图2是由图1经过一种确定的transformation变换而来的；另一种，是作者自己提出一种pipeline，区别于之前用完全利用sfm获得dense correspondence（感觉在说D2...），作者先用sfm生成图像的3D点与6DoF位姿（sparse），对于sufficient overlap图像，用sfm提供的2D correspondence计算F matrix（作者发现这比直接用图像位姿去算要更可靠），然后用EpicFlow获得高质量的dense correspondence，作者在DeepMatching中加入epipolar constraint去增强方法，在EpicFlow的第一步获得了semi-dense correspondence。但是光流法可能无法应对有遮挡的情况，所以对于DeepMatching的输出，作者计算了一个connected consistent neighbors的图，只保留属于较大（至少有20个matches）connected component的matches，然后用一个thresholded kernel density estimator在验证后的matches中估计一个mask，作为optical flow可信度的度量。</p>
<h2 id="data-2"><em>Data</em></h2>
<p>Oxford，Paris，Aachen Day-Night.</p>
<h2 id="results"><em>Results</em></h2>
<figure data-type="image" tabindex="29"><img src="https://jinyu-m.github.io/post-images/1604543745556.png" alt="" loading="lazy"></figure>
<p>这张图很直观的表现出r2d2的优点，对于repeatability来说（第2行图），天空是可重复性很高的，但是对于特征来说，由于天空有大量重复纹理或无纹理，所以不利于区分，所以其上的特征reliability很低，r2d2综合考虑了这两点，所以提取的特征比较好。</p>
<figure data-type="image" tabindex="30"><img src="https://jinyu-m.github.io/post-images/1604544063401.png" alt="" loading="lazy"></figure>
<p>在hseq上效果也很好。</p>
<h2 id="一些见解-3"><em>一些见解</em></h2>
<p>r2d2很明确的定义了特征的两种特性，repeatability和reliability，其中reliability就是discriminativeness。</p>
<p>目前bag of others中据说效果很好的一种特征了，很显式的将特征的repeatable和disciminative纳入loss中，让网络去学习。</p>
<p>完全没有人工标记的特征点了，所以是网络自己去学习判断和提取特征——superpoint</p>
<p>在原分辨率的feature map上提取特征，定位准确度高了——D2</p>
<p>考虑到了local maxima可能并不全是利于匹配的特征，要考虑disciminative——D2+SuperPoint</p>
<hr>
<h1 id="sekd-pdf-code">SEKD <a href="http://arxiv.org/abs/2006.05077">pdf</a> <a href="https://github.com/aliyun/Self-Evolving-Keypoint-Demo">code</a></h1>
<h2 id="abstract-5"><em>Abstract</em></h2>
<p>论文提出，现存的一些特征提取方法（hand-crafted or learnt）都没有考虑到detector和descriptor之间的相互促进作用，所以导致效果或多或少不尽人意。所以这篇文章，其实是设计了一种自监督训练框架，强调repeatability和reliability，用完全无标注的自然图像去学习特征。</p>
<h2 id="introduction-4"><em>Introduction</em></h2>
<p>作者更加细化的分别定义了detector和descriptor的repeatability和reliability：</p>
<figure data-type="image" tabindex="31"><img src="https://jinyu-m.github.io/post-images/1604544171601.png" alt="" loading="lazy"></figure>
<p>总的来说就是两大特性，细分为四部分：（1）Repeatability：detector的repeatability体现在如果两幅图像描述了同一场景，那么在图1中“看到”的一个keypoint在图2中也应该可以看到；descriptor的repeatability体现在相同真实位置的关键点在不同图像中应该是invariant；（2）Reliability（其实可以理解为我们常说的disciminativeness）：detector的reliability体现在给定描述子的计算方法，一个detected keypoint应该可靠的区别于其他点，直白点说就是应该落在利于分辨的区域，避开重复性纹理区域；descriptor的reliability体现在给定了detection方法，计算出的描述子应该足够区分这些detected keypoints。</p>
<p>思考一下上面的这些特性，其实repeatability特性是detector和descriptor自己的inherent property，而reliability则体现了detector与descriptor之间的interactive property。</p>
<p>这篇论文别出心裁，不一起训练detector和descriptor（SuperPoint是先训detector后训descriptor，D2和R2D2是一起训），而是采用了一种iterative training strategy。利用上面说的inherent and interactive property，去直到训练。</p>
<p>简单的说，找出所有具有reliable descriptor的keypoints（descriptor repeatability），作为ground-truth去训练detector（detector reliability），用优化后的detector去检测keypoints（detector repeatability），基于这些keypoints训练descriptor（descriptor reliability）。重复这一过程，直到模型收敛。这就是self-evolving framework。整个训练过程不需要带有标注的数据。</p>
<p>（其实，我感觉和SuperPoint中提到的Iterative Homographic Adaptation有些相似，不过SEKD将这个流程变为一个end-to-end的训练过程，从零开始训练了）</p>
<h2 id="architecture-2"><em>Architecture</em></h2>
<figure data-type="image" tabindex="32"><img src="https://jinyu-m.github.io/post-images/1604544204468.png" alt="" loading="lazy"></figure>
<p>SEKD采用了类似于SuperPoint的结构，backbone由1个卷积和9个ResNet_v2模块，得到1/4大小的feature map。detector branch由2个deconv和1个softmax构成，输出2 x H x W的map P，代表keypoint probability，为了提升定位精度，有两个来自低层feature map的shortcut。descriptor branch由1个ResNet_v2模块和1个bi_linear上采样层构成，输出C-d描述子。</p>
<h2 id="self-evolving"><em>Self-Evolving !</em></h2>
<figure data-type="image" tabindex="33"><img src="https://jinyu-m.github.io/post-images/1604566729992.png" alt="" loading="lazy"></figure>
<p>在训练过程中，网络利用两方面的监督：（1）关键点的选取，有可靠descriptor的point被认为是keypoint；（2）不同图像间的keypoints correspondence，这个通过用一张图像，经过affine transformation获得匹配图像，因此correspondence也可以直接获得。</p>
<p>训练的流程基本分为四步：</p>
<p>1.用detector branch得到keypoint probability map P，利用NMS筛选keypoint；</p>
<p>2.在这些keypoint上，通过增强descriptor的repeatability和reliability来更新descriptor branch；</p>
<p>3.计算keypoint，具有reliable（repeatable and distinct） descriptor的point被作为keypoints;</p>
<p>4.在这些新的keypoint上，根据detector的repeatability和reliability来更新detector branch。</p>
<h3 id="1detect-keypoints-using-detector">1.Detect Keypoints using Detector</h3>
<figure data-type="image" tabindex="34"><img src="https://jinyu-m.github.io/post-images/1604566746753.png" alt="" loading="lazy"></figure>
<p>具有较高相应的点被视为可能的keypoint，经过NMS，每张图像可以获得1000个keypoint。但是由于不同图像条件下，可能没法取到一样的keypoint，所以作者采用了affine adaption方法，即对于原始图像进行random affine transformation和color jitter，获得新的图像后经过网络，获得不同图像条件下的P，最后映射回原图，取平均，得到最后的P.</p>
<h3 id="2update-keypoint-descriptor">2.Update Keypoint Descriptor</h3>
<p>根据上一节，获得了一张图像I中的keypoints Q，对I和Q进行random affine transformation和color jitter H，得到I<sup>和Q</sup>，并且可以获得特征的匹配关系&lt;Q,Q^&gt;，那么根据descriptor repeatability，匹配特征的des应该很靠近，根据descriptor reliability，不匹配的特征应该有很好的区分度。所以作者使用了triplet loss with hardest example mining去训练descriptor。</p>
<figure data-type="image" tabindex="35"><img src="https://jinyu-m.github.io/post-images/1604566756477.png" alt="" loading="lazy"></figure>
<p>除此之外，由于网络使用共享参数的backbone，所以为了保证detection的结果不会变化，作者还加入了一个损失函数：</p>
<figure data-type="image" tabindex="36"><img src="https://jinyu-m.github.io/post-images/1604566764397.png" alt="" loading="lazy"></figure>
<p>其中N’表示更新后的N。所以，用于更新descriptor的总loss为：</p>
<figure data-type="image" tabindex="37"><img src="https://jinyu-m.github.io/post-images/1604566770713.png" alt="" loading="lazy"></figure>
<h3 id="3compute-keypoints-via-descriptor">3.Compute Keypoints via Descriptor</h3>
<p>更新了descriptor后，下一步是要从descriptor map中提取keypoint。特征的reliability可从repeatability和distinctiveness两方面度量。对于repeatability：</p>
<figure data-type="image" tabindex="38"><img src="https://jinyu-m.github.io/post-images/1604566777144.png" alt="" loading="lazy"></figure>
<p>D越低，说明descriptor在相同位置上更靠近，repeatability更好。而对于distinctiveness：</p>
<figure data-type="image" tabindex="39"><img src="https://jinyu-m.github.io/post-images/1604566782560.png" alt="" loading="lazy"></figure>
<p>D‘越大，说明descriptor在不同位置的差异越大，distinctiveness更好。所以综合两点，特征的reliability定义为：</p>
<figure data-type="image" tabindex="40"><img src="https://jinyu-m.github.io/post-images/1604566791572.png" alt="" loading="lazy"></figure>
<p>R越大，说明特征更reliable。</p>
<p>由于匹配的图像对是用affine transformation获得的，所以图像中可能一些点没有对应的R，所以这里依然采用了之前所用的affine adaption方法来获得一张average R。</p>
<p>另外，计算D‘的计算量很大，所以作者在邻域内计算D'：</p>
<figure data-type="image" tabindex="41"><img src="https://jinyu-m.github.io/post-images/1604566800589.png" alt="" loading="lazy"></figure>
<p>在实验中，作者在1/4，1倍分辨率的descriptor map上分别计算R，然后将两个map融合，一起使用，以获得足够精细的R。</p>
<h3 id="4update-keypoint-detector">4.Update Keypoint detector</h3>
<p>根据descriptor计算出的keypoint可以看作ground-truth对detector进行训练，作者使用了focal loss：</p>
<figure data-type="image" tabindex="42"><img src="https://jinyu-m.github.io/post-images/1604566821435.png" alt="" loading="lazy"></figure>
<p>同时，为了减小匹配图像对上detection结果的差异，作者加入了：</p>
<figure data-type="image" tabindex="43"><img src="https://jinyu-m.github.io/post-images/1604566826991.png" alt="" loading="lazy"></figure>
<p>来训练detector的repeatability。并且还需要保证descriptor在这期间不受干扰，所以加入了：</p>
<figure data-type="image" tabindex="44"><img src="https://jinyu-m.github.io/post-images/1604566831492.png" alt="" loading="lazy"></figure>
<p>最后综合三部分，训练detector的loss为：</p>
<figure data-type="image" tabindex="45"><img src="https://jinyu-m.github.io/post-images/1604566836368.png" alt="" loading="lazy"></figure>
<h2 id="training-3"><em>Training</em></h2>
<p>特征在MS COCO验证集上完成训练。</p>
<p>训练进行了5个iteration，每个iteration中分别训练detector和descriptor20个epoches</p>
<h2 id="model-size"><em>Model Size</em></h2>
<figure data-type="image" tabindex="46"><img src="https://jinyu-m.github.io/post-images/1604566842806.png" alt="" loading="lazy"></figure>
<h2 id="performance"><em>Performance</em></h2>
<figure data-type="image" tabindex="47"><img src="https://jinyu-m.github.io/post-images/1604566848258.png" alt="" loading="lazy"></figure>
<hr>
<h1 id="l2-net-2017-pdf-code">L2-Net (2017) <a href="https://ieeexplore.ieee.org/document/8100132">pdf</a> <a href="https://github.com/yuruntian/L2-Net">code</a></h1>
<h2 id="abstract-6"><em>Abstract</em></h2>
<p>这篇论文提出了一种在欧拉空间中表现很好的CNN特征，突出点有四点：（1）提出了一种渐进的采样策略，使得网络可以在很少epoch内获得数以亿计的训练样本；（2）重视descriptor之间的相对距离；（3）对中间的feature map有格外的监督；（4）考虑des的compactness。</p>
<h2 id="architecture-3"><em>Architecture</em></h2>
<figure data-type="image" tabindex="48"><img src="https://jinyu-m.github.io/post-images/1604566899195.png" alt="" loading="lazy"></figure>
<p>网络结构如上图，在BN层中，作者设置权重为1，方差为0，不进行更新。在输出层，作者使用了local response normalization layer（LRN）来输出单位des。L2-Net将32 x 32的patch转变为128维的des。作者也使用了central-surround L2-Net，将两个L2-Net concat，左边的网络输入的是原始输入，右边的网络输入的是原本patch经过crop和resize后的中心部分（据说是可以处理scale不变性）。</p>
<h2 id="training-data"><em>Training data</em></h2>
<p>L2-Net用Hpatches和Brown数据集进行训练，这两个数据集都提供了matched pairs。</p>
<p>在加载训练数据时，从P个3D点中挑选p1个点，然后从P-p1中挑选p2个点，得到了p(p1+p2)个点，对每个p，随机获取一个匹配的patch，这样就获得了2p个训练数据作为网络的输入，记为X，X是32 x 32 x 2p维的。网路的输出记为Y，Y是128 x 2p维的。由于网络的输出经过了normalization，所以可以定义距离矩阵<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>D</mi><mo>=</mo><mi>s</mi><mi>q</mi><mi>r</mi><mi>t</mi><mo>(</mo><mn>2</mn><mi>x</mi><mo>(</mo><mn>1</mn><mo>−</mo><msubsup><mi>Y</mi><mn>1</mn><mi>T</mi></msubsup><msub><mi>Y</mi><mn>2</mn></msub><mo>)</mo><mo>)</mo></mrow><annotation encoding="application/x-tex">D=sqrt(2 x (1 - Y_1^T Y_2))</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">D</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault">s</span><span class="mord mathdefault" style="margin-right:0.03588em;">q</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mord mathdefault">t</span><span class="mopen">(</span><span class="mord">2</span><span class="mord mathdefault">x</span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.0913309999999998em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.22222em;">Y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-2.4518920000000004em;margin-left:-0.22222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">T</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.24810799999999997em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.22222em;">Y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.22222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mclose">)</span></span></span></span>。</p>
<p>D中包含了p x p个pairs，对角线上的p个pair是positive matched pair，非对角线上的pair是negative pairs。<strong>(Q: 点都是随机取得，那在原本的p点中就可能会出现相互匹配的点，那么非对角线上的pair也不一定都是negative吧)</strong></p>
<h2 id="loss-function"><em>Loss function</em></h2>
<p>损失函数由三部分构成，第一部分，作者利用相对距离去约束匹配和非匹配的pair；第二部分，作者强调des的紧凑性，即des的各维信息之间应该没有相互关系；第三部分，作者对中间的feature map进行了约束。</p>
<h3 id="descriptor-similarity">descriptor similarity</h3>
<p>des之间的相互距离在pair是匹配的时候最小，所以体现在D中，就是对角线上的元素应当是行、列中最小的。定义行相似矩阵和列相似矩阵：</p>
<figure data-type="image" tabindex="49"><img src="https://jinyu-m.github.io/post-images/1604566957511.png" alt="" loading="lazy"></figure>
<p><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>S</mi><mi>c</mi></msup></mrow><annotation encoding="application/x-tex">S^c</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.664392em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">c</span></span></span></span></span></span></span></span></span></span></span>可以理解维<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>y</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">y_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>匹配到<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>y</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">y_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>的概率，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>S</mi><mi>r</mi></msup></mrow><annotation encoding="application/x-tex">S^r</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.664392em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">r</span></span></span></span></span></span></span></span></span></span></span>可以理解维<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>y</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">y_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>匹配到<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>y</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">y_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>的概率。为了让匹配的des之间距离减小，loss设计为：</p>
<figure data-type="image" tabindex="50"><img src="https://jinyu-m.github.io/post-images/1604566963223.png" alt="" loading="lazy"></figure>
<h3 id="descriptor-compactness">descriptor compactness</h3>
<p>作者发现过拟合问题是由于des各维度之间的correlation（我理解的是des出现了冗余）。所以作者加入了对des compactness的考虑。</p>
<p>作者设计了一个correlation matrix R：</p>
<figure data-type="image" tabindex="51"><img src="https://jinyu-m.github.io/post-images/1604566969526.png" alt="" loading="lazy"></figure>
<p>其中bi表示q个patch的des中第i维元素的集合，是个行向量。（我理解是对des的每一维调整均值后，计算cosine相似度，r=0，说明计算的两维des间正交，不相关）所以R的非对角线位置的元素需要靠近0。所以des compactness的loss为：</p>
<figure data-type="image" tabindex="52"><img src="https://jinyu-m.github.io/post-images/1604566974432.png" alt="" loading="lazy"></figure>
<p>如果加入了LRN后，每维数据的均值为0，所以Rs的计算可以简化为：</p>
<figure data-type="image" tabindex="53"><img src="https://jinyu-m.github.io/post-images/1604566979212.png" alt="" loading="lazy"></figure>
<h4 id="intermediate-feature-maps">Intermediate feature maps</h4>
<p>用E1的loss去计算网络中间的feature map上的similarity matrix G，然后构建了loss：</p>
<figure data-type="image" tabindex="54"><img src="https://jinyu-m.github.io/post-images/1604566984516.png" alt="" loading="lazy"></figure>
<p>作者称之为Discriminative Intermediate Feature maps (DIF)，并且发现在BN层后面加入DIF会提升效果，所以作者在第一个和最后一个BN层后计算了DIF。</p>
]]></content>
    </entry>
</feed>