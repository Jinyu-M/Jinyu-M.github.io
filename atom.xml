<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://jinyu-m.github.io</id>
    <title>年少万兜鍪</title>
    <updated>2021-03-11T06:42:42.478Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://jinyu-m.github.io"/>
    <link rel="self" href="https://jinyu-m.github.io/atom.xml"/>
    <subtitle>少年吔
尘世恰好，有诗有酒刚好吐槽</subtitle>
    <logo>https://jinyu-m.github.io/images/avatar.png</logo>
    <icon>https://jinyu-m.github.io/favicon.ico</icon>
    <rights>All rights reserved 2021, 年少万兜鍪</rights>
    <entry>
        <title type="html"><![CDATA[Place Recognition/Loop Closure Detection]]></title>
        <id>https://jinyu-m.github.io/post/traditional-place-recognition/</id>
        <link href="https://jinyu-m.github.io/post/traditional-place-recognition/">
        </link>
        <updated>2020-12-25T08:09:14.000Z</updated>
        <content type="html"><![CDATA[<h1 id="写在前面">写在前面</h1>
<p>这篇日志是自己在回环检测领域看过的一些论文，有离线训练词典的，有增量式构建词典的，不一而足。就我个人感觉而言，回环检测目前的趋势还是增量式检测在SLAM中的应用，当前的SLAM系统大多还停留在离线训练词典的阶段，但是在我的实验中，我发现词典训练存在太多先验经验和trick，导致词典对应不同场景的适应性较差。因此如何高效地检索，如何构建泛化性较强的词典，如何解决回环检测中感知混淆问题，是这个领域尚待解决的课题。</p>
<hr>
<h1 id="总结">总结</h1>
<h2 id="iros-2009-online-visual-vocabulary-for-robot-navigation-and-mapping">[IROS 2009] <strong>Online Visual Vocabulary for Robot Navigation and Mapping</strong></h2>
<p>这篇论文提出了一个很完整的增量式构建词典树的方法，利用特征跟踪获得基本单元，自下而上构建词典树，词典树的根节点为视觉单词，叶节点为基本单元，词典树（视觉单词）的数量由一个目标函数优化得到，无需人工干预，很新颖。词典的更新构成采用了增量式地更新，利用一些方法避免了重复计算。使用LDA对特征进行降维。应用场景为水下场景的SfM算法。</p>
<h2 id="tro-2012-automatic-visual-bag-of-words-for-online-robot-navigation-and-mapping">[TRO 2012] <strong>Automatic Visual Bag-of-Words for Online Robot Navigation and Mapping</strong></h2>
<p>这篇论文是在[OVV IROS 2009]的基础上拓展的期刊论文，在这篇论文中，作者对于词典的更新间隔进行了改进，不再是每隔m张图像更新一次词典，而是通过判断特征与单词的关联率来判断词典是否需要更新。并且，对于具有较少信息的分支，词典进行了剪枝，使得结构更加紧凑。</p>
<hr>
<h1 id="目录">目录</h1>
<p><ul class="markdownIt-TOC">
<li><a href="#%E5%86%99%E5%9C%A8%E5%89%8D%E9%9D%A2">写在前面</a></li>
<li><a href="#%E6%80%BB%E7%BB%93">总结</a>
<ul>
<li><a href="#iros-2009-online-visual-vocabulary-for-robot-navigation-and-mapping">[IROS 2009] <strong>Online Visual Vocabulary for Robot Navigation and Mapping</strong></a></li>
<li><a href="#tro-2012-automatic-visual-bag-of-words-for-online-robot-navigation-and-mapping">[TRO 2012] <strong>Automatic Visual Bag-of-Words for Online Robot Navigation and Mapping</strong></a></li>
</ul>
</li>
<li><a href="#%E7%9B%AE%E5%BD%95">目录</a></li>
<li><a href="#online-visual-vocabulary-for-robot-navigation-and-mapping-iros-2019-pdf">Online Visual Vocabulary for Robot Navigation and Mapping (IROS 2019) pdf</a>
<ul>
<li><a href="#abstract">Abstract</a></li>
<li><a href="#introduction">Introduction</a></li>
<li><a href="#visual-vocabulary">Visual Vocabulary</a>
<ul>
<li><a href="#vocabulary-building">Vocabulary Building</a></li>
<li><a href="#cluster-characterization">Cluster Characterization</a></li>
<li><a href="#cluster-merging">Cluster Merging</a></li>
<li><a href="#convergence-criterion">Convergence criterion</a></li>
<li><a href="#vocabulary-update">Vocabulary update</a></li>
<li><a href="#linear-discriminant-analysis-lda">Linear Discriminant Analysis (LDA)</a></li>
</ul>
</li>
<li><a href="#image-indexing">Image Indexing</a>
<ul>
<li><a href="#cluster-association">Cluster association</a></li>
<li><a href="#image-re-indexing">Image re-indexing</a></li>
<li><a href="#image-similarity">Image similarity</a></li>
<li><a href="#cross-over-detection">Cross-over detection</a></li>
</ul>
</li>
<li><a href="#experimental-results">Experimental Results</a></li>
</ul>
</li>
<li><a href="#automatic-visual-bag-of-words-for-online-robot-navigation-and-mapping-tro-2012-pdf">Automatic Visual Bag-of-Words for Online Robot Navigation and Mapping (TRO 2012) pdf</a>
<ul>
<li><a href="#abstract-2">Abstract</a></li>
<li><a href="#introduction-2">Introduction</a></li>
<li><a href="#visual-vocabulary-2">Visual Vocabulary</a>
<ul>
<li><a href="#agglomerative-clustering">Agglomerative clustering</a></li>
<li><a href="#vocabulary-building-2">Vocabulary building</a></li>
<li><a href="#cluster-characterization-2">Cluster characterization</a>
<ul>
<li><a href="#cluster-updating">Cluster updating</a></li>
</ul>
</li>
<li><a href="#cluster-merging-criterion">Cluster merging criterion</a></li>
<li><a href="#convergence-criterion-2">Convergence Criterion</a></li>
<li><a href="#adding-new-clusters">Adding New Clusters</a></li>
<li><a href="#linear-disciminant-analysis">Linear Disciminant Analysis</a></li>
<li><a href="#vocabulary-update-criterion">Vocabulary Update Criterion</a></li>
</ul>
</li>
<li><a href="#image-indexing-2">Image Indexing</a>
<ul>
<li><a href="#cluster-association-2">Cluster Association</a>
<ul>
<li><a href="#image-reindexing">Image Reindexing</a></li>
</ul>
</li>
<li><a href="#image-similarity-2">Image similarity</a></li>
</ul>
</li>
<li><a href="#increasing-vocabulary-efficiency">Increasing Vocabulary Efficiency</a></li>
<li><a href="#experiments">Experiments</a></li>
</ul>
</li>
<li><a href="#dbow-tro-pdf">DBoW (TRO) pdf</a>
<ul>
<li><a href="#introduction-3"><em>Introduction</em></a></li>
<li><a href="#image-database"><em>Image Database</em></a></li>
<li><a href="#loop-detection-algorithm"><em>Loop Detection Algorithm</em></a>
<ul>
<li><a href="#database-query">Database query</a></li>
<li><a href="#match-grouping">Match grouping</a></li>
<li><a href="#temporal-consistency">Temporal consistency</a></li>
<li><a href="#efficient-geometrical-consistency">Efficient geometrical consistency</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#fast-and-effective-visual-place-recognition-using-binary-codes-and-disparity-information-iros-2014-pdf">Fast and Effective Visual Place Recognition using Binary Codes and Disparity Information (IROS 2014) pdf</a>
<ul>
<li><a href="#abstract-3"><strong>Abstract</strong></a></li>
<li><a href="#introduction-4"><strong>Introduction</strong></a></li>
<li><a href="#binary-descriptor"><strong>Binary Descriptor</strong></a>
<ul>
<li><a href="#proposed-method"><strong>Proposed Method</strong></a>
<ul>
<li><a href="#binary-code-calculation"><strong>Binary code calculation</strong></a></li>
<li><a href="#binary-codes-matching"><strong>Binary codes matching</strong></a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><a href="#calc-pdf-code">CALC pdf code</a>
<ul>
<li><a href="#abstract-4"><em>Abstract</em></a></li>
<li><a href="#method"><em>Method</em></a></li>
<li><a href="#performance"><em>Performance</em></a></li>
<li><a href="#%E4%B8%80%E7%82%B9%E7%9C%8B%E6%B3%95">一点看法</a></li>
</ul>
</li>
</ul>
</p>
<hr>
<h1 id="online-visual-vocabulary-for-robot-navigation-and-mapping-iros-2019-pdf">Online Visual Vocabulary for Robot Navigation and Mapping (IROS 2019) <a href="http://eia.udg.edu/~rafa/papers/iros-2009.pdf">pdf</a></h1>
<h2 id="abstract">Abstract</h2>
<p>受到content-based image retrieval算法的启发，回环检测算法使用visual vocabularies来度量图像间的相似度。但是这类算法有两个缺陷：（1）他们需要很强的人工干预，即通过trial-and-error的方法来训练和调试参数，（2）他们只适合批处理数据，即所有数据在处理前都是已经获得的（应该是指算法只在见过的场景中表现良好）。因此，作者提出了一个算法，在线构建和更新vocabularies，来高效地表示场景中的图像，并且词典构建过程不需要人工干预。</p>
<h2 id="introduction">Introduction</h2>
<p>在这篇论文中，作者提出了一个增量式构建视觉词典的框架。该算法不需要人工干预，不需要关于环境的先验信息。在导航过程中，当视觉信息输入到系统中，系统会构建一个简化的词典。该词典会进行更新，以正确地对场景中出现的视觉信息建模。该词典使用一种考虑视觉数据的全局分布的方法来构建，提升了效率。并且，作者提出了一种新的用于特征-聚类之间的联合方法和图像检索方法，适合在线的检测。<br>
提出的方法被应用在水下导航和建图的SFM算法中，视觉词典被用于量化帧间的相似度，从而进行回环检测。<br>
<img src="https://jinyu-m.github.io/post-images/1615277597694.png" alt="" loading="lazy"></p>
<h2 id="visual-vocabulary">Visual Vocabulary</h2>
<p>当前sota的算法都处于一个off-line的阶段，这一阶段需要实现从场景中获取视觉特征。这些特征然后通过某种聚类方法被用于构建视觉词典。典型的off-line词典构建方法使用K-means，K-medians或者fixed-radius clustering方法，这些方法需要使用者去设置许多参数，比如聚类簇数。为一个最优的词典找到合适的参数是一项繁琐的任务，需要不同的试错。比如，一个拥有过多单词的词典不会有足够的抽象能力来检测图像间的相似度，反之，一个单词太少的词典将受到混淆，单词过于泛化导致无法区分。</p>
<blockquote>
<p>the adequate parameters for an optimum vocabulary is a tedious task which generally involves a trial and error approach. For example, a vocabulary with too many words would not have enough abstraction power to detect similarities between images. In contrast, a vocabulary with too few words would be too confusing and generalized to be discriminant.</p>
</blockquote>
<p>作者提出了一种先进的视觉词典构建方法，它是可扩展的（scalable，因此适用于on-line检测）和自动的（automatic）。为此，作者使用了修改版的agglomerative clustering。agglomerative algorithm从将每个element作为独立的cluster（以下称之为elementary clusters）开始，然后利用某种相似度度量方法将它们合并为更大的clusters中，直到达到一些收敛条件（比如最小clusters数量，最大cluster半径等）。</p>
<h3 id="vocabulary-building">Vocabulary Building</h3>
<p>在本方法中，elementary clusters是通过对场景点的视觉跟踪产生的，一个elementary cluster对应着一个追踪的特征。视觉词典通过增量式地合并这些clusters。词典构建过程可以总结为两步：</p>
<ol>
<li>词典初始化阶段。词典由前m张图像中的elementary cluster初始化，这些cluster逐渐合并，直到收敛（合并的准则在后文中详细描述）；</li>
<li>词典更新阶段。当机器人移动，机器人获得了场景中的更多视觉信息，这些信需要包含到词典中。因此，对于每m张图像，新的elementary cluster被提取出来。这些cluster被加入到词典中，然后全部clusters逐渐合并，直到收敛。这一步每输入m张图像重复一次。<br>
<img src="https://jinyu-m.github.io/post-images/1615277763160.png" alt="" loading="lazy"></li>
</ol>
<h3 id="cluster-characterization">Cluster Characterization</h3>
<p>词典中每个cluster由它在N维空间中的位置和大小（半径）定义。这样提供了关于cluster分布和clusters间交互的完整信息。因为elementary cluster是由特征跟踪获得的，我们这样定义：<br>
<img src="https://jinyu-m.github.io/post-images/1615278043519.png" alt="" loading="lazy"><br>
其中，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>C</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">C_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.07153em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>是cluster的中心值，由图像<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.65952em;vertical-align:0em;"></span><span class="mord mathdefault">i</span></span></span></span>中场景点<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.03148em;">k</span></span></span></span>的平均特征向量给出。<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>R</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">R_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.00773em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>是点<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.03148em;">k</span></span></span></span>的协方差矩阵。</p>
<p>每次cluster合并是指两个cluster的合并（如图2）。新产生的cluster的参数直接从合并的clusters中获得，不需要重新从初始数据开始计算。这样做，节省了计算时间和内存消耗，尤其是在某些大的cluster中。新cluster的位置和大小由下式给出:<br>
<img src="https://jinyu-m.github.io/post-images/1615278465223.png" alt="" loading="lazy"><br>
其中，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>C</mi><mi>a</mi></msub></mrow><annotation encoding="application/x-tex">C_a</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.07153em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">a</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>和<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>C</mi><mi>b</mi></msub></mrow><annotation encoding="application/x-tex">C_b</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.07153em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">b</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>分别为要合并的两个cluster的中心值，这两个cluster分别有<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>n</mi><mi>a</mi></msub></mrow><annotation encoding="application/x-tex">n_a</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">n</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">a</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>和<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>n</mi><mi>b</mi></msub></mrow><annotation encoding="application/x-tex">n_b</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">n</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">b</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>个elements。</p>
<h3 id="cluster-merging">Cluster Merging</h3>
<p>一般的距离方法依赖于相似度度量方法，比如欧拉距离、曼哈顿距离、切比雪夫距离、马氏距离、向量夹角等，但是这些距离只是局部的分析了数据，所以在高维的聚类空间中是次优的。因此，作者提出一种新的距离方法，将数据的全局分布也考虑进来。该方法基于Fisher's linear disciminant，将数据聚类来最大化目标函数：<br>
<img src="https://jinyu-m.github.io/post-images/1615279001618.png" alt="" loading="lazy"><br>
其中<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>t</mi><mi>r</mi><mo>(</mo><mo>)</mo></mrow><annotation encoding="application/x-tex">tr()</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault">t</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mopen">(</span><span class="mclose">)</span></span></span></span>求得迹，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>S</mi><mi>B</mi></msub></mrow><annotation encoding="application/x-tex">S_B</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.05017em;">B</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>表示<strong>between clusters scatter matrix</strong>，而<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>S</mi><mi>W</mi></msub></mrow><annotation encoding="application/x-tex">S_W</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">W</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>表示<strong>within clusters scatter matrix</strong>，由下式求得<br>
<img src="https://jinyu-m.github.io/post-images/1615279185925.png" alt="" loading="lazy"><br>
其中C是所有数据的全局中心值。N表示所有element的数量，而<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>n</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">n_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">n</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>是cluster k中包含的element数量。<br>
实际上，合并过程可以描述为：</p>
<ol>
<li>对于每个cluster，我们用kd-tree的方法搜索欧式空间中的邻近cluster，作为合并的待选；</li>
<li>对于每对可能要进行合并的clusters，我们计算两个cluster合并后目标函数的值<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>Q</mi><mo mathvariant="normal">′</mo></msup></mrow><annotation encoding="application/x-tex">Q&#x27;</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.946332em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathdefault">Q</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.751892em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span></span></span></span>。如果目标函数的值增大，那么两个cluster被合并，同时<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>S</mi><mi>B</mi></msub><mo separator="true">,</mo><msub><mi>S</mi><mi>W</mi></msub></mrow><annotation encoding="application/x-tex">S_B,S_W</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8777699999999999em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.05017em;">B</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">W</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>随之更新。（实际上，在合并时，作者对于所有可能合并的cluster都计算了Q的增益，将其从高到低排序，然后按照这一顺序进行合并。这样做，合并过程就和分析cluster的顺序无关了。）<br>
每一个合并都会改变词典中数据的分布，需要重新计算<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>S</mi><mi>B</mi></msub></mrow><annotation encoding="application/x-tex">S_B</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.05017em;">B</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>和<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>S</mi><mi>W</mi></msub></mrow><annotation encoding="application/x-tex">S_W</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">W</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>。直接重新计算会非常耗时，我们提出了一种增量式的更新策略：<br>
<img src="https://jinyu-m.github.io/post-images/1615279929545.png" alt="" loading="lazy"></li>
</ol>
<h3 id="convergence-criterion">Convergence criterion</h3>
<p>上述合并过程将重复进行，逐渐合并clusters，直到没有可以让Q增加的合并。通过这种方法，本算法提供了一种自然的收敛标准，不需要任何人工参数。</p>
<h3 id="vocabulary-update">Vocabulary update</h3>
<p>在词典更新阶段，新的elementary clusters加入，包含新的视觉特征。对于每个新加入的elementary cluster <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>ζ</mi><mi>e</mi></msub></mrow><annotation encoding="application/x-tex">\zeta_e</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07378em;">ζ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.07378em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">e</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>S</mi><mi>B</mi></msub></mrow><annotation encoding="application/x-tex">S_B</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.05017em;">B</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>和<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>S</mi><mi>W</mi></msub></mrow><annotation encoding="application/x-tex">S_W</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">W</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>必须相应的更新。为了避免重复计算scatter matrix，作者提出了一种新的更新方法。<br>
更新<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>S</mi><mi>W</mi></msub></mrow><annotation encoding="application/x-tex">S_W</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">W</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>只涉及<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>ζ</mi><mi>e</mi></msub></mrow><annotation encoding="application/x-tex">\zeta_e</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07378em;">ζ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.07378em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">e</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>的covariance matrix<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>R</mi><mi>e</mi></msub></mrow><annotation encoding="application/x-tex">R_e</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.00773em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">e</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>，用element的数量<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>n</mi><mi>e</mi></msub></mrow><annotation encoding="application/x-tex">n_e</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">n</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">e</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>（每个elementary cluster中elements的数量是指特征跟踪中的帧数）加权：<br>
<img src="https://jinyu-m.github.io/post-images/1615280758589.png" alt="" loading="lazy"><br>
<strong>这里为什么不是<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><msup><mi>S</mi><mo mathvariant="normal">′</mo></msup><mi>W</mi></msub><mo>=</mo><mfrac><mrow><mi>N</mi><msub><mi>S</mi><mi>W</mi></msub><mo>+</mo><msub><mi>n</mi><mi>e</mi></msub><msub><mi>R</mi><mi>e</mi></msub></mrow><mrow><mi>N</mi><mo>+</mo><msub><mi>n</mi><mi>e</mi></msub></mrow></mfrac></mrow><annotation encoding="application/x-tex">{S&#x27;}_W=\frac{NS_W+n_eR_e}{N+n_e}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.901892em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord"><span class="mord"><span class="mord mathdefault" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.751892em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">W</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.3337359999999998em;vertical-align:-0.44509999999999994em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8886359999999999em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.10903em;">N</span><span class="mbin mtight">+</span><span class="mord mtight"><span class="mord mathdefault mtight">n</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.16454285714285719em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathdefault mtight">e</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.410305em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.10903em;">N</span><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3567071428571427em;margin-left:-0.05764em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">W</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.14329285714285717em;"><span></span></span></span></span></span></span><span class="mbin mtight">+</span><span class="mord mtight"><span class="mord mathdefault mtight">n</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.16454285714285719em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathdefault mtight">e</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.16454285714285719em;"><span style="top:-2.357em;margin-left:-0.00773em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathdefault mtight">e</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.44509999999999994em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span>呀，有点没看懂诶....</strong><br>
增加新的cluster会影响全局的数据中心<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>C</mi></mrow><annotation encoding="application/x-tex">C</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.07153em;">C</span></span></span></span>，新的中心值<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>C</mi><mo mathvariant="normal">′</mo></msup></mrow><annotation encoding="application/x-tex">C&#x27;</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.751892em;vertical-align:0em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.751892em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span></span></span></span>为：<br>
<img src="https://jinyu-m.github.io/post-images/1615281745215.png" alt="" loading="lazy"><br>
考虑到C的变化，那么<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>S</mi><mi>B</mi></msub></mrow><annotation encoding="application/x-tex">S_B</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.05017em;">B</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>应该更新为：<br>
<img src="https://jinyu-m.github.io/post-images/1615281792324.png" alt="" loading="lazy"><br>
其中，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>δ</mi><mi>C</mi></msub><mo>=</mo><msup><mi>C</mi><mo mathvariant="normal">′</mo></msup><mo>−</mo><mi>C</mi></mrow><annotation encoding="application/x-tex">\delta_C=C&#x27;-C</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03785em;">δ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03785em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.07153em;">C</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.835222em;vertical-align:-0.08333em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.751892em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.07153em;">C</span></span></span></span>，V是每个新加入的cluster与全局中心值之间差异的加权和。V可以增量式地获取：<br>
<img src="https://jinyu-m.github.io/post-images/1615281993246.png" alt="" loading="lazy"><br>
<strong>懵了，这些公式都没推导过...</strong></p>
<h3 id="linear-discriminant-analysis-lda">Linear Discriminant Analysis (LDA)</h3>
<p>对于视觉词典中包含的cluster信息，我们需要找到一种数据变换方法来是cluster的区分度最大，并且可以让我们减少数据的维度，来提升词典构建和图像检索的速度。因此，作者最大化以下LDA目标函数：<br>
<img src="https://jinyu-m.github.io/post-images/1615341122606.png" alt="" loading="lazy"><br>
其中，w是一个决定最大cluster分散度方向的向量。将最大化J(w)当做一个一般的特征值问题，我们得到一个特征向量对应着w的数据变换。选取G中对应着w中较大值的m列，我们可以将数据的维度降低到s维。<br>
<strong>为什么会降低到s维？不是m维</strong></p>
<h2 id="image-indexing">Image Indexing</h2>
<p>一般来说，有两个方面决定了视觉词典的有效性：</p>
<ol>
<li>相似的图像特征应当被对应到相同的cluster（可重复性）；</li>
<li>不相似的图像特征应该对应着不同的clusters（区分能力）。</li>
</ol>
<blockquote>
<p>Generally, there are two aspects that define the efficiency of a visual vocabulary: (i) similar image features should be associated with the same clusters (repetitiveness) and (ii) dissimilar image features have to be associated with different clusters (discriminative power).</p>
</blockquote>
<p>在on-line词典中，作者定义了第三种特性：stability。因为词典一直在更新，作者的目的是相似的特征应当在词典更新的不同阶段都对应着相同的cluster。</p>
<h3 id="cluster-association">Cluster association</h3>
<p>特征与视觉单词间的对应是通过比较每个特征与词典中所有cluster来获得的。特征被对应到最相似的cluster。大多数图像检索方法利用特征空间中的距离来计算特征和clusters之间的距离。这种方法适合在静态预训练好的词典中使用。<br>
<img src="https://jinyu-m.github.io/post-images/1615342470093.png" alt="" loading="lazy"><br>
如图3所示，传统的特征association方法是不适用于on-line词典的（<strong>很棒的关注点！</strong>）。因此，作者提出的feature-cluster association方法是基于树的。在前文的词典构建过程中，词典树被构建好，树的节点对应着clusters，而树的分支对应着cluster的合并层次。树的根节点对应着视觉单词，树的叶节点对应着elementary clusters（从图像中tracking得到的基本单元）。<br>
<img src="https://jinyu-m.github.io/post-images/1615342741631.png" alt="" loading="lazy"><br>
在feature-cluster association过程中，自顶向下遍历树，计算特征和node之间的欧式距离。为了加速，算法只访问与特征相近的分支，为此，作者计算特征和视觉单词之间的距离，并选取满足：<br>
<img src="https://jinyu-m.github.io/post-images/1615343028338.png" alt="" loading="lazy"><br>
的树，其中<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>D</mi><mo>(</mo><mi>f</mi><mo separator="true">,</mo><msub><mi>ζ</mi><mi>k</mi></msub><mo>)</mo></mrow><annotation encoding="application/x-tex">D(f,\zeta_k)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">D</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07378em;">ζ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.07378em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>是特征f与<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>ζ</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">\zeta_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07378em;">ζ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.07378em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>之间的距离，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>D</mi><mi>m</mi></msub></mrow><annotation encoding="application/x-tex">D_m</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">m</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>是特征f与视觉单词之间的最小距离，而<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>τ</mi></mrow><annotation encoding="application/x-tex">\tau</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.1132em;">τ</span></span></span></span>是一个大于1的预设常值。<br>
被选取的树将被并行访问，为了提升效率，算法使用了一个类似于式15的停止准则，不需要访问离f较远的分支。特征最后被关联到最相似的叶节点对应的视觉单词上。（就是自顶向下查找，找到最相似的叶节点，这一颗树的根节点，即视觉单词，被关联到特征）</p>
<h3 id="image-re-indexing">Image re-indexing</h3>
<p>在更新阶段，词典的设置被改变了。因此，无法计算在不同更新阶段索引的图像之间的相似性，而且在每次词典更新后对图像进行索引不是一个可行的解决方案，因为它的计算成本很大。<br>
作者为此提出了一个转换<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mrow></mrow><mi>p</mi></msup><msub><mi>T</mi><mrow><mi>p</mi><mo>−</mo><mn>1</mn></mrow></msub></mrow><annotation encoding="application/x-tex">{}^pT_{p-1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.969438em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord"></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.664392em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">p</span></span></span></span></span></span></span></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.301108em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">p</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span>来体现更新阶段词典的变化。这个转换可以实现对image re-indexing，而不需要重新进行image indexing：<br>
<img src="https://jinyu-m.github.io/post-images/1615343875714.png" alt="" loading="lazy"><br>
其中<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msubsup><mi>H</mi><mi>I</mi><mrow><mi>p</mi><mo>−</mo><mn>1</mn></mrow></msubsup></mrow><annotation encoding="application/x-tex">H^{p-1}_{I}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.225547em;vertical-align:-0.293531em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.08125em;">H</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.932016em;"><span style="top:-2.4064690000000004em;margin-left:-0.08125em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.07847em;">I</span></span></span></span><span style="top:-3.1809080000000005em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">p</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.293531em;"><span></span></span></span></span></span></span></span></span></span>是图像I在p-1词典更新阶段时的检索，而<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mover accent="true"><msubsup><mi>H</mi><mi>I</mi><mi>p</mi></msubsup><mo stretchy="true">‾</mo></mover></mrow><annotation encoding="application/x-tex">\overline{H^{p}_{I}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.2758310000000002em;vertical-align:-0.293531em;"></span><span class="mord overline"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9823000000000001em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathdefault" style="margin-right:0.08125em;">H</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7823em;"><span style="top:-2.4064690000000004em;margin-left:-0.08125em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.07847em;">I</span></span></span></span><span style="top:-3.1809080000000005em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">p</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.293531em;"><span></span></span></span></span></span></span></span></span><span style="top:-3.9023em;"><span class="pstrut" style="height:3em;"></span><span class="overline-line" style="border-bottom-width:0.04em;"></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.293531em;"><span></span></span></span></span></span></span></span></span>是图像I在p-1词典更新阶段时的近似检索。<br>
在更新阶段，词典经历了以下改变：</p>
<ol>
<li>添加elementary clusters。如果新的cluster没有被其他已存在的clusters吸收，它们将包含新的视觉信息。在这种情况下，任何图像的特征在更新之前都不太可能与它们相关联。因此，这部分<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mover accent="true"><msubsup><mi>H</mi><mi>I</mi><mi>k</mi></msubsup><mo stretchy="true">‾</mo></mover></mrow><annotation encoding="application/x-tex">\overline{H^{k}_{I}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.324439em;vertical-align:-0.29353099999999993em;"></span><span class="mord overline"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.030908em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathdefault" style="margin-right:0.08125em;">H</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.830908em;"><span style="top:-2.4064690000000004em;margin-left:-0.08125em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.07847em;">I</span></span></span></span><span style="top:-3.0448000000000004em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.29353099999999993em;"><span></span></span></span></span></span></span></span></span><span style="top:-3.950908em;"><span class="pstrut" style="height:3em;"></span><span class="overline-line" style="border-bottom-width:0.04em;"></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.29353099999999993em;"><span></span></span></span></span></span></span></span></span>被初始化为0；</li>
<li>cluster合并。在这种情况下，两个或多个clusters合并，所有之前关联到这些cluster的特征将被关联到新合成的cluster上。因此，与新cluster关联的出现elements数是正在合并的clusters的elements数之和。<br>
为了反映这些变化，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mrow></mrow><mi>p</mi></msup><msub><mi>T</mi><mrow><mi>p</mi><mo>−</mo><mn>1</mn></mrow></msub></mrow><annotation encoding="application/x-tex">{}^pT_{p-1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.969438em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord"></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.664392em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">p</span></span></span></span></span></span></span></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.301108em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">p</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span>需要初始化对应着新添加的cluster的直方图元素，求和对应着合并的clusters的元素。举个例子：<br>
<img src="https://jinyu-m.github.io/post-images/1615345181242.png" alt="" loading="lazy"></li>
</ol>
<h3 id="image-similarity">Image similarity</h3>
<p><img src="https://jinyu-m.github.io/post-images/1615345809486.png" alt="" loading="lazy"><br>
作者还使用了TF-IDF权重。</p>
<h3 id="cross-over-detection">Cross-over detection</h3>
<figure data-type="image" tabindex="1"><img src="https://jinyu-m.github.io/post-images/1615346135592.png" alt="" loading="lazy"></figure>
<h2 id="experimental-results">Experimental Results</h2>
<p>该回环检测算法被应用在一个SfM算法（T. Nicosevici and R. Garcia. Online Robust 3D Mapping Using Structure from Motion Cues. In MTS/IEEE OCEANS Conference, pages 1–7, 2008.）中。SfM算法应用SIFT、SURF、MSER、Harris等特征进行特征跟踪。</p>
<p>第一个实验在实验室中进行，使用了一个包含书、箱子和杂志的相对平坦的场景。场景的视觉组成是<br>
复杂的，结合了无纹理区域、自然场景、几何图像和抽象的画。测试集包含215张640x480的图像，利用Canon G9 compact camera采集。算法利用SURF提取特征，特征描述子为64维，反映了特征附近的Haar小波响应。词典用前20张图像进行初始化，然后每10张图像更新一次。<br>
<img src="https://jinyu-m.github.io/post-images/1615346729684.png" alt="" loading="lazy"><br>
<img src="https://jinyu-m.github.io/post-images/1615346752503.png" alt="" loading="lazy"><br>
在序列的末端，词典的规模增长速度逐渐变慢。<br>
<img src="https://jinyu-m.github.io/post-images/1615346927451.png" alt="" loading="lazy"><br>
作者采用了一个直接的data association方法，来测试数据聚类的质量和所提出索引方法的效率。对于每个图像特征，我们直接将其与欧式距离小的elementary cluster相关联。然后，利用词典树检索该图像特征，如果该特征最后检索到了与相关联的elementary cluster对应的叶节点，被认为是一次“命中”，否则是一次“错失”。作者测试了不同LDA维度缩减和<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>τ</mi></mrow><annotation encoding="application/x-tex">\tau</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.1132em;">τ</span></span></span></span>值，最后得到，当LDA将特征维度从64降到24，并且<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>τ</mi><mo>=</mo><mn>1.4</mn></mrow><annotation encoding="application/x-tex">\tau=1.4</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.1132em;">τ</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span><span class="mord">.</span><span class="mord">4</span></span></span></span>时，错失率为0.96%。这一参数设置可以很好地减少计算耗时，同时很好的保留词典的能力。在这个序列上，词典更新的平均时间为每次更新1.36秒，图像检索的平均时间为每帧0.23秒。<br>
<img src="https://jinyu-m.github.io/post-images/1615347676267.png" alt="" loading="lazy"><br>
回环检测的结果使用similarity matrix给出的.</p>
<p>第二个实验是在水下数据集进行的，该数据集包含235张720x530的图像。回环检测结果依然由similarity matrix给出。（好像早期的研究偏向于similarity matrix做直观的显示，没有p-r曲线和p@r=1这样的指标）<br>
<img src="https://jinyu-m.github.io/post-images/1615347862825.png" alt="" loading="lazy"></p>
<hr>
<h1 id="automatic-visual-bag-of-words-for-online-robot-navigation-and-mapping-tro-2012-pdf">Automatic Visual Bag-of-Words for Online Robot Navigation and Mapping (TRO 2012) <a href="https://doi.org/10.1109/TRO.2012.2192013">pdf</a></h1>
<p>本文是Online Visual Vocabulary for Robot Navigation and Mapping (IROS 2009)论文的期刊版。</p>
<h2 id="abstract-2">Abstract</h2>
<blockquote>
<p>Detecting already-visited regions based on their visual appearance helps reduce drift and position uncertainties in robot navigation and mapping. Inspired from content-based image retrieval, an efficient approach is the use of visual vocabularies to measure similarities between images. This way, images corresponding to the same scene region can be associated.  <strong>State-of-the-art proposals that address this topic use prebuilt vocabularies that generally require a priori knowledge of the environment</strong>. We propose a novel method for appearance-based navigation and mapping where the visual vocabularies are built online, thus eliminating the need for prebuilt data. We also show that the proposed technique allows efficient loop-closure detection, even at small vocabulary sizes, resulting in a higher computational efficiency.</p>
</blockquote>
<p>SLAM系统一般会将回环检测任务当作一个2D-2D的图像检索任务来完成，bag-of-word模型是一个高效的解决方案，但是现存SOTA的算法是现在一个训练集上训练一个pre-built vocabulary，这里就需要用到人类对于环境的先验认知（比如室内还是室外，词典的规模等）。这篇论文提出了一种在线训练词典的方法，所以无需训练数据集。实验结果证明了提出的算法即使使用一个比较小的词典，也可以达到不错的回环检测效果，计算效率非常高。</p>
<h2 id="introduction-2">Introduction</h2>
<p>传统BoW的算法流程大致分为两部分：1.离线部分，从训练集中提取特征完成聚类，构建视觉词典，特征的聚类被当作描述图像的视觉单词；2.在线部分，提取当前图像的特征，量化到视觉单词上，用视觉单词的直方图向量来描述图像，完成图像相似度的计算。</p>
<blockquote>
<p>BoW image representation employs two stages: 1) In the training stage, sets of visual features are grouped or clustered together to generate visual vocabularies, i.e., collections of generalized visual features or visual words; 2) in the second stage, the images are represented as histograms of visual word occurrences.</p>
</blockquote>
<p>当前BoW模型的缺点之一就是使用了静态的pre-built vocabulary，需要先验的知识，但是在复杂、大型的场景中，这一定是不合理的（我们的试验也证明了这一点，室内场景构建的词典在室外检测效果不好，室外训练的词典在室内效果不好）。<br>
作者提出了一种无需先验和人工设计参数的增量式词典训练方法，online visual vocabulary(OVV)。另外，作者也设计了一种新的聚类方法，用一种新的、考虑到整个聚类分布的聚类收敛标准。<br>
<img src="https://jinyu-m.github.io/post-images/1610877239498.png" alt="" loading="lazy"></p>
<h2 id="visual-vocabulary-2">Visual Vocabulary</h2>
<blockquote>
<p>Finding the adequate parameters for an optimum vocabulary is a tedious task which generally involves a trial-and-error approach. For instance, a vocabulary with too many words would not have enough abstraction power to detect similarities between images. In contrast, a vocabulary with too few words would be too confusing and generalized to be discriminative.</p>
</blockquote>
<p>作者先提出了static pre-built vocabulary的一个弊端，就是词典的规模完全由人工反复实验获得，耗时且不一定最优。而且对于词典树来说，当词典的规模过大，特征的鲁棒性下降了，对于视觉的干扰过于敏感；反之，当词典的规模过小，特征的disciminativeness下降，特征容易误匹配。<br>
作者因此提出了一种增量式的视觉词典训练方法，为了实现这一点，作者采用一种修改后的聚类方法（Agglomerative clustering）.</p>
<h3 id="agglomerative-clustering">Agglomerative clustering</h3>
<p>该聚类方法是一种自底向上的层次聚类方法，过程如：</p>
<ol>
<li>先将每个元素单独定为一类（elementary clusters）；</li>
<li>合并指定距离最小的类；</li>
<li>重复（2）直到所有元素都归为同一类。</li>
</ol>
<h3 id="vocabulary-building-2">Vocabulary building</h3>
<p>在这篇论文中，首先跟踪图像中的特征点，用这些跟踪到的点作为elementary clusters，减少了用于构建词典树的特征数量。词典树通过增量式的合并这些clusters来构建，构建过程可以总结为两点：</p>
<ol>
<li>初始化：词典先用前m张图像提取到的tracked features去初始化一个词典，然后由底向上构建词典树；</li>
<li>更新：我理解的是，OVV用了一种滑动窗的概念，每m张图像中提取出的elementary clusters都被加入到词典树中，然后整个词典树继续由底向上完成构建。这样，新出现的场景中的特征也会被更新到词典树中。</li>
</ol>
<h3 id="cluster-characterization-2">Cluster characterization</h3>
<p>每个cluster具有两个属性，聚类中心值<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>C</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">C_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.07153em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>，和协方差矩阵<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>R</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">R_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.00773em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>。<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>C</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">C_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.07153em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>反映了cluster在整个t为特征空间中的分布，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>R</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">R_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.00773em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>反映了cluster内被合并的子cluster之间的关系。<br>
<img src="https://jinyu-m.github.io/post-images/1610877261587.png" alt="" loading="lazy"></p>
<h4 id="cluster-updating">Cluster updating</h4>
<p>每个聚类都是通过合并两个聚类来获得的，所以新的聚类属性可以根据原本的两个聚类的属性来获得。<br>
<img src="https://jinyu-m.github.io/post-images/1610877270139.png" alt="" loading="lazy"><br>
这样可以节省运算的消耗。</p>
<h3 id="cluster-merging-criterion">Cluster merging criterion</h3>
<p>作者认为原本在Agglomerative clustering度量距离的方法是局部最优的，没有考虑到特征的全局分布。所以作者提出了新的聚类方法，在聚类时，同时增加各类之间的间距和类内的compactness。这一点至关重要，因为视觉词典的有效性由两个方面决定：1) repetitiveness，即相似的图像特征应当被关联到相同的cluster，2) discriminative power，即不想似的图像特征应当被关联到不同的cluster上。新的聚类方法基于Fisher’s linear discriminant。先计算了两个矩阵：<br>
<img src="https://jinyu-m.github.io/post-images/1610877281134.png" alt="" loading="lazy"><br>
其中C是所有数据的中心值，N表示所有数据的数量，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>n</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">n_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">n</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>表示在第k个cluster中包含数据的数量。<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>S</mi><mi>B</mi></msub></mrow><annotation encoding="application/x-tex">S_B</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.05017em;">B</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>代表了between clusters scatter matrix，我理解的是体现了类与类之间的分散程度（类间距离），这个值越大越好；<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>S</mi><mi>W</mi></msub></mrow><annotation encoding="application/x-tex">S_W</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">W</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>代表了within clusters scatter matrix，是体现了类内数据的分散程度（类内紧密度），这个值越小越好。然后用<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>S</mi><mi>B</mi></msub></mrow><annotation encoding="application/x-tex">S_B</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.05017em;">B</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>和<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>S</mi><mi>W</mi></msub></mrow><annotation encoding="application/x-tex">S_W</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">W</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>的迹的比值作为目标函数，在聚类时应使目标函数尽可能大:<br>
<img src="https://jinyu-m.github.io/post-images/1610877295645.png" alt="" loading="lazy"><br>
实际上，合并分两步进行：</p>
<ol>
<li>对于每个cluster，利用kd-tree在它的领域内（欧拉空间中）搜索可能合并的candidate；</li>
<li>对于每个candidate，计算合并前后的Q，如果Q有提升，那么将两个cluster合并，并且更新相应的<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>S</mi><mi>B</mi></msub></mrow><annotation encoding="application/x-tex">S_B</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.05017em;">B</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>和<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>S</mi><mi>W</mi></msub></mrow><annotation encoding="application/x-tex">S_W</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">W</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>。<br>
由于每次合并都会引起<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>S</mi><mi>B</mi></msub></mrow><annotation encoding="application/x-tex">S_B</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.05017em;">B</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>和<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>S</mi><mi>W</mi></msub></mrow><annotation encoding="application/x-tex">S_W</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">W</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>的更新，所需的计算量较大。所以作者提出一种增量式的更新方案：<br>
<img src="https://jinyu-m.github.io/post-images/1610877301528.png" alt="" loading="lazy"></li>
</ol>
<h3 id="convergence-criterion-2">Convergence Criterion</h3>
<p>在算法中，重复上一节的合并过程，直到Q值无法提升。此时，词典的repetitiveness和disciminative power都达到了最大。这样的收敛标准无需人工干预。</p>
<h3 id="adding-new-clusters">Adding New Clusters</h3>
<p>在词典更新阶段，新的elementary cluster被加入。对于每个新加入的elementary cluster <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>ζ</mi><mi>e</mi></msub></mrow><annotation encoding="application/x-tex">\zeta_e</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07378em;">ζ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.07378em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">e</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>S</mi><mi>B</mi></msub></mrow><annotation encoding="application/x-tex">S_B</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.05017em;">B</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>和<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>S</mi><mi>W</mi></msub></mrow><annotation encoding="application/x-tex">S_W</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">W</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>要相应的更新，为了减少更新时的计算量，作者使用增量式更新的方法，和之前iros会议版本的方法一样。</p>
<h3 id="linear-disciminant-analysis">Linear Disciminant Analysis</h3>
<p>与之前iros会议版本的方法一样。</p>
<h3 id="vocabulary-update-criterion">Vocabulary Update Criterion</h3>
<p>在实际操作中，词典不是间隔固定时间更新一次的，而是自适应的更新。在图像检索过程中，特征被关联到词典中的clusters上。对于每个特征<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>f</mi><mi>l</mi></msub></mrow><annotation encoding="application/x-tex">f_l</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.10764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>和cluster <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>ζ</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">\zeta_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07378em;">ζ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.07378em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>之间的关联，我们检查特征是否当特征是否属于该cluster：<br>
<img src="https://jinyu-m.github.io/post-images/1610877346064.png" alt="" loading="lazy"><br>
其中，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>δ</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">\delta_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03785em;">δ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.03785em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>为cluster <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>ζ</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">\zeta_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07378em;">ζ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.07378em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>的标准方差，| |表示每个维度上的绝对值比较。即特征的每个维度都符合式15的条件时，我们认为该特征属于该cluster。在每一个特征更新阶段，当特征落入cluster的比率小于90%，则更新词典。（<strong>相对会议论文的改进</strong>）</p>
<h2 id="image-indexing-2">Image Indexing</h2>
<h3 id="cluster-association-2">Cluster Association</h3>
<p>与之前iros会议版本的方法一样。</p>
<h4 id="image-reindexing">Image Reindexing</h4>
<p>与之前iros会议版本的方法一样。</p>
<h3 id="image-similarity-2">Image similarity</h3>
<p>与之前iros会议版本的方法一样。</p>
<h2 id="increasing-vocabulary-efficiency">Increasing Vocabulary Efficiency</h2>
<p>在导航和建图过程中，新的视觉特征被加入，OVV的规模会一直增大。作者在词典构建和图像检索过程中使用了approximate nearest neighbor techniques来提高效率。同时，为了进一步提升OVV的计算效率，作者对包含较少信息的节点进行了剪枝。当<br>
<img src="https://jinyu-m.github.io/post-images/1610877509249.png" alt="" loading="lazy"><br>
时，进行剪枝。其中<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msubsup><mi>R</mi><mi>k</mi><mi>i</mi></msubsup></mrow><annotation encoding="application/x-tex">R^{i}_{k}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.1077719999999998em;vertical-align:-0.2831079999999999em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.824664em;"><span style="top:-2.4168920000000003em;margin-left:-0.00773em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2831079999999999em;"><span></span></span></span></span></span></span></span></span></span>是cluster <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>ζ</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">\zeta_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07378em;">ζ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.07378em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>中节点i的半径，p是一个预设标量。在实验中，作者发现p=0.1效果最好。（<strong>没太懂这里的意义，R不是elementary cluster的协方差矩阵么</strong>）</p>
<h2 id="experiments">Experiments</h2>
<p><img src="https://jinyu-m.github.io/post-images/1610877518916.png" alt="" loading="lazy"><br>
OVV的词典会随着环境的增大而逐渐增大。<br>
<img src="https://jinyu-m.github.io/post-images/1615435162513.png" alt="" loading="lazy"><br>
可以看到，图像检索的时间基本稳定，没有随着环境规模变大而增长。词典更新的频率也逐渐降低。<br>
<img src="https://jinyu-m.github.io/post-images/1610877528466.png" alt="" loading="lazy"><br>
作者比较了incremental indexing和full indexing的表现（对应着image reindexing节），说明增量式的方法在大幅度减少计算消耗的同时，还保持了不错的表现。</p>
<hr>
<h1 id="dbow-tro-pdf">DBoW (TRO) <a href="https://doi.org/10.1109/TRO.2012.2197158">pdf</a></h1>
<h2 id="introduction-3"><em>Introduction</em></h2>
<p>贡献点可以总结为几点：<br>
1.使用了一种改进的FAST+BEIFF二进制特征；<br>
2.把邻近图像联系起来，组成island，防止过于靠近的图像被匹配到（算是一种temporal constrant）；<br>
3.在词典树中加入inverse index来实现快速的图像检索，加入direct index来保留图像间的correspondence，加快geometrical check的速度。</p>
<h2 id="image-database"><em>Image Database</em></h2>
<p>由于作者使用二进制描述子，所以构建了二进制词典树，使用K-means++ seeding初始化K-means的初始medians，medians中非二进制值得被置为0。<br>
计算两个BoW向量得相似度时使用了L1分数：<br>
<img src="https://jinyu-m.github.io/post-images/1610877562404.png" alt="" loading="lazy"></p>
<p>在词典树中，作者使用了inverse index table来保留该单词出现过的图像索引值。当一张新的图像加入database，inverse index table会随之更新。<br>
作者来使用了direct index table，对于每张图像，作者在direct index table中储存了该图像出现过的单词所属的位于l层的节点，以及该节点包含的局部特征。此结构可以用于在获得candidate loop时，准备进行geometrical check时计算同属于一个word或者同属于一个节点的特征的correspondence。</p>
<h2 id="loop-detection-algorithm"><em>Loop Detection Algorithm</em></h2>
<h3 id="database-query">Database query</h3>
<p>对于每个query图像，利用词典树，搜索到一系列匹配的candidates以及对应的分数，由于这些分数受query image和它其中的单词分布影响，所以作者对分数进行了归一化：<br>
<img src="https://jinyu-m.github.io/post-images/1610877572685.png" alt="" loading="lazy"></p>
<h3 id="match-grouping">Match grouping</h3>
<p>为了避免相邻的图像被匹配，作者将相邻图像构成了island，将其视为一个匹配。如果query匹配到的candidate的时间戳之间差距很小，那么就将这些candidate视为一个island，其匹配分数为：<br>
<img src="https://jinyu-m.github.io/post-images/1610877580156.png" alt="" loading="lazy"></p>
<p>具有最高匹配分数的island被挑选出来作为matching group，进入下一步的验证。</p>
<h3 id="temporal-consistency">Temporal consistency</h3>
<p>当获得最好的matching island后，对其进行时间一致性的检验，即其之前的k个query也必须被匹配到，当其通过检验后，挑选island中具有最高匹配分数的一个image作为当前query的匹配。</p>
<h3 id="efficient-geometrical-consistency">Efficient geometrical consistency</h3>
<p>作者的几何检验思路是计算匹配图像对的F矩阵，利用RANSAC，至少需要有12个匹配点对。为了加快特征匹配，作者用direct index去粗略搜索。</p>
<hr>
<h1 id="fast-and-effective-visual-place-recognition-using-binary-codes-and-disparity-information-iros-2014-pdf">Fast and Effective Visual Place Recognition using Binary Codes and Disparity Information (IROS 2014) <a href="https://www.researchgate.net/publication/263298223">pdf</a></h1>
<h2 id="abstract-3"><strong>Abstract</strong></h2>
<p>这篇工作提出了一个基于二进制code和视差信息的双目场景识别算法。算法（ABLE-S）在全局框架中使用Local Difference Binary（LDB）描述子来获得鲁棒的全局图像描述，该描述是基于图像像素对间亮度和梯度之间差异的。LDB相比其他描述子，如仅依赖于图像亮度的BRIEF，有更好的描述能力。除此之外，作者还讲视差信息加入了二进制描述子（D-LDB）。视差可以提供一些有用的信息，来解决场景识别中常见的问题，如perceptual aliasing。<br>
论文用KITTI数据集测试算法。并且，作者提供了一个回环的真值，以方便回环检测算法表现的比较。</p>
<h2 id="introduction-4"><strong>Introduction</strong></h2>
<p>作者提出FAB-MAP有一些缺陷，即需要事先训练环境的视觉词典和相关联的概率方法，使得算法无法适应实时的应用。<br>
在这篇论文中，作者提出了一个用于视觉回环检测和场景识别的算法，该算法使用基于像素对的亮度、梯度和视差比较的全局二进制描述子，如图1所示。作者将视差信息加入了LDB，得到了D-LDB。在实验中，作者证明了视差的加入提供了更准确的视觉定位，减少了视觉场景识别中的常见问题，如perceptual aliasing。最后的实验证明，ABLE-S算法获得了超过FAB-MAP、WI-SURF、BRIEF-Gist的表现，并且计算消耗更低。<br>
<img src="https://jinyu-m.github.io/post-images/1610877655376.png" alt="" loading="lazy"></p>
<h2 id="binary-descriptor"><strong>Binary Descriptor</strong></h2>
<p>二进制描述子最好的性质为可以用hamming距离进行高效的匹配。假设一个平滑后的图像块p，其中心为关键点(x,y)，那么二进制检测可以定义为：<br>
<img src="https://jinyu-m.github.io/post-images/1610877660015.png" alt="" loading="lazy"><br>
其中，f(i)是一个函数，返回p中特定pixel或cell的图像特征响应。f(i)可以采用如BRIEF、ORB和BRISK中二进制描述子一样的平滑后的图像灰度值。除此之外，f(i)也可以是如LDB和M-LDB中不同二进制比较结构的串联，比如平均图像灰度、p中特定cell的图像梯度Gx和Gy。<br>
<img src="https://jinyu-m.github.io/post-images/1610877671571.png" alt="" loading="lazy"></p>
<p>为了减少场景识别问题中perceptual aliasing等问题的干扰，作者拓展了LDB，加入了平均视差Davg的二进制比较结构：<br>
<img src="https://jinyu-m.github.io/post-images/1610877681169.png" alt="" loading="lazy"></p>
<p>最后，合成的描述子<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>d</mi><mi>n</mi></msub><mo>(</mo><mi>p</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">d_n(p)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathdefault">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathdefault">p</span><span class="mclose">)</span></span></span></span>为一个n次二进制检测的向量，n是描述子的维度，通常被矫正为：<br>
<img src="https://jinyu-m.github.io/post-images/1610877692854.png" alt="" loading="lazy"></p>
<h3 id="proposed-method"><strong>Proposed Method</strong></h3>
<h4 id="binary-code-calculation"><strong>Binary code calculation</strong></h4>
<p>在本文中，作者采用了LDB，因为LDB相对BRIEF加入了梯度信息。作者还加入了视差信息，得到D-LDB。视差是通过SGBM(Semi Global Block Matching)获得的。</p>
<p>作者将图像块的大小定义为64x64，在提取全局二进制描述子之前将图像缩放到这一尺寸。更小的图像块会削弱场景识别算法的有效性，更大的分辨率也没有得到更好的表现。另外，作者将二进制描述子的维度定义为256比特。描述子通过LDB的随机比特挑选方法来满足维度要求。</p>
<p>该全局描述子将缩放后图像块的中心作为关键点，来进行计算，没有显性的旋转和缩放。然而，可以采用其他替代方法，将图像划分为多个grids，将每个grid的中心视为关键点，然后计算每个grid的二进制描述子，拼接到一起得到最后的二进制code。这一方法可以考虑采用不同宽和高的grid(<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>g</mi><mi>w</mi></msub><mo>×</mo><msub><mi>g</mi><mi>h</mi></msub></mrow><annotation encoding="application/x-tex">g_w \times g_h</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7777700000000001em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.02691em;">w</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">h</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>)。</p>
<h4 id="binary-codes-matching"><strong>Binary codes matching</strong></h4>
<p>对要分析的m个场景，提取二进制描述子，构成向量v。计算二进制描述子之间的hamming距离，得到距离矩阵M</p>
<hr>
<h1 id="calc-pdf-code">CALC <a href="https://arxiv.org/abs/1805.07703.pdf">pdf</a> <a href="https://github.com/rpng/calc">code</a></h1>
<h2 id="abstract-4"><em>Abstract</em></h2>
<p>这篇论文提出了一种无监督的神经网络，采用autoencoder的结构，但是重建的不是原始图像，而是图像的HoG描述子。</p>
<h2 id="method"><em>Method</em></h2>
<p>这篇论文作者设计了一个可以将高维的原始图像信息映射到低维特征空间的网络，对场景变化不敏感，训练方法不需要标注图像。<br>
训练pipeline如下：<br>
<img src="https://jinyu-m.github.io/post-images/1610854867832.png" alt="" loading="lazy"></p>
<p>训练集中的每张图像被缩小到120x160，灰度图。通过projective transformations获得匹配图像。<br>
HOG特征对网络提供了一个先验的几何约束，网络可以获得光照不变性，通过projective transformations来获得HOG所不具备的视角不变性。<br>
获得训练的方法-projective transformations过程如下：<br>
<img src="https://jinyu-m.github.io/post-images/1610854876928.png" alt="" loading="lazy"></p>
<p>这个过程的目的是：根据一张真实图像I，通过随机的2D projective transformation获得一系列描述同场景、但视角不同的图像。<br>
对于每张图像，从其四角的某一区域内各随机选一个点，作为生成图像的四个角点，获得四个点后，就可以获得从原图到生成图像的homograph，矫正之后就生成了新图像。<br>
<img src="https://jinyu-m.github.io/post-images/1610854884737.png" alt="" loading="lazy"></p>
<h2 id="performance"><em>Performance</em></h2>
<p><img src="https://jinyu-m.github.io/post-images/1610854891056.png" alt="" loading="lazy"><br>
<img src="https://jinyu-m.github.io/post-images/1610854894727.png" alt="" loading="lazy"><br>
<img src="https://jinyu-m.github.io/post-images/1610854897698.png" alt="" loading="lazy"><br>
<img src="https://jinyu-m.github.io/post-images/1610854900621.png" alt="" loading="lazy"></p>
<h2 id="一点看法">一点看法</h2>
<p>这篇工作虽然说是无监督，但是其实用了HoG描述子去监督训练网络，算是自己制作了伪真值去训练网络，最后得到的网络效果超过了HoG，证明了数据集如果够丰富，神经网络的泛化能力还是很强的。有点像MagicPoint和SuperPoint的detector，虽然最初的annotated label是人工设置的角点，但是最后训练得到的网络却具备更泛化的能力。论文中projective transformation用于拓展数据集，让网络学习（小）视角不变性，简单有效，值得参考。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Loss Function]]></title>
        <id>https://jinyu-m.github.io/post/fastap/</id>
        <link href="https://jinyu-m.github.io/post/fastap/">
        </link>
        <updated>2020-12-13T10:02:24.000Z</updated>
        <content type="html"><![CDATA[<h1 id="写在前面">写在前面</h1>
<p>这篇日志记录了一些别出心裁的损失函数。在我看来，深度学习的主要改进就体现在网络结构和损失函数上，如何将待优化问题转换成数学公式实在是一门艺术。</p>
<hr>
<h1 id="总结">总结</h1>
<h2 id="cvpr-2019-average-precision-loss">[CVPR 2019] <strong>Average Precision Loss</strong></h2>
<p>目前基于深度学习的特征算法大多使用metric learning来进行训练description，一般会使用pair-based，triplet-based的损失函数来进行无监督或弱监督的训练。doap和r2d2中使用了rank-based <strong>A</strong>verage <strong>P</strong>recision loss，很好的提升了效果。FastAP是doap作者在doap之后发表的一篇论文，是一种高效的AP loss，我感觉和doap中的损失函数有很多共同之处(btw, doap没有提供训练代码，r2d2中讲解不详细).</p>
<hr>
<h1 id="目录">目录</h1>
<p><ul class="markdownIt-TOC">
<li><a href="#%E5%86%99%E5%9C%A8%E5%89%8D%E9%9D%A2">写在前面</a></li>
<li><a href="#%E6%80%BB%E7%BB%93">总结</a>
<ul>
<li><a href="#cvpr-2019-average-precision-loss">[CVPR 2019] <strong>Average Precision Loss</strong></a></li>
</ul>
</li>
<li><a href="#%E7%9B%AE%E5%BD%95">目录</a></li>
<li><a href="#ap-loss-pdf-code">AP-Loss pdf code</a>
<ul>
<li><a href="#abstract">Abstract</a></li>
<li><a href="#introduction">Introduction</a></li>
<li><a href="#learning-to-rank-with-average-precision">Learning to Rank with Average Precision</a>
<ul>
<li><a href="#fastap">FastAP</a></li>
</ul>
</li>
<li><a href="#stochastic-optimization">Stochastic Optimization</a></li>
<li><a href="#large-batch-training">Large-Batch Training</a></li>
<li><a href="#minibatch-sampling">Minibatch Sampling</a></li>
<li><a href="#code-with-comments">code with comments</a></li>
</ul>
</li>
</ul>
</p>
<hr>
<h1 id="ap-loss-pdf-code">AP-Loss <a href="http://openaccess.thecvf.com/content_CVPR_2019/papers/Cakir_Deep_Metric_Learning_to_Rank_CVPR_2019_paper.pdf">pdf</a> <a href="https://github.com/kunhe/FastAP-metric-learning">code</a></h1>
<h2 id="abstract">Abstract</h2>
<p>作者基于learning to rank的方法提出了一种新的深度学习方法，FastAP，通过一种源自距离量化的近似方法来优化<strong>rank-based Average Precision</strong>。FastAP具有较低的复杂度，适应于stochastic gradient descent (SGD)。为了全面探索该方法的优势，作者还提出了一种新的minibatch sampling策略，一种允许large-batch training的新启发式方法。</p>
<h2 id="introduction">Introduction</h2>
<p>metric learning中最重要的应用领域就是nearest neighbor retrieval。对于该问题，几乎所有metric learning都基于相同的指导原则：<em>the true &quot;neighbors&quot; of a reference object should be closer than its &quot;non-neighbors&quot; in the learned metric space.</em><br>
作者将metric learning视为一种learning to rank问题，其目标是优化受learned metric影响的整体目标排序。直接优化排序相比其他算法有两个主要的优势：1.可以避免训练集的高阶爆炸，并且可以关注于对距离畸变不敏感的排序；2.值得特别注意的是，可以避免使用高度敏感的超参，如距离阈值或margin。<br>
这篇论文的主要贡献为提出一种优化AP的方法，AP被广泛用于information retrieval任务的评估，为了实现这个rank-based and non-decomposable优化目标，作者使用了一种高效的基于量化的近似方法，并让算法适应于SGD。这个方法被称为FastAP。</p>
<h2 id="learning-to-rank-with-average-precision">Learning to Rank with Average Precision</h2>
<p>假设设置一个标准的信息检索任务，给定特征空间<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>χ</mi></mrow><annotation encoding="application/x-tex">\chi</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathdefault">χ</span></span></span></span>，有一个query <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>q</mi><mo>∈</mo><mi>χ</mi></mrow><annotation encoding="application/x-tex">q \in \chi</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7335400000000001em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">q</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathdefault">χ</span></span></span></span>和一个检索数据集<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi mathvariant="script">R</mi><mo>⊂</mo><mi>χ</mi></mrow><annotation encoding="application/x-tex">\mathcal{R} \subset \chi</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.72243em;vertical-align:-0.0391em;"></span><span class="mord"><span class="mord mathcal">R</span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">⊂</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathdefault">χ</span></span></span></span>。我们的目标是训练一个神经网络<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi mathvariant="normal">Ψ</mi><mo>:</mo><mi>χ</mi><mo>→</mo><msup><mi mathvariant="double-struck">R</mi><mi>m</mi></msup></mrow><annotation encoding="application/x-tex">\Psi: \chi \rightarrow \mathbb{R}^{m}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord">Ψ</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathdefault">χ</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">→</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.68889em;vertical-align:0em;"></span><span class="mord"><span class="mord"><span class="mord mathbb">R</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.664392em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">m</span></span></span></span></span></span></span></span></span></span></span></span>，将输入嵌入到一个m维的欧拉空间中，并且在欧氏空间中优化AP。<br>
为了实现最近邻检索，我们首先要根据与q的距离对<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi mathvariant="script">R</mi></mrow><annotation encoding="application/x-tex">\mathcal{R}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord"><span class="mord mathcal">R</span></span></span></span></span>中的目标进行排序，得到一个有序的列表<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mo>{</mo><msub><mi>x</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>x</mi><mn>2</mn></msub><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo separator="true">,</mo><msub><mi>x</mi><mi>N</mi></msub><mo>}</mo></mrow><annotation encoding="application/x-tex">\{x_1, x_2,...,x_N\}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">{</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.10903em;">N</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">}</span></span></span></span>，其中<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>N</mi><mo>=</mo><mi mathvariant="normal">∣</mi><mi mathvariant="script">R</mi><mi mathvariant="normal">∣</mi></mrow><annotation encoding="application/x-tex">N=|\mathcal{R}|</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.10903em;">N</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">∣</span><span class="mord"><span class="mord mathcal">R</span></span><span class="mord">∣</span></span></span></span>。然后，我们可以得到Precision-Recall曲线：<br>
<img src="https://jinyu-m.github.io/post-images/1610854661572.png" alt="" loading="lazy"><br>
其中，Prec(i)和Rec(i)为有序列表中第i个位置上的准确率和召回率。由此，可以计算AP：<br>
<img src="https://jinyu-m.github.io/post-images/1610854670940.png" alt="" loading="lazy"><br>
为了方便，我们假设Prec(0)=Rec(0)=0.<br>
上述得到AP的方法有一个问题，就是为了获得p-r曲线，需要先获得一个有序的列表，而这一步中包含了离散的排序操作。对于基于梯度的优化来说，排序是主要的障碍：虽然排序几乎处处可微，它的倒数是0或者未定义的。相反，作者的主要观点为：AP会存在另一种解释，它是基于把准确率和召回率看作距离的函数这一观点的，而非基于有序的元素。</p>
<h3 id="fastap">FastAP</h3>
<p>在信息检索领域，AP也可以解释为the area under precision-recall curve (AUPR)。当公式3的基数趋于无穷，这一关系是存在的：<br>
<img src="https://jinyu-m.github.io/post-images/1610854680266.png" alt="" loading="lazy"><br>
其中<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi mathvariant="script">R</mi><mo>+</mo></msup><mo separator="true">,</mo><mo>(</mo><msup><mi mathvariant="script">R</mi><mo>−</mo></msup><mo>)</mo><mo>⊂</mo><mi mathvariant="script">R</mi></mrow><annotation encoding="application/x-tex">\mathcal{R}^+, (\mathcal{R}^-) \subset \mathcal{R}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.021331em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord"><span class="mord mathcal">R</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.771331em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">+</span></span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mopen">(</span><span class="mord"><span class="mord"><span class="mord mathcal">R</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.771331em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">−</span></span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">⊂</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord"><span class="mord mathcal">R</span></span></span></span></span>代表了q的匹配（非匹配）集合。AP的AUPR解释允许将准确率和召回率看作距离，而非有序元素的有参数函数。这样可以帮助我们避免不可微的排序操作，进而提出一种AP的近似方法。<br>
一个连续的p-r曲线（不是如公式1中那种有限的集合）可以定义为：<br>
<img src="https://jinyu-m.github.io/post-images/1610854688240.png" alt="" loading="lazy"><br>
其中z表示query与<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi mathvariant="script">R</mi></mrow><annotation encoding="application/x-tex">\mathcal{R}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord"><span class="mord mathcal">R</span></span></span></span></span>中元素的距离，z在区域<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi mathvariant="normal">Ω</mi></mrow><annotation encoding="application/x-tex">\Omega</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord">Ω</span></span></span></span>中。AP随之变为：<br>
<img src="https://jinyu-m.github.io/post-images/1610854696576.png" alt="" loading="lazy"><br>
接着，我们定义一些概率量化来计算公式7。令<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi mathvariant="script">Z</mi></mrow><annotation encoding="application/x-tex">\mathcal{Z}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord"><span class="mord mathcal" style="margin-right:0.07944em;">Z</span></span></span></span></span>为对应距离z的随机变量，那么<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi mathvariant="script">R</mi><mo>+</mo></msup><mo separator="true">,</mo><msup><mi mathvariant="script">R</mi><mo>−</mo></msup></mrow><annotation encoding="application/x-tex">\mathcal{R}^+, \mathcal{R}^-</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9657709999999999em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord"><span class="mord mathcal">R</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.771331em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">+</span></span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord"><span class="mord mathcal">R</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.771331em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">−</span></span></span></span></span></span></span></span></span></span></span>的距离分布可以定义为<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>p</mi><mo>(</mo><mi>z</mi><mi mathvariant="normal">∣</mi><msup><mi mathvariant="script">R</mi><mo>+</mo></msup><mo>)</mo><mo separator="true">,</mo><mi>p</mi><mo>(</mo><mi>z</mi><mi mathvariant="normal">∣</mi><msup><mi mathvariant="script">R</mi><mo>−</mo></msup><mo>)</mo></mrow><annotation encoding="application/x-tex">p(z|\mathcal{R}^+), p(z|\mathcal{R}^-)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.021331em;vertical-align:-0.25em;"></span><span class="mord mathdefault">p</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="mord">∣</span><span class="mord"><span class="mord"><span class="mord mathcal">R</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.771331em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">+</span></span></span></span></span></span></span></span><span class="mclose">)</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">p</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="mord">∣</span><span class="mord"><span class="mord"><span class="mord mathcal">R</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.771331em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">−</span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>。令<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>P</mi><mo>(</mo><msup><mi mathvariant="script">R</mi><mo>+</mo></msup><mo>)</mo></mrow><annotation encoding="application/x-tex">P(\mathcal{R}^+)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.021331em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord"><span class="mord"><span class="mord mathcal">R</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.771331em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">+</span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>和<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>P</mi><mo>(</mo><msup><mi mathvariant="script">R</mi><mo>−</mo></msup><mo>)</mo><mo>=</mo><mn>1</mn><mo>−</mo><mi>P</mi><mo>(</mo><msup><mi mathvariant="script">R</mi><mo>+</mo></msup><mo>)</mo></mrow><annotation encoding="application/x-tex">P(\mathcal{R}^-)=1-P(\mathcal{R}^+)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.021331em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord"><span class="mord"><span class="mord mathcal">R</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.771331em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">−</span></span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.021331em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord"><span class="mord"><span class="mord mathcal">R</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.771331em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">+</span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>为先验概率，表示了检索集合<span class='katex-error' title='ParseError: KaTeX parse error: Expected &#039;}&#039;, got &#039;EOF&#039; at end of input: \mathcal{R'>\mathcal{R</span>相对于query的偏度。最后，令<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>F</mi><mo>(</mo><mi>z</mi><mo>)</mo><mo>=</mo><mi>P</mi><mo>(</mo><mi mathvariant="script">Z</mi><mo>&lt;</mo><mi>z</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">F(z)=P(\mathcal{Z}&lt; z)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">F</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord"><span class="mord mathcal" style="margin-right:0.07944em;">Z</span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="mclose">)</span></span></span></span>来表示<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi mathvariant="script">Z</mi></mrow><annotation encoding="application/x-tex">\mathcal{Z}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord"><span class="mord mathcal" style="margin-right:0.07944em;">Z</span></span></span></span></span>的累积分布。<br>
基于以上定义，准确率和召回率可以定义为：<br>
<img src="https://jinyu-m.github.io/post-images/1610854704788.png" alt="" loading="lazy"><br>
带入公式7，得到：<br>
<img src="https://jinyu-m.github.io/post-images/1610854712132.png" alt="" loading="lazy"><br>
显然地，公式12可以用有限集合来近似估计。我们首先假设嵌入函数<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi mathvariant="normal">Ψ</mi></mrow><annotation encoding="application/x-tex">\Psi</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord">Ψ</span></span></span></span>的输出是L2-normalized，因此，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi mathvariant="normal">Ω</mi></mrow><annotation encoding="application/x-tex">\Omega</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord">Ω</span></span></span></span>或者说公式12的z是属于<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mo>[</mo><mn>0</mn><mo separator="true">,</mo><mn>2</mn><mo>]</mo></mrow><annotation encoding="application/x-tex">[0,2]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">[</span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">2</span><span class="mclose">]</span></span></span></span>的。然后，我们将<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mo>[</mo><mn>0</mn><mo separator="true">,</mo><mn>2</mn><mo>]</mo></mrow><annotation encoding="application/x-tex">[0,2]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">[</span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">2</span><span class="mclose">]</span></span></span></span>用有限集合量化为<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>Z</mi><mo>=</mo><mrow><msub><mi>z</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>z</mi><mn>2</mn></msub><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo separator="true">,</mo><msub><mi>z</mi><mi>L</mi></msub></mrow></mrow><annotation encoding="application/x-tex">Z={z_1,z_2,...,z_L}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.07153em;">Z</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord"><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.04398em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.04398em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.04398em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">L</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span>，令产生的离线概率分布函数PDF为P，最后我们定义这种新的近似为FastAP：<br>
<img src="https://jinyu-m.github.io/post-images/1610854719905.png" alt="" loading="lazy"><br>
接着，作者用直方图符号来重新说明FastAP。明确的来说，作者构建了一个距离直方图，每个bin的中心点（中值）为Z的每个元素。令<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>h</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">h_j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.980548em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span>为第j个bin中元素的数量，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>H</mi><mi>j</mi></msub><mo>=</mo><msub><mo>∑</mo><mrow><mi>k</mi><mo>≤</mo><mi>j</mi></mrow></msub><msub><mi>h</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">H_j=\sum_{k\le j}h_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.969438em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.08125em;">H</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.08125em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.185818em;vertical-align:-0.43581800000000004em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:-0.0000050000000000050004em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.18639799999999984em;"><span style="top:-2.40029em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span><span class="mrel mtight">≤</span><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.43581800000000004em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>为直方图的累积和。并且，令<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msubsup><mi>h</mi><mi>j</mi><mo>+</mo></msubsup></mrow><annotation encoding="application/x-tex">h^+_j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.224434em;vertical-align:-0.412972em;"></span><span class="mord"><span class="mord mathdefault">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.811462em;"><span style="top:-2.4231360000000004em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span><span style="top:-3.1031310000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">+</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.412972em;"><span></span></span></span></span></span></span></span></span></span>为第j个bin内query的正确匹配数量，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msubsup><mi>H</mi><mi>j</mi><mo>+</mo></msubsup></mrow><annotation encoding="application/x-tex">H^+_j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.224434em;vertical-align:-0.412972em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.08125em;">H</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.811462em;"><span style="top:-2.4231360000000004em;margin-left:-0.08125em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span><span style="top:-3.1031310000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">+</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.412972em;"><span></span></span></span></span></span></span></span></span></span>为其累积和。根据这些定义，我们可以重写公式13的概率量化，得到一个简单的表达式：<br>
<img src="https://jinyu-m.github.io/post-images/1610854727835.png" alt="" loading="lazy"><br>
进行histogram bining和计算FastAP的时间复杂度为O(NL)。</p>
<h2 id="stochastic-optimization">Stochastic Optimization</h2>
<p>AP被定义为关于query和retrieval set间的检索问题。在minibatches中，一个自然的选择是定义in-batch检索问题，其中检索集<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi mathvariant="script">R</mi></mrow><annotation encoding="application/x-tex">\mathcal{R}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord"><span class="mord mathcal">R</span></span></span></span></span>被限制在minibatch中。特别地，我们将每个样本都视为q，来从这个batch内其他样本中检索匹配。每个样本的检索都可以得到一个AP，一个minibatch内的整体目标即为它们的平均值mAP。<br>
为了使用梯度下降法优化目标，公式14内的直方图必须使用允许梯度下降的方法来构建。为此，我们使用了简单的线性插值技术来用一种可微的soft bining技术来代替一般的bining处理。这种插值使得整数型的bin计数变为连续的，定义为<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mover accent="true"><mi>h</mi><mo>^</mo></mover></mrow><annotation encoding="application/x-tex">\hat{h}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9578799999999998em;vertical-align:0em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9578799999999998em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault">h</span></span></span><span style="top:-3.26344em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.25em;">^</span></span></span></span></span></span></span></span></span>，累积和为<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mover accent="true"><mi>H</mi><mo>^</mo></mover></mrow><annotation encoding="application/x-tex">\hat{H}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9467699999999999em;vertical-align:0em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9467699999999999em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.08125em;">H</span></span></span><span style="top:-3.25233em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.19444em;">^</span></span></span></span></span></span></span></span></span>。基于这一可微的bining处理，我们现在可以获得FastAP的偏微分。<br>
并且，与doap中的bining不同，这篇论文中的FastAP可以直接用于训练浮点型描述子，而doap中对应部分其实是将浮点型描述子量化为与二进制描述子一样的直方图，然后用二进制描述子的优化方法去训练，会带来额外的损失。</p>
<h2 id="large-batch-training">Large-Batch Training</h2>
<p>作者首先说了，data parallelism对于FastAP是不可取的，因为FastAP是不可分解的：即每个样本目标函数的值是由这个batch内其他样本来决定的。<br>
作者提出一种启发式的方法来让FastAP可以进行large-batch training。The main insight is that the loss layer takes the embedding matrix of the minibatch as input (see supplementary material). Thus, a large batch can be first broken into smaller chunks to incrementally compute the embedding matrix. Then, we compute the gradients with respect to the embedding matrix, which is a relatively lightweight operation involving only the loss layer. Finally, gradients are back-propagated through the network, again in chunks. This solution works even with a single GPU.（没看懂.....）</p>
<h2 id="minibatch-sampling">Minibatch Sampling</h2>
<p><img src="https://jinyu-m.github.io/post-images/1610854736976.png" alt="" loading="lazy"><br>
大体上来讲，就是作者提出一种采样方法来让一个batch内的negatives更hard，作者利用categories这一概念，一个category包含一些class label对应于此的类，所以在采样一个batch的数据时，先挑选少量几个categories，再从每个category中挑选单独的类，这样一个category中不同类就构成了hard negatives。</p>
<h2 id="code-with-comments">code with comments</h2>
<p>代码是作者开源的，加了一些自己的注释方便理解。</p>
<pre><code class="language-python">import torch
from torch.autograd import Variable, Function

def softBinning(D, mid, Delta):
    &quot;&quot;&quot;
    Args:
        D:      torch.Tensor(N x N), distance matrix
        mid:    torch.Tensor(1), middle value of an interval in histogram
        Delta:  torch.Tensor(1), step of histogram
    &quot;&quot;&quot;
    y = 1 - torch.abs(D-mid)/Delta
    return torch.max(torch.Tensor([0]).cuda(), y)

def dSoftBinning(D, mid, Delta):
    side1 = (D &gt; (mid - Delta)).type(torch.float)
    side2 = (D &lt;= mid).type(torch.float)
    ind1 = (side1 * side2) #.type(torch.uint8)

    side1 = (D &gt; mid).type(torch.float)
    side2 = (D &lt;= (mid + Delta)).type(torch.float)
    ind2 = (side1 * side2) #.type(torch.uint8)

    return (ind1 - ind2)/Delta
    

class FastAP(torch.autograd.Function):
    &quot;&quot;&quot;
    FastAP - autograd function definition

    This class implements the FastAP loss from the following paper:
    &quot;Deep Metric Learning to Rank&quot;, 
    F. Cakir, K. He, X. Xia, B. Kulis, S. Sclaroff. CVPR 2019

    NOTE:
        Given a input batch, FastAP does not sample triplets from it as it's not 
        a triplet-based method. Therefore, FastAP does not take a Sampler as input. 
        Rather, we specify how the input batch is selected.
    &quot;&quot;&quot;

    @staticmethod
    def forward(ctx, input, target, num_bins):
        &quot;&quot;&quot;
        Args:
            input:     torch.Tensor(N x embed_dim), embedding matrix
            target:    torch.Tensor(N x 1), class labels
            num_bins:  int, number of bins in distance histogram
        &quot;&quot;&quot;
        N = target.size()[0]
        assert input.size()[0] == N, &quot;Batch size donesn't match!&quot;
        
        # 1. get affinity matrix
        Y   = target.unsqueeze(1) # shape(N)
        Aff = 2 * (Y == Y.t()).type(torch.float) - 1 # shape(N, N), value{-1, 1}, 1:matched, -1:unmatched
        Aff.masked_fill_(torch.eye(N, N).byte(), 0)  # set diagonal to 0

        I_pos = (Aff &gt; 0).type(torch.float).cuda() # bool, positive matches
        I_neg = (Aff &lt; 0).type(torch.float).cuda() # bool, negatives
        N_pos = torch.sum(I_pos, 1) # the number of positives for each query

        # 2. compute distances from embeddings
        # squared Euclidean distance with range [0,4]
        dist2 = 2 - 2 * torch.mm(input, input.t()) # shape(N, N), value[0, 4], less -&gt; more similar

        # 3. estimate discrete histograms
        Delta = torch.tensor(4. / num_bins).cuda() # step
        Z     = torch.linspace(0., 4., steps=num_bins+1).cuda() # histograms
        L     = Z.size()[0] # length of histograms
        h_pos = torch.zeros((N, L)).cuda() # shape(N, L)
        h_neg = torch.zeros((N, L)).cuda() # shape(N, L)
        for l in range(L): # for each interval of histogram
            pulse    = softBinning(dist2, Z[l], Delta) # shape(N, N), the distance ratio related to corresponding interval
            h_pos[:,l] = torch.sum(pulse * I_pos, 1) # number of positives locating in corresponding interval
            h_neg[:,l] = torch.sum(pulse * I_neg, 1) # number of negatives locating in corresponding interval

        H_pos = torch.cumsum(h_pos, 1) # shape(N, L), number of positive matches for each query under threshold (precision)
        h     = h_pos + h_neg # shape(N, L)
        H     = torch.cumsum(h, 1) # shape(N, L), number of total matches for each query under threshold (base)
        
        # 4. compate FastAP, as in paper &quot;Deep Metric Learning to Rank&quot;
        FastAP = h_pos * H_pos / H
        FastAP[torch.isnan(FastAP) | torch.isinf(FastAP)] = 0
        FastAP = torch.sum(FastAP,1) / N_pos
        FastAP = FastAP[ ~torch.isnan(FastAP) ]
        loss   = 1 - torch.mean(FastAP)
        if torch.rand(1) &gt; 0.99:
            print(&quot;loss value (1-mean(FastAP)): &quot;, loss.item())

        # 6. save for backward
        ctx.save_for_backward(input, target)
        ctx.Z     = Z
        ctx.Delta = Delta
        ctx.dist2 = dist2
        ctx.I_pos = I_pos
        ctx.I_neg = I_neg
        ctx.h_pos = h_pos
        ctx.h_neg = h_neg
        ctx.H_pos = H_pos
        ctx.N_pos = N_pos
        ctx.h     = h
        ctx.H     = H
        ctx.L     = torch.tensor(L)
        
        return loss

    
    @staticmethod
    def backward(ctx, grad_output):
        input, target = ctx.saved_tensors

        Z     = Variable(ctx.Z     , requires_grad = False)
        Delta = Variable(ctx.Delta , requires_grad = False)
        dist2 = Variable(ctx.dist2 , requires_grad = False)
        I_pos = Variable(ctx.I_pos , requires_grad = False)
        I_neg = Variable(ctx.I_neg , requires_grad = False)
        h     = Variable(ctx.h     , requires_grad = False)
        H     = Variable(ctx.H     , requires_grad = False)
        h_pos = Variable(ctx.h_pos , requires_grad = False)
        h_neg = Variable(ctx.h_neg , requires_grad = False)
        H_pos = Variable(ctx.H_pos , requires_grad = False)
        N_pos = Variable(ctx.N_pos , requires_grad = False)

        L     = Z.size()[0]
        H2    = torch.pow(H,2)
        H_neg = H - H_pos

        # 1. d(FastAP)/d(h+)
        LTM1 = torch.tril(torch.ones(L,L), -1)  # lower traingular matrix
        tmp1 = h_pos * H_neg / H2
        tmp1[torch.isnan(tmp1)] = 0

        d_AP_h_pos = (H_pos * H + h_pos * H_neg) / H2 
        d_AP_h_pos = d_AP_h_pos + torch.mm(tmp1, LTM1.cuda())
        d_AP_h_pos = d_AP_h_pos / N_pos.repeat(L,1).t()
        d_AP_h_pos[torch.isnan(d_AP_h_pos) | torch.isinf(d_AP_h_pos)] = 0


        # 2. d(FastAP)/d(h-)
        LTM0 = torch.tril(torch.ones(L,L), 0)  # lower triangular matrix
        tmp2 = -h_pos * H_pos / H2
        tmp2[torch.isnan(tmp2)] = 0

        d_AP_h_neg = torch.mm(tmp2, LTM0.cuda())
        d_AP_h_neg = d_AP_h_neg / N_pos.repeat(L,1).t()
        d_AP_h_neg[torch.isnan(d_AP_h_neg) | torch.isinf(d_AP_h_neg)] = 0


        # 3. d(FastAP)/d(embedding)
        d_AP_x = 0
        for l in range(L):
            dpulse = dSoftBinning(dist2, Z[l], Delta)
            dpulse[torch.isnan(dpulse) | torch.isinf(dpulse)] = 0
            ddp = dpulse * I_pos
            ddn = dpulse * I_neg

            alpha_p = torch.diag(d_AP_h_pos[:,l]) # N*N
            alpha_n = torch.diag(d_AP_h_neg[:,l])
            Ap = torch.mm(ddp, alpha_p) + torch.mm(alpha_p, ddp)
            An = torch.mm(ddn, alpha_n) + torch.mm(alpha_n, ddn)

            # accumulate gradient 
            d_AP_x = d_AP_x - torch.mm(input.t(), (Ap+An))

        grad_input = -d_AP_x
        return grad_input.t(), None, None    


class FastAPLoss(torch.nn.Module):
    &quot;&quot;&quot;
    FastAP - loss layer definition

    This class implements the FastAP loss from the following paper:
    &quot;Deep Metric Learning to Rank&quot;, 
    F. Cakir, K. He, X. Xia, B. Kulis, S. Sclaroff. CVPR 2019
    &quot;&quot;&quot;
    def __init__(self, num_bins=10):
        super(FastAPLoss, self).__init__()
        self.num_bins = num_bins

    def forward(self, batch, labels):
        return FastAP.apply(batch, labels, self.num_bins)
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Dataset]]></title>
        <id>https://jinyu-m.github.io/post/dataset/</id>
        <link href="https://jinyu-m.github.io/post/dataset/">
        </link>
        <updated>2020-11-30T10:54:17.000Z</updated>
        <content type="html"><![CDATA[<h1 id="写在前面">写在前面</h1>
<p>这篇日志记录了一些可能用到的数据集。</p>
<hr>
<h1 id="总结">总结</h1>
<h2 id="semantic-segmentation-cross-season-correspondence-dataset">[semantic segmentation] <strong>Cross-Season Correspondence dataset</strong></h2>
<p>这篇论文中，作者提出了一个数据集，包括不同视觉条件下同一场景的图像，以及图像间2D-2D点的真值匹配关系。在语义分割框架中，作者加入了特征匹配带来的语义一致性约束（即匹配到的特征点应该具有相同的语义标签），提升了语义分割算法的表现。</p>
<hr>
<h1 id="目录">目录</h1>
<p><ul class="markdownIt-TOC">
<li><a href="#%E5%86%99%E5%9C%A8%E5%89%8D%E9%9D%A2">写在前面</a></li>
<li><a href="#%E6%80%BB%E7%BB%93">总结</a>
<ul>
<li><a href="#semantic-segmentation-cross-season-correspondence-dataset">[semantic segmentation] <strong>Cross-Season Correspondence dataset</strong></a></li>
</ul>
</li>
<li><a href="#%E7%9B%AE%E5%BD%95">目录</a></li>
<li><a href="#cross-season-correspondence-dataset-paper-link">Cross-Season Correspondence Dataset paper link</a>
<ul>
<li><a href="#abstract">Abstract</a></li>
<li><a href="#introduction">Introduction</a></li>
<li><a href="#semantic-correspondence-loss">Semantic Correspondence Loss</a></li>
<li><a href="#a-cross-season-correspondence-dataset">A Cross-Season Correspondence Dataset</a>
<ul>
<li><a href="#cmu-seasons-correspondence-dataset">CMU Seasons Correspondence Dataset</a></li>
<li><a href="#oxford-robotcar-correspondence-dataset">Oxford RoBotCar Correspondence Dataset</a></li>
</ul>
</li>
<li><a href="#inplementation-details">Inplementation Details</a></li>
</ul>
</li>
</ul>
</p>
<hr>
<h1 id="cross-season-correspondence-dataset-paper-link">Cross-Season Correspondence Dataset <a href="https://arxiv.org/abs/1903.06916v2">paper</a> <a href="https://visuallocalization.net">link</a></h1>
<h2 id="abstract">Abstract</h2>
<p>这篇论文中，作者提出一种利用不同视觉条件下图像的2D-2D点匹配来训练语义分割网络的方法。通过要求匹配点的语义一致性，来让语义分割网络在不同视觉条件下更鲁棒。</p>
<h2 id="introduction">Introduction</h2>
<p>论文的主要贡献为：1.不同视觉条件下图像之间的点匹配为语义分割网络的训练提供了新的约束，即匹配点应当有一致的语义，作者以此作为一个损失函数；2.作者获得点对应关系的方法不需要真值，只需少量的人工干预；3.本篇论文得到的模型在多变视觉条件下表现有显著提升。</p>
<h2 id="semantic-correspondence-loss">Semantic Correspondence Loss</h2>
<p>作者将从数据集中获得一个样本记为<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mo>(</mo><msup><mi>I</mi><mi>r</mi></msup><mo separator="true">,</mo><msup><mi>I</mi><mi>t</mi></msup><mo separator="true">,</mo><msup><mi>x</mi><mi>r</mi></msup><mo separator="true">,</mo><msup><mi>x</mi><mi>t</mi></msup><mo>)</mo></mrow><annotation encoding="application/x-tex">(I^r,I^t,x^r,x^t)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.043556em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07847em;">I</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.664392em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">r</span></span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07847em;">I</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7935559999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.664392em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">r</span></span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7935559999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>，其中<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>I</mi><mi>r</mi></msup></mrow><annotation encoding="application/x-tex">I^r</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07847em;">I</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.664392em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">r</span></span></span></span></span></span></span></span></span></span></span>是reference traversal中的一张图像，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>I</mi><mi>t</mi></msup></mrow><annotation encoding="application/x-tex">I^t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7935559999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07847em;">I</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7935559999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span></span></span></span></span></span></span></span>是target traversal中的一张图像，x分别是两张图像中匹配的关键点位置。reference每次取同一次traversal，而target从其他traversal随机选取。因此，匹配损失函数<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>L</mi><mrow><mi>c</mi><mi>o</mi><mi>r</mi><mi>r</mi></mrow></msub></mrow><annotation encoding="application/x-tex">L_{corr}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">c</span><span class="mord mathdefault mtight">o</span><span class="mord mathdefault mtight" style="margin-right:0.02778em;">r</span><span class="mord mathdefault mtight" style="margin-right:0.02778em;">r</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>可以记为：<br>
<img src="https://jinyu-m.github.io/post-images/1610854543994.png" alt="" loading="lazy"><br>
其中，l为hinge loss或cross-entropy loss。<br>
令<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>d</mi><mi>x</mi></msub><mo>∈</mo><msup><mi>R</mi><mi>F</mi></msup></mrow><annotation encoding="application/x-tex">d_x \in R^F</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">x</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.8413309999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">F</span></span></span></span></span></span></span></span></span></span></span>为语义分割网络在点x处获得的长度为F的特征向量。则correspondence hinge loss被定义为：<br>
<img src="https://jinyu-m.github.io/post-images/1610854548771.png" alt="" loading="lazy"><br>
而对于correspondence cross-entropy loss，作者首先从reference image的最后特征图中得到最可能的语义类别，用一个one-hot编码向量<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>c</mi><msub><mi>x</mi><mi>i</mi></msub></msub></mrow><annotation encoding="application/x-tex">c_{x_i}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68066em;vertical-align:-0.2501em;"></span><span class="mord"><span class="mord mathdefault">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139199999999997em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathdefault mtight">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3280857142857143em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2501em;"><span></span></span></span></span></span></span></span></span></span>来表示<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>x</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">x_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>位置点的最可能的类别，损失函数可以写为：<br>
<img src="https://jinyu-m.github.io/post-images/1610854553605.png" alt="" loading="lazy"><br>
在训练过程中，作者在标准的cross-entropy loss之外加入correspondence loss进行训练。</p>
<h2 id="a-cross-season-correspondence-dataset">A Cross-Season Correspondence Dataset</h2>
<p>数据集中每个样本包含了不同季节或天气条件下采集的两张邻近图像，并且包含图像间2D-2D的点对应关系。点对应关系是自动通过两点间3D几何一致性来得到的。在不同视觉条件下，几何关系要比光度信息更稳定。该数据集是基于CMU和RobotCar建立的。<br>
<img src="https://jinyu-m.github.io/post-images/1610854558299.png" alt="" loading="lazy"><br>
该数据集的建立可以分为四步：1.计算每张图像的位姿；2.对每个条件或traversal下的环境建立一个稠密的3D点云；3.不同条件下的3D点云进行匹配，由于所有的点云是在同一坐标系下，所以可以通过位置来匹配，不需要特征描述子，避免了视觉条件的干扰；最后，根据相机位姿，基于3D点云的匹配关系，获得2D-2D的匹配关系。</p>
<h3 id="cmu-seasons-correspondence-dataset">CMU Seasons Correspondence Dataset</h3>
<figure data-type="image" tabindex="1"><img src="https://jinyu-m.github.io/post-images/1610854562662.png" alt="" loading="lazy"></figure>
<h3 id="oxford-robotcar-correspondence-dataset">Oxford RoBotCar Correspondence Dataset</h3>
<p>由于视觉条件较差，所以用RGB图像去进行MVS点云中的点太少了，所以作者用了Lidar点云去建图，利用真值的pose和时间戳，去获得点云到图像的映射。<br>
<img src="https://jinyu-m.github.io/post-images/1610854566453.png" alt="" loading="lazy"></p>
<h2 id="inplementation-details">Inplementation Details</h2>
<p>作者使用了在Cityscapes上预训练过的PSPNet作为模型。除了Cityscapes训练图像外，作者来添加了一个CMU和RobotCar粗略标注的图像。这一过程，是为了避免模型将所有像素预测为同一类别，让模型在Cityscapes上依然具有好的表现。<br>
作者还添加了一个运行过程中进行的correspondence refinement阶段，即那些在reference image中被分类为不稳定类别点的匹配被删除。被纳入考虑的类别有person,rider,car,truck,bus,train,motorcycle和bicycle。在加入correspondence loss前，模型先经过了500代warm-up，来保证模型对于reference images有较好的分割效果。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Incremental/Automatic Loop Closure]]></title>
        <id>https://jinyu-m.github.io/post/incrementalautomatic-loop-closure/</id>
        <link href="https://jinyu-m.github.io/post/incrementalautomatic-loop-closure/">
        </link>
        <updated>2020-11-25T01:16:04.000Z</updated>
        <summary type="html"><![CDATA[<p>基于static vocabulary的回环检测在词典训练时很难保证词典中的视觉单词具有普适性，所以在训练完成后，在一些未曾见过的场景中会表现较差，所以增量式的词典构建或者增量式的检索图像很值得关注一下。</p>
]]></summary>
        <content type="html"><![CDATA[<p>基于static vocabulary的回环检测在词典训练时很难保证词典中的视觉单词具有普适性，所以在训练完成后，在一些未曾见过的场景中会表现较差，所以增量式的词典构建或者增量式的检索图像很值得关注一下。</p>
<!-- more -->
<h1 id="fast-and-incremental-loop-closure-detection-with-deep-features-and-proximity-graphs-pdf-code">Fast and Incremental Loop Closure Detection with Deep Features and Proximity Graphs <a href="https://arxiv.org/abs/1911.10752">pdf</a> <a href="https://github.com/AnshanTJU/FILD">code</a></h1>
<h2 id="abstract"><em>Abstract</em></h2>
<p>这篇论文中，作者提出了一个FILD++算法，当相机采集到新的图像，算法通过一个神经网络的两个分支分别得到全局特征和局部特征。接着，一个层次化可导航的small-world graph增量式的利用全局特征构建了一个视觉数据库，来表示机器人的移动轨迹。给定检索的传感器数据，可以通过这些表征来检索轨迹中相同地点，并且得益于局部特征提供的空间信息，图像到图像的匹配也可以进一步得到。</p>
<h2 id="introduction"><em>Introduction</em></h2>
<p>这篇论文中，作者着手于建立一个增量式的数据库（地图），来利用视觉信息实现快速、scalable回环检测。算法利用一个神经网络提取图像的deep features，在机器人移动过程中，一个modified hierarchical navigable small world (HNSW) graph被构建。因此，可以采用一种更快的最近邻搜索来减少计算检索的消耗。</p>
<h2 id="image-representation"><em>Image Representation</em></h2>
<p><img src="https://jinyu-m.github.io/post-images/1606269122126.png" alt="" loading="lazy"><br>
作者设计的特征提取网络包括两个部分，当图像输入后，将其缩放为两个不同的尺寸，第一个尺寸的图像通过backbone (ResNet-50)后，得到的特征图经global average pooling得到全局描述子；第二个尺寸的图像通过backbone后，得到的特征图，经过一个attention机制的筛选，得到合适的局部特征，经过特征降维，得到最后的局部特征。</p>
<h3 id="global-features">Global Features</h3>
<p>全局特征通过Global Average Pooling得到，将<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>w</mi><mo>×</mo><mi>h</mi><mo>×</mo><mi>c</mi></mrow><annotation encoding="application/x-tex">w \times h \times c</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.66666em;vertical-align:-0.08333em;"></span><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.77777em;vertical-align:-0.08333em;"></span><span class="mord mathdefault">h</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault">c</span></span></span></span>的特征图pooling为<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>1</mn><mo>×</mo><mn>1</mn><mo>×</mo><mi>c</mi></mrow><annotation encoding="application/x-tex">1 \times 1 \times c</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault">c</span></span></span></span>的全局描述子。</p>
<h3 id="attention-based-local-features">Attention-based Local Features</h3>
<p>attention层由两层1x1卷积构成，目的为学习每个局部特征的分数。具有高于阈值<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>δ</mi></mrow><annotation encoding="application/x-tex">\delta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.03785em;">δ</span></span></span></span>的分数的局部特征被挑选出来，来避免无用特征的干扰。在第二层中，使用softplus激活函数来保证分数非负。最后，得到一个<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>w</mi><mo>×</mo><mi>h</mi><mo>×</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">w \times h \times 1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.66666em;vertical-align:-0.08333em;"></span><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.77777em;vertical-align:-0.08333em;"></span><span class="mord mathdefault">h</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span>的score map。</p>
<h3 id="local-features-dimensionality-reduction">Local Features' Dimensionality Reduction</h3>
<p>为了缩小特征空间，作者对得到的局部特征进行L2-normalization后，使用PCA进行降维，产生的40维特征再次用L2-normalization处理。</p>
<h3 id="features-scales">Features' Scales</h3>
<p>为了获得有代表性的特征，作者选择在提取阶段使用不同尺寸的图像，为了减少图像金字塔消耗的时间，需要作者只选择了两个尺寸的图像，第一个用于生成全局描述子，第二个用于提取局部特征。</p>
<h2 id="hierarchical-navigable-small-world-graph-database"><em>Hierarchical Navigable Small World Graph Database</em></h2>
<h3 id="hierarchical-navigable-small-world">Hierarchical Navigable Small World</h3>
<p><img src="https://jinyu-m.github.io/post-images/1606271629868.png" alt="" loading="lazy"><br>
一个图<strong>G=(V,E)<strong>由一组节点</strong>V</strong>和一组连接他们的边<strong>E</strong>组成。HNSW来源于NSW，基于增量式的k-NN结构来构建一个图。在这篇论文中，节点由全局描述子表示，边用于连接节点。节点的邻域定义为与该节点直接相连的点的集合，节点的度表示了这个集合的大小。首选的检索策略是先对其父节点进行选择，这样可以避免其他邻近图的主要缺点，并且在面对低维聚类数据时也可以解决表现退化的问题。在NSW方案中，在单次贪婪搜索中跳步的数量和节点的度都呈多重对数变化。另一方面，作者提出的算法为了选择特定节点、分开不同尺度的连接和利用一种启发式的方法选择邻近点，而使用了不同的策略。根据不同层中连接的长度，可以获得一个鲁棒的划分，然后，在一个允许对数级可伸缩的层次化多层图中，搜索过程可以实现。</p>
<h3 id="database-construction-and-exploration">Database Construction and Exploration</h3>
<p>与基于BoW模型的方法不同（基于BoW的方法需要离线训练视觉词典），本文提出的算法在机器人探索过程中构建它的数据库，不需要事先获得先验数据。对于每个插入的元素q，根据一个指数衰减的概率分布随机选择整数最大层l。从高到低遍历图，每一层的ef个最近邻点被视为下一层的进入点。继续这一过程，直到插入元素的M个连接达到底层。归一化的乘积（向量间的cosine距离）被选作对应全局描述子间的距离度量。<br>
<img src="https://jinyu-m.github.io/post-images/1606273183336.png" alt="" loading="lazy"><br>
为了构建一个低计算消耗的系统，作者使用了<a href="https://software.intel.com/en-us/articles/introduction-to-intel-advanced-vector-extensions/">Advanced Vector Extensions</a>指令来加速算法过程。</p>
<h2 id="detection-pipeline"><em>Detection Pipeline</em></h2>
<h3 id="system-overall">System Overall</h3>
<p>在本算法中，全局描述子用于HNSW图构建和检索，局部特征用于几何验证。算法采用时序一致性来防止false positive的情况。算法伪代码如下：<br>
<img src="https://jinyu-m.github.io/post-images/1606273548877.png" alt="" loading="lazy"></p>
<h3 id="non-search-area-definition">Non-Search Area Definition</h3>
<p>由于相邻图像一定具有很高的相似性，所以作者设计了一个FIFO队列来存储全局描述子。全局描述子先存入队列，直到机器人离开non-search区域，描述子才会用于插入HNSW图中。这一区域由时间常数<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>ψ</mi></mrow><annotation encoding="application/x-tex">\psi</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">ψ</span></span></span></span>,相机帧率<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>ϕ</mi></mrow><annotation encoding="application/x-tex">\phi</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathdefault">ϕ</span></span></span></span>定义。因此，对于当前图像，算法只搜索<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>N</mi><mo>−</mo><mi>ψ</mi><mo>×</mo><mi>ϕ</mi></mrow><annotation encoding="application/x-tex">N-\psi \times \phi</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.76666em;vertical-align:-0.08333em;"></span><span class="mord mathdefault" style="margin-right:0.10903em;">N</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">ψ</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathdefault">ϕ</span></span></span></span>区域中的图像。其中N是直到当前时刻的所有图像数据。</p>
<h3 id="image-matching">Image Matching</h3>
<p>在检索过程中，进行如前文所述的搜索过程，主要区别在于底层获得的最近邻将返回作为结果。搜索的质量由ef控制。作者使用暴力匹配法进行局部特征匹配，因为特征描述子维度很低。算法还加入了distance raio test来检查匹配，阈值为<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>ε</mi></mrow><annotation encoding="application/x-tex">\varepsilon</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault">ε</span></span></span></span>.</p>
<h3 id="geometrical-verification">Geometrical Verification</h3>
<p>算法加入了几何一致性的验证，用RANSAC计算匹配图像的F矩阵，如果计算成功，则用最高的内点数量来作为分数。</p>
<h3 id="temporal-consistency-check">Temporal Consistency Check</h3>
<p>最后，算法加入时间一致性检验来保证检测的正确性，当连续<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>β</mi></mrow><annotation encoding="application/x-tex">\beta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.05278em;">β</span></span></span></span>帧是回环，验证通过。这样虽然会丢失回环序列中的前几个回环，但是作者更希望保证算法的准确性（回环检测对准确性要求更高）。</p>
<h2 id="performance"><em>Performance</em></h2>
<p><img src="https://jinyu-m.github.io/post-images/1606275615688.png" alt="" loading="lazy"><br>
<img src="https://jinyu-m.github.io/post-images/1606275618541.png" alt="" loading="lazy"></p>
<hr>
<h1 id="ibow-lcd-an-appearance-based-loop-closure-detection-approach-using-incremental-bags-of-binary-words-pdf-code">iBoW-LCD: An Appearance-based Loop Closure Detection Approach using incremental Bags of Binary Words <a href="https://arxiv.org/abs/1802.05909v2">pdf</a> <a href="https://github.com/emiliofidalgo/ibow-lcd">code</a></h1>
<h2 id="abstract-2"><em>Abstract</em></h2>
<p>这篇论文提出了iBoW-LCD算法，使用一个基于二进制描述子的增量式的BoW方法来检测回环，不需要传统BoW模型的离线训练阶段。除此之外，该算法建立在dynamic islands这一概念上，这是一个简单但有效的将时间上相邻的相似图像聚成一组的方法，可以减少Bayesian框架的计算时间。</p>
<h2 id="introduction-2"><em>Introduction</em></h2>
<p>这篇论文，作者提出了一个有效的appearance-based回环检测算法，称为iBoW-LCD （Incremental Bag-of-Words Loop Closure Detection)，该算法使用增量式的二进制词典，可以在线构建视觉词典，避免了离线训练的各种弊端。这一方法，与inverted index结构结合，可以很有效的检索到回环图像。接着，一个鲁棒回环检测方法被提出。它拓展并加强了island的概念，来防止将相邻图像检索为回环候选。<br>
关于BoW模型，之前的一些工作只添加视觉单词，而没有遗忘（删除）无用的视觉单词，在这篇工作中，优化的词典不光添加单词，在单词被认为无用时也删除单词。实验证明，这样的处理可以用更少的词典达到相似的表现。关于回环检测，作者之前的工作是基于贝叶斯滤波的，但是随着图像数量的增多，处理时间会不断增加。所以这篇工作中，作者用一个简单但有效的基于dynamic island概念的机制来代替滤波器，可以用更少的时间来实现相似的表现。这篇论文提出的算法没有使用FLANN算法。</p>
<h2 id="incremental-bow-for-image-indexing"><strong>Incremental BoW for Image Indexing</strong></h2>
<h3 id="overview-of-mujas-approach">Overview of Muja's Approach</h3>
<p>作者参考了Muja and Lowe提出的方法，该方法引入一种高效的层次化结构来检索和匹配二进制特征，需要很少的内存空间并且比一般的hashing方法scale better。这一结构由一个树构成，非叶节点包含着聚类中心，叶节点存储着要匹配的视觉描述子。也就是增量式词典树的视觉单词被储存在叶节点中。<br>
在构建过程中，算法先随机从初始点集中挑选K个描述子作为聚类中心。然后，余下的每个输入描述子根据hamming距离被分配到最近的聚类中心上。这一过程递归的重复进行，直到一个聚类中的描述子数量小于阈值S。Muja et al.也提出构建多个树T，在搜索过程中并行的使用它们会带来更好的效果。<br>
<img src="https://jinyu-m.github.io/post-images/1606290151915.png" alt="" loading="lazy"><br>
为了并行的利用这些树来搜索描述子，算法对于每个树，从根节点到叶节点遍历树，每步中挑选与检索描述子最相近的节点，并把未被探索过的节点加入一个优先级队列中。当达到叶节点时，该节点中的所有点被线性搜索。当每个树被搜索过一次后，从优先级队列中最近的节点开始继续搜索。直到一定数量的描述子被检查过（在本文中，设为64），这一过程结束。</p>
<h3 id="visual-vocabulary-update">Visual Vocabulary Update</h3>
<p>Muja的方法最初是设计用于检索一个静态的描述子集合。在本文的方法中，作者需要处理一个增量式的视觉词典，所以作者引入了需要改进。首先，在探索过程中，二进制描述子被匹配和合并，以一种合并的政策来更新词典的视觉单词。作者用bitwise AND operation来实现合并：<br>
<img src="https://jinyu-m.github.io/post-images/1606290905303.png" alt="" loading="lazy"><br>
这一策略被实验证明不会导致描述子退化（几乎所有位都变为0）。<br>
其次，在检索过程中没有匹配的描述子将被包含入词典中，作为一个新的视觉单词。为此，每个描述子从根节点到叶节点被搜索。接着，评估将对应的新描述子加入被选定的节点中是否会超过最大叶尺寸S。如果是，则将该描述子加入最初的描述子，递归的重建这个节点。否则，直接将这个描述子加入该节点。<br>
<img src="https://jinyu-m.github.io/post-images/1606291269472.png" alt="" loading="lazy"><br>
然后，算法保留了一个inverted index结构，对于每个视觉单词，它储存了该单词出现过的图像。最初，视觉词典通过把第一幅图像的二进制描述子作为视觉单词的集合来完成构建。当一幅图像输入，它的描述子与检索的视觉单词利用ratio test进行匹配。匹配到的描述子合并到对应视觉单词上。未匹配的描述子被临时当做新的视觉单词加入词典。为了减少检索的复杂度，这些临时的视觉单词只有在连续<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>P</mi><mi>f</mi></msub></mrow><annotation encoding="application/x-tex">P_f</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.969438em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.10764em;">f</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span>帧被匹配到至少<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>P</mi><mi>o</mi></msub></mrow><annotation encoding="application/x-tex">P_o</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">o</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>次，才会保留下来。inverted index相应地更新。这一策略的主要目的在于，挑选那些当机器人达到回环位置时更有可能被观察到的视觉单词。<br>
最后，作者用一种删除视觉单词的机制来保证词典支持上述的更新策略。当从词典中删除一个描述子后，它所加入的节点和其父节点都将被递归地修改来评估它们是否包含子节点。一个没有子节点的节点将不再需要，因此要删除。如果要删除的描述最与聚类中心一致，则重新选择一个新的中心。<br>
<img src="https://jinyu-m.github.io/post-images/1606292138825.png" alt="" loading="lazy"></p>
<h3 id="retrieval-of-similar-images">Retrieval of Similar Images</h3>
<p>inverted index结构可以让搜索范围缩小为与当前图像具有共同视觉单词的历史图像。对于k个之前见过的帧，初始化其相似分数<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>s</mi><mo>(</mo><msub><mi>I</mi><mi>t</mi></msub><mo separator="true">,</mo><msub><mi>I</mi><mi>k</mi></msub><mo>)</mo></mrow><annotation encoding="application/x-tex">s(I_t, I_k)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault">s</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07847em;">I</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07847em;">I</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>为0。令<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>z</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">z_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.04398em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>为从当前图像<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>I</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">I_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07847em;">I</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>中提取出的二进制描述子集合，我们在词典中对于<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>z</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">z_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.04398em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>中每个描述子搜索其最靠近的视觉单词，然后我们根据inverted index来获得具有共同视觉单词的历史图像，并且对于每个检索到的图像的相似度加一个权重。该权重用tf-idf权重来度量视觉单词在词典树和当前图像中的重要性。当处理完所有<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>z</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">z_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.04398em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>中的描述子，可以获得一个对于当前图像<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>I</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">I_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07847em;">I</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>的最相似的图像及其对应相似分数的列表。图像检索的开源代码在<a href="http://github.com/emiliofidalgo/obindex">OBIndex2</a></p>
<h2 id="loop-closure-detection"><strong>Loop Closure Detection</strong></h2>
<h3 id="searching-for-previous-images">Searching for Previous Images</h3>
<p>当在t时刻输入一张图像<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>I</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">I_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07847em;">I</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>，开始检索相似图像。利用一个缓存器来储存最近p张图像，因此防止它们被检索成为回环候选。搜索的结果可以用一个列表来表示，有j个最相似的图像，记为<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>C</mi><mi>t</mi></msub><mo>=</mo><mrow><msub><mi>I</mi><msub><mi>s</mi><mn>1</mn></msub></msub><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo separator="true">,</mo><msub><mi>I</mi><msub><mi>s</mi><mi>j</mi></msub></msub></mrow></mrow><annotation encoding="application/x-tex">C_t={I_{s_1}, ..., I_{s_j}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.07153em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.03065em;vertical-align:-0.34731999999999996em;"></span><span class="mord"><span class="mord"><span class="mord mathdefault" style="margin-right:0.07847em;">I</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139199999999997em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathdefault mtight">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31731428571428577em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2501em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07847em;">I</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathdefault mtight">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3280857142857143em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2818857142857143em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.34731999999999996em;"><span></span></span></span></span></span></span></span></span></span></span>，利用它们的相似分数来排序。相似分数的范围很大程度上决定于视觉单词的分布，在相邻图像与相似图像间变化很大，因此对于相似分数利用min-max策略进行归一化：<br>
<img src="https://jinyu-m.github.io/post-images/1606356566574.png" alt="" loading="lazy"><br>
其中<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>s</mi><mo>(</mo><msub><mi>I</mi><mi>t</mi></msub><mo separator="true">,</mo><msub><mi>I</mi><msub><mi>s</mi><mn>1</mn></msub></msub><mo separator="true">,</mo><mi>s</mi><mo>(</mo><msub><mi>I</mi><mi>t</mi></msub><mo separator="true">,</mo><msub><mi>I</mi><msub><mi>s</mi><mi>j</mi></msub></msub><mo>)</mo></mrow><annotation encoding="application/x-tex">s(I_t, I_{s_1}, s(I_t, I_{s_j})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0973199999999999em;vertical-align:-0.34731999999999996em;"></span><span class="mord mathdefault">s</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07847em;">I</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07847em;">I</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139199999999997em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathdefault mtight">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31731428571428577em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2501em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">s</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07847em;">I</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07847em;">I</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathdefault mtight">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3280857142857143em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2818857142857143em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.34731999999999996em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>是对应的最小和最大的相似分数。这一过程可以让相似分数归一化到[0,1]之间。接着，作者丢弃了一些相似分数小于预设阈值<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>τ</mi><mrow><mi>i</mi><mi>m</mi></mrow></msub></mrow><annotation encoding="application/x-tex">\tau_{im}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.1132em;">τ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.1132em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mord mathdefault mtight">m</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>的图像，产生一个最终的有序匹配图像列表<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mover accent="true"><mi>C</mi><mo>~</mo></mover><mi>t</mi></msub><mo>⊂</mo><msub><mi>C</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">\tilde{C}_{t} \subset {C}_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0701899999999998em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9201899999999998em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07153em;">C</span></span></span><span style="top:-3.6023300000000003em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.16666em;">~</span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">⊂</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord"><span class="mord mathdefault" style="margin-right:0.07153em;">C</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>.</p>
<h3 id="dynamic-islands-computation">Dynamic Islands Computation</h3>
<p>iBoW-LCD算法使用dynamic island的概念，来局部适应图像组的尺寸。这一改进与原本island的区别在于两方面：1.iBoW-LCD不是使用全部过去的图像来计算island，而是根据前一步获得的相似图像集合<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mover accent="true"><mi>C</mi><mo>~</mo></mover><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">\tilde{C}_{t}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0701899999999998em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9201899999999998em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07153em;">C</span></span></span><span style="top:-3.6023300000000003em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.16666em;">~</span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>；2.island的尺寸不是固定的，而是根据相邻图像的相似度和相机移动速度来决定的，可以根据图像流来调整islands。<br>
<img src="https://jinyu-m.github.io/post-images/1606358470060.png" alt="" loading="lazy"><br>
这篇工作中，一个island被定义为一组时间戳在两个时刻间的相似图像，这一准则可以使得算法将时间上接近的图像聚成一组，避免被检索为回环候选。记<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msubsup><mi mathvariant="normal">Υ</mi><mi>n</mi><mi>m</mi></msubsup></mrow><annotation encoding="application/x-tex">{\Upsilon}^{m}_{n}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.93033em;vertical-align:-0.247em;"></span><span class="mord"><span class="mord"><span class="mord">Υ</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.664392em;"><span style="top:-2.4530000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">n</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">m</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span></span></span></span>为一个包含时间戳在m和n之间图像的island。另外，每个island中挑选一个具有最高相似分数的图像作为代表性图像。为了管理islands，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mover accent="true"><mi>C</mi><mo>~</mo></mover><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">\tilde{C}_{t}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0701899999999998em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9201899999999998em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07153em;">C</span></span></span><span style="top:-3.6023300000000003em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.16666em;">~</span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>中的图像被如下处理：对于每张图像<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>I</mi><mi>c</mi></msub><mo>∈</mo><msub><mover accent="true"><mi>C</mi><mo>~</mo></mover><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">I_c \in \tilde{C}_{t}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07847em;">I</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">c</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.0701899999999998em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9201899999999998em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07153em;">C</span></span></span><span style="top:-3.6023300000000003em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.16666em;">~</span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>，评估他们的时间戳是否在已经存在的island所包含的范围内，如果是，则将该图像加入这个island，并且这一island的时间间隔也随之更新来包含<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>I</mi><mi>c</mi></msub></mrow><annotation encoding="application/x-tex">I_c</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07847em;">I</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">c</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>和<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>I</mi><mi>c</mi></msub></mrow><annotation encoding="application/x-tex">I_c</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07847em;">I</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">c</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>前后b张图像；如果不是，则建立一个新的island，并且将island的时间间隔初始化为c时刻周围的2b+1个时刻（前后b个时刻），将<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>I</mi><mi>c</mi></msub></mrow><annotation encoding="application/x-tex">I_c</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07847em;">I</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">c</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>加入新的island。当处理完左右<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mover accent="true"><mi>C</mi><mo>~</mo></mover><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">\tilde{C}_{t}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0701899999999998em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9201899999999998em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07153em;">C</span></span></span><span style="top:-3.6023300000000003em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.16666em;">~</span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>中的图像，产生的island被修改和缩短，如果有必要，让island之间相互不想交，避免有重叠部分。对于每个island，计算一个全局的分数，得到island的匹配列表<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi mathvariant="normal">Γ</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">{\Gamma}_{t}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord"><span class="mord">Γ</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>：<br>
<img src="https://jinyu-m.github.io/post-images/1606358504898.png" alt="" loading="lazy"><br>
构建dynamic island的伪代码如下：<br>
<img src="https://jinyu-m.github.io/post-images/1606358592315.png" alt="" loading="lazy"></p>
<h3 id="island-selection">Island Selection</h3>
<p>在这一步，iBoW-LCD挑选最佳匹配island，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi mathvariant="normal">Υ</mi><mo>∗</mo></msup><mo>(</mo><mi>t</mi><mo>)</mo><mo>∈</mo><msub><mi mathvariant="normal">Γ</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">{\Upsilon}^{*}(t) \in {\Gamma}_{t}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord"><span class="mord">Υ</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.688696em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">∗</span></span></span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathdefault">t</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord"><span class="mord">Γ</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>。为此，算法回想起前一时刻t-1的最佳island <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi mathvariant="normal">Υ</mi><mo>∗</mo></msup><mo>(</mo><mi>t</mi><mo>−</mo><mn>1</mn><mo>)</mo></mrow><annotation encoding="application/x-tex">{\Upsilon}^*(t-1)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord"><span class="mord">Υ</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.688696em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathdefault">t</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">1</span><span class="mclose">)</span></span></span></span>，并且检查是否有<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msubsup><mi mathvariant="normal">Υ</mi><mi>n</mi><mi>m</mi></msubsup><mo>∈</mo><msub><mi mathvariant="normal">Γ</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">{\Upsilon}^{m}_{n} \in {\Gamma}_{t}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.93033em;vertical-align:-0.247em;"></span><span class="mord"><span class="mord"><span class="mord">Υ</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.664392em;"><span style="top:-2.4530000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">n</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">m</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord"><span class="mord">Γ</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>与<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi mathvariant="normal">Υ</mi><mo>∗</mo></msup><mo>(</mo><mi>t</mi><mo>−</mo><mn>1</mn><mo>)</mo></mrow><annotation encoding="application/x-tex">{\Upsilon}^*(t-1)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord"><span class="mord">Υ</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.688696em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathdefault">t</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">1</span><span class="mclose">)</span></span></span></span>重叠。重叠的island被命名为priority islands，这一想法是受“连续图像应当匹配到与之前图像相匹配的island”这一思路的启发。如果priority islands被找到，具有最大全局分数G的被挑选出来，为了下一步处理。否则，算法直接挑选与当前图像最相似的island，也就是<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi mathvariant="normal">Γ</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">{\Gamma}_{t}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord"><span class="mord">Γ</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>中第一个island。</p>
<h3 id="loop-closure-decision">Loop Closure Decision</h3>
<p>在这一步中，算法首先挑选island中的代表图像来作为最终的回环候选<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>I</mi><mi>f</mi></msub></mrow><annotation encoding="application/x-tex">I_f</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.969438em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07847em;">I</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.10764em;">f</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span>。用极线分析来验证<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>I</mi><mi>f</mi></msub></mrow><annotation encoding="application/x-tex">I_f</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.969438em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07847em;">I</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.10764em;">f</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span>和当前图像<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>I</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">I_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07847em;">I</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>是否是同一场景经过相机转动和平移得到的。为此，作者先用ratio test得到一系列假定的匹配，然后用RANSAC来计算F矩阵，如果内点足够多（F矩阵有意义）则认为这一回环候选是正确的。<br>
这样的集合验证可以提高准确性，但是对每幅图像进行一次检验，势必消耗大量时间。所以，iBoW-LCD采用了一个时间上一致性的特性来避免计算消耗。算法记录着在t时刻，连续的回环数量，当priority island存在并且t时刻的连续回环数量大于阈值<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>τ</mi><mi>c</mi></msub></mrow><annotation encoding="application/x-tex">{\tau}_{c}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord"><span class="mord mathdefault" style="margin-right:0.1132em;">τ</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">c</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>，则接受这一回环，不需要计算F矩阵。</p>
<h2 id="experimental-results"><em>Experimental Results</em></h2>
<p><img src="https://jinyu-m.github.io/post-images/1606548242057.png" alt="" loading="lazy"><br>
<img src="https://jinyu-m.github.io/post-images/1606548266958.png" alt="" loading="lazy"><br>
<img src="https://jinyu-m.github.io/post-images/1606548388825.png" alt="" loading="lazy"></p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[BenchMark]]></title>
        <id>https://jinyu-m.github.io/post/a-comprehensive-comparison-of-vpr-under-changing-conditions/</id>
        <link href="https://jinyu-m.github.io/post/a-comprehensive-comparison-of-vpr-under-changing-conditions/">
        </link>
        <updated>2020-11-05T08:33:45.000Z</updated>
        <content type="html"><![CDATA[<h1 id="写在前面">写在前面</h1>
<p>这篇日志记录一下不常见或新提出的benchmark。好的算法也需要好的评价规则来体现呀！</p>
<hr>
<h1 id="总结">总结</h1>
<h2 id="place-recognition-levelling-the-playing-field">[place recognition] <strong>Levelling the Playing Field</strong></h2>
<p>这篇论文中，作者从Matching Performance, Matching Time, Memory Footprint三个角度分析了10种算法。</p>
<hr>
<h1 id="目录">目录</h1>
<p><ul class="markdownIt-TOC">
<li><a href="#%E5%86%99%E5%9C%A8%E5%89%8D%E9%9D%A2">写在前面</a></li>
<li><a href="#%E6%80%BB%E7%BB%93">总结</a>
<ul>
<li><a href="#place-recognition-levelling-the-playing-field">[place recognition] <strong>Levelling the Playing Field</strong></a></li>
</ul>
</li>
<li><a href="#%E7%9B%AE%E5%BD%95">目录</a></li>
<li><a href="#levelling-the-playing-field-a-comprehensive-comparison-of-visual-place-recognition-approaches-under-changing-conditions">Levelling the Playing Field: A Comprehensive Comparison of Visual Place Recognition Approaches under Changing Conditions</a>
<ul>
<li><a href="#introduction">Introduction</a></li>
<li><a href="#evaluation-datasets">Evaluation Datasets</a></li>
<li><a href="#evaluation-metrics">Evaluation Metrics</a></li>
<li><a href="#performance">Performance</a></li>
</ul>
</li>
</ul>
</p>
<hr>
<h1 id="levelling-the-playing-field-a-comprehensive-comparison-of-visual-place-recognition-approaches-under-changing-conditions">Levelling the Playing Field: A Comprehensive Comparison of Visual Place Recognition Approaches under Changing Conditions</h1>
<p>Zaffar, Mubariz and Khaliq, Ahmad and Ehsan, Shoaib and Milford, Michael and McDonald-Maier, Klaus. <em>Levelling the Playing Field: A Comprehensive Comparison of Visual Place Recognition Approaches under Changing Conditions</em>.  ICRA 2019 Workshop on Database Generation and Benchmarking of SLAM Algorithms for Robotics and VR/AR</p>
<h2 id="introduction">Introduction</h2>
<p>本文是对一些VPR算法的比较。作者提出VPR的四个难点：<strong>Seasonal Variation, Viewpoint Variation, Illumination Variation, Dynamic Objects</strong>。在这篇文献中，作者从Matching Performance, Matching Time, Memory Footprint三个角度分析了10种算法。</p>
<h2 id="evaluation-datasets">Evaluation Datasets</h2>
<p>作者使用了Berilin Kudamm Dataset, Gardens Point Dataset, Nordland Dataset作为评测的数据集。<br>
<img src="https://jinyu-m.github.io/post-images/1610853254734.png" alt="" loading="lazy"><br>
<img src="https://jinyu-m.github.io/post-images/1610853260659.png" alt="" loading="lazy"><br>
<img src="https://jinyu-m.github.io/post-images/1610853264199.png" alt="" loading="lazy"><br>
<img src="https://jinyu-m.github.io/post-images/1610853267787.png" alt="" loading="lazy"></p>
<h2 id="evaluation-metrics">Evaluation Metrics</h2>
<p>作者使用AUC来评估算法的matching performance：<br>
<img src="https://jinyu-m.github.io/post-images/1610853272896.png" alt="" loading="lazy"></p>
<p>作者记录了每个算法对每张query image匹配所需的时间，包括query image的feature encoding time和利用描述子匹配R张reference image的时间。</p>
<p>作者还第一次将每个算法特征描述子所需的储存空间进行了比较。</p>
<h2 id="performance">Performance</h2>
<p><img src="https://jinyu-m.github.io/post-images/1610853281610.png" alt="" loading="lazy"><br>
在Berilin Kudamm Dataset上NetVLAD表现最好。在Gardens Point Dataset上，Cross-Region-BoW获得最佳表现，NetVLAD、HybridNet和AMOSNet也获得了相似的不错表现。在Nordland数据集上，Region-VLAD、NetVLAD和Cross-Region-BoW表现较好。<br>
<img src="https://jinyu-m.github.io/post-images/1610853289214.png" alt="" loading="lazy"><br>
<img src="https://jinyu-m.github.io/post-images/1610853296288.png" alt="" loading="lazy"><br>
<img src="https://jinyu-m.github.io/post-images/1610853301967.png" alt="" loading="lazy"></p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Semantic Localization]]></title>
        <id>https://jinyu-m.github.io/post/semantic-localization/</id>
        <link href="https://jinyu-m.github.io/post/semantic-localization/">
        </link>
        <updated>2020-11-05T02:56:52.000Z</updated>
        <content type="html"><![CDATA[<h1 id="improving-condition-and-enviroment-invariant-pr-with-semantic-place-categorization-iros2017-pdf">Improving Condition- and Enviroment- Invariant PR with Semantic Place Categorization -IROS2017 <a href="https://arxiv.org/abs/1706.07144">pdf</a></h1>
<h2 id="abstract"><em>Abstract</em></h2>
<p>论文提出place recognition可以分为两个子问题：特定场景识别和场景分类。这篇论文的创新点在于&quot;use place context to inform place recognition&quot;，即把两个子问题结合起来，相互补充。场景识别得到的语义信息，可以帮助PR提升在昼夜、光照、室内外变化时的表现。</p>
<h2 id="introduction"><em>Introduction</em></h2>
<p>在这篇论文中，作者分析了环境中局部条件变化对于具有全局条件不变的PR算法的影响。并提出一个可以解决这种在一次探索过程或不同探索过程中，出现条件变化情况的方法。这种方法结合了语义标签和场景分类结果，通过将场景分割来改进场景识别。一旦一个场景被分类，作者将使用SeqSLAM进行场景识别，并使用一种动态的加权策略，来控制场景匹配到具有相似场景特性的、或具有相似场景分类的场景。结果证明，不论baseline的表现如何，论文所提出的几何场景分类信息的方法都可以提升算法表现。</p>
<h2 id="method"><em>Method</em></h2>
<p>作者利用VGG16-Places365获得图像的语义标签，将物理位置划分为不同的区域。这些分割后的区域被用于PR来控制场景在特定语义区域内匹配。</p>
<h3 id="place-categorization">Place Categorization</h3>
<p>作者用CNN预测了reference database中每张图像的分类概率，称为场景属性（共102类）。</p>
<h3 id="physical-space-segmentation">Physical Space Segmentation</h3>
<p>利用语义标签去分割区域需要唯一的标签，而非场景属性。为了避免瞬时的预测错误，考虑到输入图像的时间连续性，作者引入了HMM模型，根据语义标签的分类概率，预测每张图像对应的模型参数和隐藏状态。</p>
<p>假设一段序列有T张图像，则该序列的语义标签为<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>X</mi><mo>=</mo><mo>(</mo><msub><mi>x</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>x</mi><mn>2</mn></msub><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo separator="true">,</mo><msub><mi>x</mi><mi>T</mi></msub><mo>)</mo></mrow><annotation encoding="application/x-tex">X=(x_1,x_2,...,x_T)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.07847em;">X</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">T</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>，隐藏变量记为<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>Z</mi><mo>=</mo><mo>(</mo><msub><mi>z</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>z</mi><mn>2</mn></msub><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo separator="true">,</mo><msub><mi>z</mi><mi>T</mi></msub><mo>)</mo></mrow><annotation encoding="application/x-tex">Z=(z_1,z_2,...,z_T)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.07153em;">Z</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.04398em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.04398em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.04398em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">T</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>，其中t时刻的<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>z</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">z_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.04398em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>属于N个隐藏状态中的一个。假设给定<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>z</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub></mrow><annotation encoding="application/x-tex">z_{t-1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.638891em;vertical-align:-0.208331em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.301108em;"><span style="top:-2.5500000000000003em;margin-left:-0.04398em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">t</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"><span></span></span></span></span></span></span></span></span></span>，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>z</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">z_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.04398em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>独立于之前的隐藏变量，并且当前的观测<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>x</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">x_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>只与当前的隐藏状态<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>z</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">z_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.04398em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>有关。因此，状态转移矩阵A表示为：<br>
<img src="https://jinyu-m.github.io/post-images/1610876271940.png" alt="" loading="lazy"><br>
初始状态分布<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>π</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">{\pi}_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">π</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>表示为：<br>
<img src="https://jinyu-m.github.io/post-images/1610876278667.png" alt="" loading="lazy"><br>
t时刻观测到状态i的概率为：<br>
<img src="https://jinyu-m.github.io/post-images/1610876282966.png" alt="" loading="lazy"><br>
目标为找到一个隐藏的状态序列，描述了reference images的期望语义标签。用后验概率来表示：<br>
<img src="https://jinyu-m.github.io/post-images/1610876288670.png" alt="" loading="lazy"><br>
其中<img src="https://jinyu-m.github.io/post-images/1610876296813.png" alt="" loading="lazy">是模型参数。<br>
<img src="https://jinyu-m.github.io/post-images/1610876302928.png" alt="" loading="lazy"><br>
估计了模型参数<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>θ</mi></mrow><annotation encoding="application/x-tex">\theta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span></span></span></span>后，可以获得reference image的最后语义标签<img src="https://jinyu-m.github.io/post-images/1610876309819.png" alt="" loading="lazy"><br>
输入的特征向量，即观察量<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>x</mi><mo>(</mo><mi>t</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">x(t)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault">x</span><span class="mopen">(</span><span class="mord mathdefault">t</span><span class="mclose">)</span></span></span></span>是Place Categorization的输出响应向量，是一个102维的向量，每一维的值代表了属于每个场景的可能性。在输入HMM之前，特征向量被标准化到[0,1]之间。模型参数<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>θ</mi></mrow><annotation encoding="application/x-tex">\theta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span></span></span></span>由Baum-Welch算法确定，可获得最可能的隐藏状态序列。隐藏状态的数量N由以经验决定。</p>
<h3 id="place-recognition">Place Recognition</h3>
<h4 id="sequence-based-place-matching">sequence-based place matching</h4>
<p>作者使用了SeqSLAM算法来进行场景识别。SeqSLAM通过reference和query images之间的Sum of Absolute Difference (SAD)分数D来实现场景识别。<br>
<img src="https://jinyu-m.github.io/post-images/1610876319890.png" alt="" loading="lazy"><br>
其中<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>S</mi><mi>x</mi></msub><mo separator="true">,</mo><msub><mi>S</mi><mi>y</mi></msub></mrow><annotation encoding="application/x-tex">S_x,S_y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.969438em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">x</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03588em;">y</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span>是下采样后图像尺寸，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msubsup><mi>p</mi><mrow><mi>x</mi><mo separator="true">,</mo><mi>y</mi></mrow><mi>i</mi></msubsup><mo separator="true">,</mo><msubsup><mi>p</mi><mrow><mi>x</mi><mo separator="true">,</mo><mi>y</mi></mrow><mi>j</mi></msubsup></mrow><annotation encoding="application/x-tex">p^i_{x,y},p^j_{x,y}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.2077719999999998em;vertical-align:-0.383108em;"></span><span class="mord"><span class="mord mathdefault">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.824664em;"><span style="top:-2.4530000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">x</span><span class="mpunct mtight">,</span><span class="mord mathdefault mtight" style="margin-right:0.03588em;">y</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.383108em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.824664em;"><span style="top:-2.4530000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">x</span><span class="mpunct mtight">,</span><span class="mord mathdefault mtight" style="margin-right:0.03588em;">y</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.383108em;"><span></span></span></span></span></span></span></span></span></span>是reference和query images的像素值。difference vector利用一个尺寸为R的sliding window，进行neighborhood normalization。<br>
<img src="https://jinyu-m.github.io/post-images/1610876324859.png" alt="" loading="lazy"><br>
在邻近标准化后的SAD矩阵中，在限制的速度范围内，从每个reference image开始搜索长度为<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>d</mi><mi>s</mi></msub></mrow><annotation encoding="application/x-tex">d_s</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">s</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>的局部图像序列。具有最佳分数的序列通过一个阈值来确定。</p>
<h4 id="localized-and-semantically-informed-matching">localized and semantically-informed matching</h4>
<p>place matching scores着重体现了环境中局部物理区域的匹配，而非找到一个全局最小值。sliding window的尺寸R体现了环境的跨度/范围。<br>
在前文，作者利用HMM模型将数据集分割成若干带有相似环境条件的区域。作者提出用由HMM给出的<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>L</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">L_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>决定的邻近区域代替传统SeqSLAM中reference image的邻近图像。被分割出的区域可以表示为：<br>
<img src="https://jinyu-m.github.io/post-images/1610876332200.png" alt="" loading="lazy"><br>
也就是一段段具有相同语义标签<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>L</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">L_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>的序列。SAD矩阵的邻近标准化也相应变化。<br>
<img src="https://jinyu-m.github.io/post-images/1610876338453.png" alt="" loading="lazy"><br>
这样的处理使得SeqSLAM计算SAD时的sliding window随着场景条件的变化而变化，不再是一个定值，更具备condition-invariant。</p>
<h2 id="一点看法"><em>一点看法</em></h2>
<p>这篇论文究其根本，是利用语义信息来讲reference image进行划分，代替了SeqSLAM中固定尺寸的sliding window策略，借此提升了在一些跨场景数据集中的表现，这种变长的sliding window可以拓展下应用，在利用temporal consistency的算法中都可以参考借鉴的。</p>
<hr>
<h1 id="lost-appearance-invariant-place-recognition-for-opposite-viewpoints-using-visual-semantics-rss2018-pdf-code">LoST? Appearance-Invariant Place Recognition for Opposite Viewpoints using Visual Semantics -RSS2018 <a href="https://arxiv.org/abs/1804.05526">pdf</a> <a href="https://github.com/oravus/lostX">code</a></h1>
<h2 id="abstract-2"><em>Abstract</em></h2>
<p>We first propose a novel Local Semantic Tensor (LoST) descriptor of images using the convolutional feature maps from a state-of-the-art dense semantic segmentation network. Then, to verify the spatial semantic arrangement of the top matching candidates, we develop a novel approach for mining semantically-salient keypoint correspondences.</p>
<h2 id="introduction-2"><em>Introduction</em></h2>
<p><img src="https://jinyu-m.github.io/post-images/1610876351119.png" alt="" loading="lazy"><br>
作者提出现有的sota场景识别算法，在面对extreme appearance variation时的表现受到严重挑战。所以作者希望用语义信息来解决viewpoint and appearance variations问题，并且只有limited filed-of-view camera，而非全景相机或lidar。本文的贡献点在于：<br>
1.提出一个PR算法，结合了基于语义和外观的全局描述子和空间一致的局部keypoint correspondences；<br>
2.由语义标签和卷积特征图获得一种新的图像描述子，LoST；<br>
3.一种新的从匹配图像对中挖掘和筛选具有语义显著性的keypoint correspondences方法。</p>
<h2 id="method-2"><em>Method</em></h2>
<figure data-type="image" tabindex="1"><img src="https://jinyu-m.github.io/post-images/1610876357256.png" alt="" loading="lazy"></figure>
<h3 id="local-semantic-tensor">Local Semantic Tensor</h3>
<p>本文中，作者提出一种方法，利用语义标签分数和来自于稠密语义分割网络获得的卷积特征图来semantically pool features.<br>
作者使用了在Cityscapes数据集上训练好的RefineNet作为语义分割网络，提取conv5层输出的卷积特征图，特征图的尺寸为<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mfrac><mn>1</mn><mn>32</mn></mfrac><mi>H</mi><mo>×</mo><mfrac><mn>1</mn><mn>32</mn></mfrac><mi>W</mi><mo>×</mo><mi>D</mi></mrow><annotation encoding="application/x-tex">\frac{1}{32}H\times \frac{1}{32}W \times D</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.190108em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.845108em;"><span style="top:-2.6550000000000002em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">3</span><span class="mord mtight">2</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mord mathdefault" style="margin-right:0.08125em;">H</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.190108em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.845108em;"><span style="top:-2.6550000000000002em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">3</span><span class="mord mtight">2</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mord mathdefault" style="margin-right:0.13889em;">W</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">D</span></span></span></span>，其中H和W都是原图的大小，D为2048维。得到的语义标签分数尺寸为<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mfrac><mn>1</mn><mn>4</mn></mfrac><mi>H</mi><mo>×</mo><mfrac><mn>1</mn><mn>4</mn></mfrac><mi>W</mi><mo>×</mo><mi>D</mi></mrow><annotation encoding="application/x-tex">\frac{1}{4}H\times \frac{1}{4}W \times D</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.190108em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.845108em;"><span style="top:-2.6550000000000002em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">4</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mord mathdefault" style="margin-right:0.08125em;">H</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.190108em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.845108em;"><span style="top:-2.6550000000000002em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">4</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mord mathdefault" style="margin-right:0.13889em;">W</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">D</span></span></span></span>，D为20，表示Cityscapes中的20类语义类别。在使用时，将语义分数缩放到与特征图一样的尺寸。<br>
作者设计了语义描述子L，称为Local Semantic Tensor(LoST)。该描述子通过卷积特征图和语义标签概率计算得到：<br>
<img src="https://jinyu-m.github.io/post-images/1610876362317.png" alt="" loading="lazy"></p>
<p>其中<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>l</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">l_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.01968em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>是特征图中在i位置的D维描述子<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>x</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">x_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>的语义标签，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>μ</mi><mi>s</mi></msub></mrow><annotation encoding="application/x-tex">{\mu}_{s}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord"><span class="mord mathdefault">μ</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">s</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>为语义类别s的平均描述子，均值是根据每个像素最可能的语义标签来计算的。图像描述子<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>L</mi><mi>s</mi></msub></mrow><annotation encoding="application/x-tex">L_s</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">s</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>是用像素i输出语义类别s的概率<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>m</mi><mrow><mi>i</mi><mi>s</mi></mrow></msub></mrow><annotation encoding="application/x-tex">m_{is}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">m</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mord mathdefault mtight">s</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>来计算的。<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>m</mi><mrow><mi>i</mi><mi>s</mi></mrow></msub></mrow><annotation encoding="application/x-tex">m_{is}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">m</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mord mathdefault mtight">s</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>是标签分数在D维上进行L1-normalization得到的。实际上，每个语义描述子<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>L</mi><mi>s</mi></msub></mrow><annotation encoding="application/x-tex">L_s</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">s</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>是特定语义类别s中residual descriptor与其他语义类别的带噪声分布的聚合，通过语义标签概率来进行加权。(与VLAD描述子很相近，这里采用语义信息进行聚类)。最后图像的描述子L是road、building和vegetation三类<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>L</mi><mi>s</mi></msub></mrow><annotation encoding="application/x-tex">L_s</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">s</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>经L2-normalization后拼接得到。<br>
在reference database中，作者将公式2中计算平均值的范围从单张图像拓展到邻近15张图像。<br>
在candidate search中，利用余弦距离计算query与reference images之间的距离，取10个candidates。</p>
<h3 id="correspondence-extraction">Correspondence Extraction</h3>
<p>在这篇论文中，作者将maximally-activated locations视为keypoint。作者认为，既然高层的卷积特征图可以捕获图像的语义信息而且语义信息是由相互对应关系的，那么可以合理假设，卷积特征图中包含着correspondence，并且这种correspondence可以映射到特征图中的高响应关键点位置。对于一堆图像，我们可以从高层网络中提取出D个keypoint correspondence。<br>
如果匹配的图像是理想的或者完全一致的，那么correspondence会很完美。但是在实际场景中，会有一些原因造成false correspondence：1.卷积核隐形地被训练去检测特定特征，但是这些特征没有出现在当前图像中，可能会导致网络在随机位置被触发，错误的检测出特定特征；2.同一图像中多个类似物体，会导致cross-correspond；3.动态物体也会引起false corresponde</p>
<h3 id="spatial-layout-verification">Spatial Layout Verification</h3>
<p>为了限制correspondence的数量并且防止false correspondence，作者使用了基于语义一致性的先验筛选。</p>
<h4 id="semantic-label-consistency">Semantic Label consistency</h4>
<p>对于每对keypoint correspondence，作者是用语义标签去筛选，那些具有相似标签的被保留下来。这一步可以筛掉一半多的correspondence，特别是那些受原因1影响的情况。进一步地，作者用neighborhood density test来筛选剩下的correspondence，即在keypoint周围3x3的邻域内，只有一个correspondence被保留下来。这一步可以帮助减少相同语义类别的小范围内冗余的correspondence。</p>
<h4 id="weighted-keypoint-matching">Weighted Keypoint Matching</h4>
<p>对于剩余的corresponding keypoints，记为M，从conv5层提取的k和<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>k</mi><mo mathvariant="normal">′</mo></msup></mrow><annotation encoding="application/x-tex">k&#x27;</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.751892em;vertical-align:0em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03148em;">k</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.751892em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span></span></span></span>处keypoint的D维描述子<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>x</mi><mi>k</mi></msub><mo separator="true">,</mo><msubsup><mi>x</mi><mi>k</mi><mo mathvariant="normal">′</mo></msubsup></mrow><annotation encoding="application/x-tex">x_k, x_k&#x27;</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.035em;vertical-align:-0.2831079999999999em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.751892em;"><span style="top:-2.4168920000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2831079999999999em;"><span></span></span></span></span></span></span></span></span></span>。同时，将图像左右翻转(处理rear-view图像)，得到keypoint对应的翻转坐标<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>p</mi><mi>k</mi></msub><mo separator="true">,</mo><msubsup><mi>p</mi><mi>k</mi><mo mathvariant="normal">′</mo></msubsup></mrow><annotation encoding="application/x-tex">p_k, p_k&#x27;</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.035em;vertical-align:-0.2831079999999999em;"></span><span class="mord"><span class="mord mathdefault">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.751892em;"><span style="top:-2.4168920000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2831079999999999em;"><span></span></span></span></span></span></span></span></span></span>。然后这些keypoint的位置通过加权欧拉距离来完成匹配：<br>
<img src="https://jinyu-m.github.io/post-images/1610876380411.png" alt="" loading="lazy"><br>
其中<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>w</mi><mrow><mi>k</mi><msup><mi>k</mi><mo mathvariant="normal">′</mo></msup></mrow></msub></mrow><annotation encoding="application/x-tex">w_{kk&#x27;}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6828285714285715em;"><span style="top:-2.786em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>是对应descriptor <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>x</mi><mi>k</mi></msub><mo separator="true">,</mo><msubsup><mi>x</mi><mi>k</mi><mo mathvariant="normal">′</mo></msubsup></mrow><annotation encoding="application/x-tex">x_k, x_k&#x27;</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.035em;vertical-align:-0.2831079999999999em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.751892em;"><span style="top:-2.4168920000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2831079999999999em;"><span></span></span></span></span></span></span></span></span></span>的余弦距离，在所有匹配对M上进行normalization。<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>r</mi><mi>c</mi></msub></mrow><annotation encoding="application/x-tex">r_c</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">c</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>是候选c的匹配分数，具有最低分数的候选被认为是最终的匹配。</p>
<h4 id="我的理解">我的理解</h4>
<p>这部分看的有点懵，我的理解是，作者将D维feature map中的每一维都提取出来，找到图中最大响应值的位置，作为keypoint。这样对于query和reference image，每张图像可以提取出D个keypoint，并且两张图像的keypoint已经有了一一对应的的关系，也就是D个keypoint correspondence。对于这D个keypoint correspondence，作者对每个correspondence先用语义进行了筛选，如果每个correspondence中对应的keypoint的语义类别是相同的，那么保留这个correspondence，否则剔除。并且，为了减少同一语义类别中小邻域内存在大量keypoint，作者在3x3的区域内，只保留了一个correspondence。在计算query和reference之间的匹配分数时，由于已知了keypoint correspondence，所以只需要计算匹配误差就行。也就是加权欧拉距离，但是这里**为什么要计算翻转后keypoint坐标的欧拉距离？**还没想清楚。难道是假设了遇到的情况都是opposite-view？而且视角都在同一水平面内平移？这种情况有点局限吧。</p>
<h3 id="image-sequence-matching">Image Sequence Matching</h3>
<p>作者用OpenSeqSLAM的方法加入了temporal consistency，也就是累加序列的匹配分数，找到最优的匹配候选。</p>
<h2 id="performance"><em>Performance</em></h2>
<p>LoST是指只采用图像描述子的检测方法，LoST-X是指整个算法。<br>
sequence matching:<br>
<img src="https://jinyu-m.github.io/post-images/1610876409601.png" alt="" loading="lazy"><br>
single_frame matching:<br>
<img src="https://jinyu-m.github.io/post-images/1610876414942.png" alt="" loading="lazy"></p>
<hr>
<h1 id="dont-look-back-robustifying-place-categorization-for-viewpoint-and-condition-invariant-place-recognition-icra-2018-pdf">Don't Look Back: Robustifying Place Categorization for Viewpoint- and Condition-Invariant Place Recognition (ICRA 2018) <a href="https://arxiv.org/abs/1801.05078">pdf</a></h1>
<h2 id="abstract-3"><em>Abstract</em></h2>
<p>In this work, we develop a novel methodology for using the semantics-aware higher-order layers of deep neural networks for recognizing specific places from within a reference database. To further improve the robustness to appearance change, we develop a descriptor normalization scheme that builds on the success of normalization schemes for pure appearance-based techniques such as SeqSLAM.</p>
<h2 id="introduction-3"><em>Introduction</em></h2>
<p>作者先说了一下place categorization和place recognition之间的联系和区别。place categorization相对更简单，只是识别了当前场景的类型，如parking garage，但是place recognition还要识别出在parking garage中拍摄当前图像时相机的具体位置。<br>
在这篇论文中，作者研究了神经网络高层的语义级别的全连接层的适应性，而非依赖于视角的中层卷积层，来获得视角不变性和条件不变性的场景识别。特别调研了语义级别的图像表征在应对极端视角变化时的表现。除此之外，作者来提出一种描述子标准化方法，来获得多变环境条件下的外观鲁棒性。并且展示了上下文信息可以用于生成一个拓展的图像描述子，进一步提升场景识别的表现。最后，作者通过与场景描述子的PCA分析得到了一些有价值的观点，突出了场景识别任务中时空特性的重要性。</p>
<h2 id="method-3"><em>Method</em></h2>
<h3 id="place-representation">Place Representation</h3>
<p>作者使用了<strong>Places365</strong>网络去表征场景，高层的全连接层可以输出场景的语义描述，所以作者使用<strong>fc6</strong>输出的4096维向量来描述场景。虽然全连接层输出的特征具被视角不变性，但是缺乏外观不变性。</p>
<h3 id="feature-normalization">Feature Normalization</h3>
<p>作者为了增加场景外观不变性，对描述子进行了标准化：<br>
<img src="https://jinyu-m.github.io/post-images/1610876425868.png" alt="" loading="lazy"><br>
其中<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>μ</mi><mi>s</mi></msub></mrow><annotation encoding="application/x-tex">{\mu}_s</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord"><span class="mord mathdefault">μ</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">s</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>是数据集中所有图像描述子的均值，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>δ</mi><mi>s</mi></msub></mrow><annotation encoding="application/x-tex">{\delta}_s</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord"><span class="mord mathdefault" style="margin-right:0.03785em;">δ</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">s</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>是方差。标准化后的特征描述子集合称为Normalized Set of Descriptors (NSD)。对于reference images，由于图像可以事先获得，所以直接在全部图像中计算均值和方差。对于query image，均值和方差随着图像输入不断更新。</p>
<h3 id="sequence-search-in-cost-matrix">Sequence Search in Cost Matrix</h3>
<p>作者计算了query image和reference images之间的余弦距离（应该是1-cosine similarity），得到了一个cost matrix，利用SeqSLAM中的序列匹配方法，搜索匹配的序列：<br>
<img src="https://jinyu-m.github.io/post-images/1610876435820.png" alt="" loading="lazy"><br>
<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>S</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">S_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>是reference image i的最小序列匹配损失。k是序列匹配的斜率（参考SeqSLAM），是在cost matrix对角线±2 rad间变化。<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>D</mi><mi>T</mi></msup></mrow><annotation encoding="application/x-tex">D^T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8413309999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">D</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span></span></span></span>是时间T时的余弦距离，在时间长度为<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>l</mi></mrow><annotation encoding="application/x-tex">l</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.01968em;">l</span></span></span></span>的序列上累加。<br>
<img src="https://jinyu-m.github.io/post-images/1610876439609.png" alt="" loading="lazy"><br>
<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>I</mi><mrow><mi>m</mi><mi>i</mi><mi>n</mi></mrow></msub></mrow><annotation encoding="application/x-tex">I_{min}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07847em;">I</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">m</span><span class="mord mathdefault mtight">i</span><span class="mord mathdefault mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>是匹配的reference image</p>
<h3 id="cropped-regions">Cropped Regions</h3>
<p><img src="https://jinyu-m.github.io/post-images/1610876446888.png" alt="" loading="lazy"><br>
为了解决opposite-view的问题，作者在图像中提取左右两个region，分别提取Normalized Descriptor，得到两个4096维的描述子，在匹配时，两个描述子都计算余弦距离，取较小的作为度量。(称为NSD-CR)</p>
<h2 id="performance-2"><em>Performance</em></h2>
<h3 id="across-datasets">Across Datasets</h3>
<p><img src="https://jinyu-m.github.io/post-images/1610876451656.png" alt="" loading="lazy"><br>
<img src="https://jinyu-m.github.io/post-images/1610876457172.png" alt="" loading="lazy"><br>
<img src="https://jinyu-m.github.io/post-images/1610876462079.png" alt="" loading="lazy"><br>
证明了在front v.s. rear-view的情况下，NSD-CR算法表现最好。</p>
<h3 id="across-layers">Across Layers</h3>
<p><img src="https://jinyu-m.github.io/post-images/1610876468709.png" alt="" loading="lazy"><br>
证明了fc6是可以较好的平衡外观不变性和视角不变性的。</p>
<h3 id="across-networks">Across Networks</h3>
<p><img src="https://jinyu-m.github.io/post-images/1610876479791.png" alt="" loading="lazy"><br>
证明了提出的方法NSD对于任何网络都有效，并且通过place-centric training得到的网络p365、NetVLAD表现比object-centric training得到的网络要更好，因为它表征了场景的类别属性。</p>
<h2 id="一点看法-2"><em>一点看法</em></h2>
<p>这篇论文通过利用分类网络的高层全连接层来获得语义信息，解决视角不变性。采用cropped regions的方法来解决front v.s. rear view的问题，但是我感觉有些局限，相当于已知视角变化是相同方向或相反方向加一个小视角偏移。像X-view适用的范围更广，所以，图模型大有可为😎</p>
<hr>
<h1 id="x-view-graph-based-semantic-multi-view-localization-ral-2018-pdf">X-View: Graph-Based Semantic Multi-View Localization (RAL 2018) <a href="https://arxiv.org/abs/1709.09905">pdf</a></h1>
<h2 id="abstract-4"><em>Abstract</em></h2>
<p>在这篇论文中，作者希望利用人造环境中的语义信息来解决剧烈视角变化的问题。利用语义图的描述子来实现定位，来实现aerial-to-ground、ground-to-ground的剧烈视角变化时的定位问题。</p>
<h2 id="method-4"><em>Method</em></h2>
<figure data-type="image" tabindex="2"><img src="https://jinyu-m.github.io/post-images/1610876488886.png" alt="" loading="lazy"></figure>
<h3 id="system-input">System Input</h3>
<p>算法的输入是具有像素级别的语义或实例分割图像。并且算法假设已经有了一个额外的里程计提供的估计和之前得到的语义地图<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>G</mi><mrow><mi>d</mi><mi>b</mi></mrow></msub></mrow><annotation encoding="application/x-tex">G_{db}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">G</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">d</span><span class="mord mathdefault mtight">b</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>.</p>
<h3 id="graph-extraction-and-assembly">Graph extraction and assembly</h3>
<p>这一步中，算法将一段语义图像序列转换成一个query graph <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>G</mi><mi>q</mi></msub></mrow><annotation encoding="application/x-tex">G_q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.969438em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault">G</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03588em;">q</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span>。先对语义图进行腐蚀和膨胀获得无噪声的语义分割图，然后提取具有相同语义标签的区域，作为一个blob。提取每个blob的中心点<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>p</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">p_j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.716668em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span>，并记录。每个blob被当作一个顶点<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>v</mi><mi>j</mi></msub><mo>=</mo><mo>{</mo><msub><mi>l</mi><mi>j</mi></msub><mo separator="true">,</mo><msub><mi>p</mi><mi>j</mi></msub><mo>}</mo></mrow><annotation encoding="application/x-tex">v_j=\{l_j,p_j\}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.716668em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.036108em;vertical-align:-0.286108em;"></span><span class="mopen">{</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.01968em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mclose">}</span></span></span></span>.<br>
可以根据一幅图像构建一张二维图像内的无向图，也可以根据一段序列构建在3D空间内的无向图<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>e</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">e_j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.716668em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span>. 利用深度信息或者深度预测，可以用3D坐标来计算blobs的欧拉距离来获得3D空间内的邻近关系。一段图像中，每张图像的无向图根据欧拉距离来连接顶点。为了减少同一语义信息的重复顶点，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>G</mi><mi>q</mi></msub></mrow><annotation encoding="application/x-tex">G_q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.969438em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault">G</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03588em;">q</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span>中邻近的实例被合并成一个顶点。</p>
<h3 id="descriptors">Descriptors</h3>
<p>图匹配问题是一个NP难问题，所以作者在这篇论文中使用了random walk描述子去描述拓扑图，保证描述子的提取和匹配时间是常数或线性的。<br>
每个节点的描述子是一个<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>n</mi><mo>×</mo><mi>m</mi></mrow><annotation encoding="application/x-tex">n\times m</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.66666em;vertical-align:-0.08333em;"></span><span class="mord mathdefault">n</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault">m</span></span></span></span>的矩阵，随机游走n次，每次走m步。在每次游走过程中，从当前节点<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>v</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">v_j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.716668em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span>开始，记录经过节点的语义标签。在控制游走路径时，防止回到上一步刚经过的节点，避免出现重复的游走路径，这样可以提升描述子的表达能力。<br>
<img src="https://jinyu-m.github.io/post-images/1610876498711.png" alt="" loading="lazy"></p>
<h3 id="descriptor-matching">Descriptor matching</h3>
<p>当<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>G</mi><mi>q</mi></msub></mrow><annotation encoding="application/x-tex">G_q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.969438em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault">G</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03588em;">q</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span>和<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>G</mi><mi>d</mi></msub><mi>b</mi></mrow><annotation encoding="application/x-tex">G_db</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">G</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">d</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord mathdefault">b</span></span></span></span>都获得后，我们计算query graph中的顶点和database graph中的顶点的描述子相似度来获得associations。对于每个query graph中的顶点，我们通过语义描述子找到database中与之具有相同随机游走的顶点，相同随机游走的数量被当作相似度分数s，被标准化至0到1之间。在第二步中，具有最大相似度的k个匹配被挑选出来，来估计query image在database map中的位置。</p>
<h3 id="localization-back-end">Localization back-end</h3>
<p>query image与global graph之间的匹配、robot观察到的顶点，以及机器人的里程计估计可以构成在顶点<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>p</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">p_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathdefault">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>和机器人位姿<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>c</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">c_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>时的约束<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>θ</mi><mi>i</mi></msub><mo>∈</mo><mi mathvariant="normal">Θ</mi><mo>(</mo><msub><mi>p</mi><mi>i</mi></msub><mo separator="true">,</mo><msub><mi>c</mi><mi>i</mi></msub><mo>)</mo></mrow><annotation encoding="application/x-tex">{\theta}_i \in \Theta(p_i, c_i)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">Θ</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>，其中<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>θ</mi><mi>i</mi></msub><mo>=</mo><msubsup><mi>e</mi><mi>i</mi><mi>T</mi></msubsup><msub><mi mathvariant="normal">Ω</mi><mi>i</mi></msub><msub><mi>e</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">{\theta}_{i}=e_i^T{\Omega}_ie_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.0999949999999998em;vertical-align:-0.258664em;"></span><span class="mord"><span class="mord mathdefault">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-2.441336em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">T</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.258664em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord"><span class="mord">Ω</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathdefault">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>, <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>e</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">e_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>是测量误差，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi mathvariant="normal">Ω</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">{\Omega}_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord"><span class="mord">Ω</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>是associated information matrix。这三种形式的约束，可以分别记为<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi mathvariant="normal">Θ</mi><mi>M</mi></msub><mo>(</mo><msub><mi>p</mi><mi>i</mi></msub><mo>)</mo></mrow><annotation encoding="application/x-tex">{\Theta}_M(p_i)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord"><span class="mord">Θ</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.10903em;">M</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>、<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi mathvariant="normal">Θ</mi><mi>V</mi></msub><mo>(</mo><msub><mi>p</mi><mi>i</mi></msub><mo separator="true">,</mo><msub><mi>c</mi><mi>i</mi></msub><mo>)</mo></mrow><annotation encoding="application/x-tex">{\Theta}_V(p_i, c_i)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord"><span class="mord">Θ</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.22222em;">V</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>和<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi mathvariant="normal">Θ</mi><mi>O</mi></msub><mo>(</mo><msub><mi>c</mi><mi>i</mi></msub><mo>)</mo></mrow><annotation encoding="application/x-tex">{\Theta}_O(c_i)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord"><span class="mord">Θ</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">O</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>。<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi mathvariant="normal">Θ</mi><mi>M</mi></msub><mo>(</mo><msub><mi>p</mi><mi>i</mi></msub><mo>)</mo></mrow><annotation encoding="application/x-tex">{\Theta}_M(p_i)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord"><span class="mord">Θ</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.10903em;">M</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>来源于语义描述子的误差，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi mathvariant="normal">Θ</mi><mi>O</mi></msub><mo>(</mo><msub><mi>c</mi><mi>i</mi></msub><mo>)</mo></mrow><annotation encoding="application/x-tex">{\Theta}_O(c_i)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord"><span class="mord">Θ</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">O</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>源自在不断将机器人位姿关联到localization graph时使用的里程计的估计误差，robot-to-vertex约束内涵了每次机器人观察到结点的转换信息。<br>
利用这三种约束，作者通过Maximum a Posterior (MAP)，让负对数后验<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>E</mi><mo>=</mo><mo>∑</mo><msub><mi>θ</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">E=\sum {\theta}_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.05764em;">E</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.00001em;vertical-align:-0.25001em;"></span><span class="mop op-symbol small-op" style="position:relative;top:-0.0000050000000000050004em;">∑</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>最小，来估计机器人的位姿<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>c</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">c_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>:<br>
<img src="https://jinyu-m.github.io/post-images/1610876507571.png" alt="" loading="lazy"><br>
该问题可以通过Gauss-Newton方法来优化。在算法中，作者用匹配顶点的平均位置来初始化机器人的位置。</p>
<h2 id="performance-3"><em>Performance</em></h2>
<p><img src="https://jinyu-m.github.io/post-images/1610876513937.png" alt="" loading="lazy"><br>
<img src="https://jinyu-m.github.io/post-images/1610876519550.png" alt="" loading="lazy"><br>
<img src="https://jinyu-m.github.io/post-images/1610876524934.png" alt="" loading="lazy"></p>
<h2 id="一点看法-3"><em>一点看法</em></h2>
<p>X-view构建语义拓扑图和利用random walk描述子来表示图像的方法很新颖、高效。但是算法要求理想的分割结果，以我自己的工程经验而言，即使在KITTI这种比较理想的真实数据集上，语义分割的效果也不足以构建如X-view论文中所需的拓扑图...所以算法的实际效果有待考证，官方代码还没开源，所以只能默默等待了。</p>
<hr>
<h1 id="calc20combining-appearance-semantic-and-geometric-information-for-robust-and-efficient-visual-loop-closure-iros-2019-pdf-code">CALC2.0：Combining Appearance, Semantic and Geometric Information for Robust and Efficient Visual Loop Closure (IROS 2019) <a href="https://arxiv.org/abs/1910.14103">pdf</a> <a href="https://github.com/rpng/calc2.0">code</a></h1>
<h2 id="abstract-5"><em>Abstract</em></h2>
<p>作者认为现有的基于CNN的回环检测算法虽然使用了语义、外观或者几何特征信息，但是没有很充分的利用一张图像可以提供过的全部信息（语义、外观、几何信息等），并且需要人工设置参数去完成实际的回环检测。这篇论文中，作者提出了一个专为场景识别设计的神经网络，由semantic segmentator、Variational Autoencoder(VAE)和triplet embedding network组成。该网络用于提取一个全局特征空间来描述图像的外观和语义分布。然后从低层卷积特征图中提取最大响应的区域作为局部关键点，关键点描述子也参考hand-crafted特征的思路从这些特征图中提取。关键点被用于全局匹配搜索候选的回环，并用于最后的几何验证来提出错误回环。</p>
<h2 id="method-5"><em>Method</em></h2>
<p>这篇论文提出的方法核心思想是，尽可能充分的利用单目图像可以提供的信息，如外观、语义和几何一致性，以此实现无需人工设计参数的回环检测。</p>
<h3 id="network-design">Network Design</h3>
<p><img src="https://jinyu-m.github.io/post-images/1610876538210.png" alt="" loading="lazy"><br>
网络由三部分组成：1 VAE， 1 semantic segmentator和1 siamese triplet embedding。最后使用时，只使用encoder部分。网络的输入是RGB图像，大小为<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>H</mi><mo>×</mo><mi>W</mi></mrow><annotation encoding="application/x-tex">H\times W</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.76666em;vertical-align:-0.08333em;"></span><span class="mord mathdefault" style="margin-right:0.08125em;">H</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">W</span></span></span></span>。encoder部分由一个3x3卷积，两个residual block和四个2x2卷积+pool组成。最后用两个1x1卷积来计算隐藏变量<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>μ</mi><mo separator="true">,</mo><mi>σ</mi></mrow><annotation encoding="application/x-tex">\mu, \sigma</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathdefault">μ</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">σ</span></span></span></span>。隐藏变量是训练用于确定一个高斯分布的参数<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi mathvariant="script">N</mi><mo>(</mo><mi>μ</mi><mo separator="true">,</mo><mi>d</mi><mi>i</mi><mi>a</mi><mi>g</mi><mo>(</mo><mi>e</mi><mi>x</mi><mi>p</mi><mo>(</mo><mi>σ</mi><mo>)</mo><mo>)</mo><mo>)</mo></mrow><annotation encoding="application/x-tex">\mathcal{N}(\mu, diag(exp(\sigma)))</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathcal" style="margin-right:0.14736em;">N</span></span><span class="mopen">(</span><span class="mord mathdefault">μ</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">d</span><span class="mord mathdefault">i</span><span class="mord mathdefault">a</span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mopen">(</span><span class="mord mathdefault">e</span><span class="mord mathdefault">x</span><span class="mord mathdefault">p</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.03588em;">σ</span><span class="mclose">)</span><span class="mclose">)</span><span class="mclose">)</span></span></span></span>.取<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>σ</mi></mrow><annotation encoding="application/x-tex">\sigma</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">σ</span></span></span></span>的指数只是为了提升数值稳定性。在这种解释下，隐藏参数应该都是向量，它们通过对它们所在的<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mfrac><mi>H</mi><mn>16</mn></mfrac><mo>×</mo><mfrac><mi>W</mi><mn>16</mn></mfrac><mo>×</mo><mi>M</mi><mo>(</mo><mi>N</mi><mo>+</mo><mn>1</mn><mo>)</mo></mrow><annotation encoding="application/x-tex">\frac{H}{16} \times \frac{W}{16} \times M(N+1)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.217331em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.872331em;"><span style="top:-2.6550000000000002em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mord mtight">6</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.08125em;">H</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.217331em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.872331em;"><span style="top:-2.6550000000000002em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mord mtight">6</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">W</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.10903em;">M</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.10903em;">N</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">1</span><span class="mclose">)</span></span></span></span>的3D数组展平得到。<br>
隐藏变量通过让其构建一个标准正太分布来优化，使用KL散度作为损失函数：<br>
<img src="https://jinyu-m.github.io/post-images/1610876542682.png" alt="" loading="lazy"></p>
<p>用一个符合标准正太分布的<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>ϵ</mi></mrow><annotation encoding="application/x-tex">\epsilon</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault">ϵ</span></span></span></span>来采样，隐藏变量<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>z</mi><mo>=</mo><mi>μ</mi><mo>+</mo><mi>d</mi><mi>i</mi><mi>a</mi><mi>g</mi><mo>(</mo><mi>e</mi><mi>x</mi><mi>p</mi><mo>(</mo><mi>σ</mi><mo>)</mo><msup><mo>)</mo><mfrac><mn>1</mn><mn>2</mn></mfrac></msup><mi>ϵ</mi></mrow><annotation encoding="application/x-tex">z=\mu + diag(exp(\sigma))^{\frac{1}{2}}\epsilon</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.7777700000000001em;vertical-align:-0.19444em;"></span><span class="mord mathdefault">μ</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.20402em;vertical-align:-0.25em;"></span><span class="mord mathdefault">d</span><span class="mord mathdefault">i</span><span class="mord mathdefault">a</span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mopen">(</span><span class="mord mathdefault">e</span><span class="mord mathdefault">x</span><span class="mord mathdefault">p</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.03588em;">σ</span><span class="mclose">)</span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9540200000000001em;"><span style="top:-3.363em;margin-right:0.05em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mopen nulldelimiter sizing reset-size3 size6"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8443142857142858em;"><span style="top:-2.656em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span><span style="top:-3.2255000000000003em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line mtight" style="border-bottom-width:0.049em;"></span></span><span style="top:-3.384em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.344em;"><span></span></span></span></span></span><span class="mclose nulldelimiter sizing reset-size3 size6"></span></span></span></span></span></span></span></span></span></span><span class="mord mathdefault">ϵ</span></span></span></span>被切分成N+1组特征图，对应着视觉外观和N个语义类别。<br>
视觉外观部分的decoder用RGB reconstruction loss来训练：<br>
<img src="https://jinyu-m.github.io/post-images/1610876548915.png" alt="" loading="lazy"><br>
其中 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>x</mi><mrow><mi>h</mi><mo separator="true">,</mo><mi>w</mi><mo separator="true">,</mo><mi>c</mi></mrow></msub><mo separator="true">,</mo><msub><mi>r</mi><mrow><mi>h</mi><mo separator="true">,</mo><mi>w</mi><mo separator="true">,</mo><mi>c</mi></mrow></msub></mrow><annotation encoding="application/x-tex">x_{h,w,c},r_{h,w,c}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.716668em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">h</span><span class="mpunct mtight">,</span><span class="mord mathdefault mtight" style="margin-right:0.02691em;">w</span><span class="mpunct mtight">,</span><span class="mord mathdefault mtight">c</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">h</span><span class="mpunct mtight">,</span><span class="mord mathdefault mtight" style="margin-right:0.02691em;">w</span><span class="mpunct mtight">,</span><span class="mord mathdefault mtight">c</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span>分布是输入图像和重建图像在(h,w,c)处的值。<br>
语义分割部分decoder的输出在channel维度拼接在一起，用一个标准的pixel-wise softmax cross entropy loss <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>L</mi><mi>s</mi></msub></mrow><annotation encoding="application/x-tex">L_s</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">s</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>来训练，用一个权重来平衡类别偏差，每个类的权重是数据集中所有当前类别的像素的百分比的倒数经标准化（最多的类别权重为1）后得到。<br>
作者在COCO stuff数据集上进行训练，没有使用COCO提供的92个类别，而是构建了13个超类来更普遍的描述场景的语义信息。这样可以帮助提升模型的语义分割精度，减少所需局部描述子的数量，来获得更紧密的嵌入表示。所有动态物体都被包含在“other”类中，让模型更关注静态的物体。<br>
在网络结构方面，除了计算隐藏变量和decoder最后的输出层外，所有卷积层都使用了Exponential Linear Unit（ELU）激活函数，语义分割decoder输出层和计算隐藏变量的卷积层没有激活函数，图像重建decoder加入sigmoid激活函数。在encoder层中，步长为2，卷积核尺寸为2x2的max-pooling被用于下采样特征，而subpixel convolution用于上采样特征。<br>
全局图像描述子从隐藏变量<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>μ</mi></mrow><annotation encoding="application/x-tex">\mu</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathdefault">μ</span></span></span></span>中获得，其可以视作一个3D的数组，一组Mx(N+1)个D维的局部描述子，对N+1个decoder每个输入M个feature map；或者可以视为一个长度为DxMx(N+1)的向量，其中<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>D</mi><mo>=</mo><mfrac><mi>H</mi><mn>16</mn></mfrac><mo>×</mo><mfrac><mi>W</mi><mn>16</mn></mfrac></mrow><annotation encoding="application/x-tex">D=\frac{H}{16} \times \frac{W}{16}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">D</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.217331em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.872331em;"><span style="top:-2.6550000000000002em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mord mtight">6</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.08125em;">H</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.217331em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.872331em;"><span style="top:-2.6550000000000002em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mord mtight">6</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">W</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span><br>
<img src="https://jinyu-m.github.io/post-images/1610876566257.png" alt="" loading="lazy"></p>
<p>根据<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>μ</mi></mrow><annotation encoding="application/x-tex">\mu</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathdefault">μ</span></span></span></span>的第二种定义，作者计算了残差<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>μ</mi><mo>−</mo><mi>c</mi></mrow><annotation encoding="application/x-tex">\mu-c</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7777700000000001em;vertical-align:-0.19444em;"></span><span class="mord mathdefault">μ</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault">c</span></span></span></span>，其中c是由Mx(N+1)个在维度D上学习到的聚类中心在channel维度拼接而成的，它是用一个高斯分布随机初始化得到的，训练去最小化triplet embedding loss。该残差然后利用NetVLAD中的intra-normalization处理，用channel维度的L2-norm来防止描述子崩坏。然后，根据<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>μ</mi></mrow><annotation encoding="application/x-tex">\mu</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathdefault">μ</span></span></span></span>的第一种定义，作者标准化整个描述子，以适应用内积来计算cosine相似度。采用triplet embedding loss来训练：<br>
<img src="https://jinyu-m.github.io/post-images/1610876572257.png" alt="" loading="lazy"></p>
<h3 id="network-training">Network Training</h3>
<p>网络利用Adam训练，总的损失函数为<br>
<img src="https://jinyu-m.github.io/post-images/1610878335066.png" alt="" loading="lazy"><br>
作者用COCO数据集完成训练，由于没有true positive数据，所以作者用homography随机warp图像，随机将图像变黑来仿真夜视图像，随机左右翻转图像，来获得fake true positive。</p>
<h3 id="inference">Inference</h3>
<h4 id="keypoint-extraction">keypoint extraction</h4>
<p>全局描述子可以用最近邻搜索完成图像检索，但是需要阈值来确定匹配。为了解决这一问题，作者选择提取低层conv5层的卷积特征图中的最大激活区域来作为关键点。conv5层是全分辨率的，具有32维的特征图。为了获得的特征数量是有意义的，作者提取图像中每个大小为<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mfrac><mi>H</mi><msub><mi>N</mi><mi>w</mi></msub></mfrac><mo>×</mo><mfrac><mi>W</mi><msub><mi>N</mi><mi>w</mi></msub></mfrac></mrow><annotation encoding="application/x-tex">\frac{H}{N_w} \times \frac{W}{N_w}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.317431em;vertical-align:-0.44509999999999994em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.872331em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.16454285714285719em;"><span style="top:-2.357em;margin-left:-0.10903em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathdefault mtight" style="margin-right:0.02691em;">w</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.08125em;">H</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.44509999999999994em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.317431em;vertical-align:-0.44509999999999994em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.872331em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.16454285714285719em;"><span style="top:-2.357em;margin-left:-0.10903em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathdefault mtight" style="margin-right:0.02691em;">w</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">W</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.44509999999999994em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span>的划窗中的最大响应区域作为特征。重复的特征被剔除。</p>
<p>得到关键点后，作者设计了一种类似于BRIEF的描述子，在conv5层的输出特征图(32d)上，作者在关键点周围3x3的邻域内计算特征向量的残差，将这些残差拼接在一起，得到256d关键点描述子。这些描述子在匹配时直接用欧拉距离度量相似度，在匹配时，作者使用K(=2)-NN来搜索，利用传统的ratio test来确定一个有效的匹配，</p>
<h4 id="loop-closure-detection">loop closure detection</h4>
<p>作者用K(=7)-NN；来搜索可能的回环，然后用特征匹配来验证回环，只有可以通过RANSAC获得有效fundamental矩阵的匹配（也就是至少8对有效匹配）的图像才被认为是正确回环。</p>
<h2 id="performance-4"><em>Performance</em></h2>
<p><img src="https://jinyu-m.github.io/post-images/1610876832863.png" alt="" loading="lazy"><br>
作者展示了在wall、structure other、visual appearance分量上，database、positive、negative的相似度，可以看到，appearance产生了混淆，但是根据语义信息，则可以较好的分辨positive和negative。</p>
<p><img src="https://jinyu-m.github.io/post-images/1610876838298.png" alt="" loading="lazy"><br>
<img src="https://jinyu-m.github.io/post-images/1610876842507.png" alt="" loading="lazy"><br>
<img src="https://jinyu-m.github.io/post-images/1610876846137.png" alt="" loading="lazy"><br>
<img src="https://jinyu-m.github.io/post-images/1610876850180.png" alt="" loading="lazy"><br>
比NetVLAD表现好，很强了</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Deep Features]]></title>
        <id>https://jinyu-m.github.io/post/deep-local-features/</id>
        <link href="https://jinyu-m.github.io/post/deep-local-features/">
        </link>
        <updated>2020-10-01T01:30:16.000Z</updated>
        <content type="html"><![CDATA[<h1 id="magicpoint-magic-leap-pdf">MagicPoint (Magic Leap) <a href="https://arxiv.org/abs/1707.07410.pdf">pdf</a></h1>
<h2 id="abstract"><em>Abstract</em></h2>
<p>论文提出了一种基于两个DCN的point tracking system。第一个DCN就是MagicPoint，提取图像的显著二维坐标点（只有detector）；第二个DCN是MagicWrap，输入利用MagicPoint得到的一对图像中的二维坐标点信息，直接预测homography（不需要descriptor信息）。</p>
<h2 id="introduction"><em>Introduction</em></h2>
<p>作者先抛出了一个问题</p>
<blockquote>
<p>what would it take to build an ImageNet for SLAM?<br>
What would it take to build DeepSLAM?</p>
</blockquote>
<p>由于SLAM领域的真实数据往往无法获得很好的标注，而仿真数据无法囊括现实中的所有变化，所以可能引起domain adaptation issues和过拟合。所以用data-driven的深度学习方法去解决SLAM问题尚未解决。<br>
作者提到了两个点，首先利用预测图像的DCN去估计ego-motion是可能得，作者没有使用直接用图像估计6DoF位姿的监督方法，而是更关注geometric consistency；其次作者发现对于SLAM系统来说，预测和对齐关键点已经足够去解算pose，那么就不用去预测整幅图像了，直接估计homography足以满足需求。</p>
<h2 id="method"><em>Method</em></h2>
<h3 id="overview">overview</h3>
<figure data-type="image" tabindex="1"><img src="https://jinyu-m.github.io/post-images/1610855003571.png" alt="" loading="lazy"></figure>
<h3 id="magicpoint">MagicPoint</h3>
<p>作者设计MagicPoint的motivation就是认为hand-crafted detector需要过多的经验和技巧，往往无法cover所有的干扰，所以就直接用DCN去估计pixel-level的显著性，提取图像关键点。<br>
<img src="https://jinyu-m.github.io/post-images/1610855041578.png" alt="" loading="lazy"></p>
<p>结构类似于VGG。输入一个图像，得到一个同等分辨率的point response image，输出的每个pixel的值代表原图中这个位置是角点的概率。但是直接用encoder下采样-decoder上采样的结构恢复分辨率很耗算力，所以作者用网络得到了1/8大小的feature map，维度是65维（65个通道），这65个通道对应原图中不重叠的8x8的区域即一个dustbin通道（用于表示该8x8区域内无关键点），最后reshape到原本分辨率，这样decoder就没有参数了。<br>
训练时使用OpenCV作了一批虚拟的几何体，几何体的角点可以直接得到，然后加入噪声、光照变化等进行数据增强。训练时对feature map上每个cell计算cross-entropy loss。</p>
<h3 id="magicwarp">MagicWarp</h3>
<p>MagicWarp输入一对图像的关键点，然后估计homography。比如两幅120x160的图像输入MagicPoint，分别得到65x15x20的feature map。输入MagicWarp后，先从channel维度上进行concatenation，得到130x15x20的feature map，然后经过一个VGG型的encoder，再通过全连接层降维，得到一个9-d的向量，恢复成3x3的homography矩阵。<br>
<img src="https://jinyu-m.github.io/post-images/1610855072152.png" alt="" loading="lazy"></p>
<p>训练时，用虚拟数据采集虚拟三维几何体的图像，来获得训练数据，计算loss时，用估计的homography将图1的point投影到图2，然后计算投影误差，用L2-distance作为loss。<br>
<img src="https://jinyu-m.github.io/post-images/1610855099118.png" alt="" loading="lazy"></p>
<h2 id="一些看法"><em>一些看法</em></h2>
<p>MagicPoint学习了如何检测corner，基本取决于annotated data中keypoint的标注位置。比较有意思的点在于非参数上采样过程，depth-to-space的处理方法很有借鉴意义。后续SuperPoint也采用了这样上采样的方式，在recover resolution的同时参数也比较少。</p>
<hr>
<h1 id="superpoint-magic-leap-pdf-official-code-society-code">SuperPoint (Magic Leap) <a href="https://arxiv.org/abs/1712.07629.pdf">pdf</a> <a href="https://github.com/magicleap/SuperPointPretrainedNetwork">official code</a> <a href="https://github.com/rpautrat/SuperPoint">society code</a></h1>
<h2 id="abstract-2"><em>Abstract</em></h2>
<p>作者在MagicPoint的基础上增加了提取descriptor的部分，提出了homographic adaptation的数据增强方法，用来训练detector的repeatability，并且使得训练数据可以从虚拟的仿真数据拓展到MS-COCO等真实数据。</p>
<h2 id="introduction-2"><em>Introduction</em></h2>
<p>作者认为deep feature训练的关键在于带有标签的数据，但是人工标注的数据中，关键点往往是ill-defined，所以作者提出自监督方法训练，用网络本身去标注一批伪真值关键点，在此基础上进行训练，这样做，关键点更丰富，标注成本也更低。<br>
<img src="https://jinyu-m.github.io/post-images/1610855133950.png" alt="" loading="lazy"></p>
<p>第一步，其实就是之前提到的训练MagicPoint，先构建了一个仿真数据集Synthetic Shapes，训练了MagicPoint(b)。虽然之前的论文提到MagicPoint在应对各种干扰时重复率和准确率都很高，但是它丢失了一些潜在的关键点，为了解决这个问题，作者用Homographic Adaption去增强了MagicPoint标注的真实图像，得到了一个更符合预期的真实数据(b)，并用此去训练一个新的网络SuperPoint(c).</p>
<h2 id="architecture"><em>Architecture</em></h2>
<figure data-type="image" tabindex="2"><img src="https://jinyu-m.github.io/post-images/1610855143136.png" alt="" loading="lazy"></figure>
<p>SuperPoint由一个共享参数的encoder和两个task-specific decoders构成，采用vgg结构，图像(H x W)通过encoder，得到一个1/8大小(Hc x Wc)的feature map。<br>
在<strong>interest point decoder</strong>中，网络依旧延续MagicPoint的做法，采用非参数的上采样过程，feature map通过head降维到65 x Hc x Wc维，分别代表原图中与之对应的8x8区域内每个点是关键点的概率以及一个dustbin通道，dustbin用以表示该8x8区域内无关键点。<br>
在<strong>descriptor decoder</strong>中，网络先提取了Hc x Wc的semi-dense descriptor，每个descriptor代表与之对应的8x8区域内关键点的256-d descriptor（根据interest point detector，每8x8区域内只可能存在1/0个关键点），然后采用bi-cubic插值恢复到原分辨率。</p>
<h2 id="loss"><em>Loss</em></h2>
<p>训练interest point detector依旧采用对每个cell计算cross-entropy loss的方法：<br>
<img src="https://jinyu-m.github.io/post-images/1610855179667.png" alt="" loading="lazy"></p>
<p>为了使这部分Lp降低，需要让Y中为1的位置（即该点为关键点）在X中有较大的值，即增大该点为关键点的概率。<br>
训练descriptor extractor时，需要先找到匹配的点，然后用匹配点的descriptor来计算loss，所以先找判断图1(h,w)和图2(h',w')是否是一组匹配点：<br>
<img src="https://jinyu-m.github.io/post-images/1610855207797.png" alt="" loading="lazy"></p>
<p>p是cell的中心位置，H是真值homography，所以上式就是判断两个cell在原图中中心是否是符合真值homography的，如果是，则这两个位置时一对匹配点，可以计算它们descriptor的距离了：<br>
<img src="https://jinyu-m.github.io/post-images/1610855240388.png" alt="" loading="lazy"></p>
<p>上式中当图1和图2中两个点是匹配点时，s=1，则两个点的descriptor之间的cosine距离应该越大越好；而当两个点不匹配时，s=0，两个点的descriptor间的cosine距离越小越好。此处作者采用了hinge loss。<br>
综上，SuperPoint训练使用的loss：<br>
<img src="https://jinyu-m.github.io/post-images/1610855269479.png" alt="" loading="lazy"></p>
<p>分别计算图1和图2与真值图像的interest point loss，再计算图1与图2间的descriptor loss。</p>
<h2 id="training"><em>Training</em></h2>
<p>作者先训练了SuperPoint中提取关键点的detector pathway，其实就是MagicPoint，发现在虚拟数据集上MP表现很好，在真实数据中，当场景中有大量角点时，效果很好，但是在自然场景中，MP效果不如传统特征，所以作者提出<strong>用自监督方法在真实场景中训练网络</strong>，即Homographic Adaptation。</p>
<h2 id="homographic-adaptation"><em>Homographic Adaptation</em></h2>
<figure data-type="image" tabindex="3"><img src="https://jinyu-m.github.io/post-images/1610855280230.png" alt="" loading="lazy"></figure>
<p>可通过iterative homographic adaptation来提升效果。100次random homography效果较好。</p>
<h2 id="一些见解"><em>一些见解</em></h2>
<p>作为MagicPoint的升级版，SuperPoint我感觉其实是作者发现了MagicPoint只是单纯的去学习检测人工标注的那些点，比较局限，所以提出了homographic adaptation去进一步提升自己。并且加入了descriptor decoder，让整个系统更完整了。但是对比后续出现的特征，SuperPoint特征在训练时依旧采用监督的方法去训练detector，导致效果有待提升。在我的试验中，Bag of SuperPoint会提升loop closure的表现，但是用于SLAM系统（ORB-SLAM2）时，SuperPoint从一幅图像提取的特征过少，可能无法满足SLAM初始化的要求。</p>
<hr>
<h1 id="d2-net-pdf-code">D2-net <a href="https://arxiv.org/abs/1905.03561.pdf">pdf</a> <a href="https://github.com/mihaidusmanu/d2-net">code</a></h1>
<h2 id="abstract-3"><em>Abstract</em></h2>
<p>D2-net的主要在于提出了detect-and-describe的特征提取方法，不再是传统的detect-then-describe方法。作者认为从高层语义信息（CNN的高层conv输出的feature map）中提取的关键点位置要比从低层结构信息中提取的更稳定一些。detector和descriptor的参数实现了完全的共享。</p>
<h2 id="method-2"><em>Method</em></h2>
<p>D2的detector和descriptor是基于相同的feature map获取的。输入图像通过一个前向网络，得到C x H x W feature map，被视为得到了H x W 个C维的稠密局部特征。<br>
<img src="https://jinyu-m.github.io/post-images/1610855323128.png" alt="" loading="lazy"></p>
<h2 id="hard-feature-detectiontest"><em>Hard feature detection(test)</em></h2>
<p>由于D2得到feature map有很多层，每一层都可以作为一个detector去检测局部最大值进而提取local feature，所以在提取特征时，D2约定（i，j）为一个特征点当且仅当在该点具有最大值的那个detector中，该点是一个局部最大值：<br>
<img src="https://jinyu-m.github.io/post-images/1610855347489.png" alt="" loading="lazy"></p>
<p>直观地来讲，就是对于每个点，我们需要先找到该点对应C个detector中最显著的那个detector，然后验证在该detector中，当前点是否是局部最大的。</p>
<h2 id="soft-feature-detectiontraining"><em>Soft feature detection(training)</em></h2>
<p>但是上述detection方法是不可微的，所有无法用BP进行训练，为了实现end-to-end训练，作者soften了上述detection的方法。<br>
首先soften筛选最显著detector的部分，计算当前detector的ratio-to-max用以表示其显著性<br>
<img src="https://jinyu-m.github.io/post-images/1610855382324.png" alt="" loading="lazy"></p>
<p>其次soften计算局部最优值的部分，计算了9邻域内某点的soft local-max占比<br>
<img src="https://jinyu-m.github.io/post-images/1610855405362.png" alt="" loading="lazy"></p>
<p>最后，综合两部分的分数，取最大值，并做image-level normalization得到一个用来表征像素是特征点的概率的score map。</p>
<h2 id="multiscale-detection"><em>Multiscale detection</em></h2>
<p>为了获取具有更强尺度不变性的特征，D2使用图像金字塔，在测试阶段，将图像分别缩放至0.5,1,2倍，输入D2，得到feature map，并将之前由低分辨率图像获得的feature map插值放大到当前分辨率，与当前feature map相加，获得更稳定的feature map，在此map上进行detection，之前提取的关键点也被上采样（最近邻）到当前尺度，纳入提取的特征中。</p>
<h2 id="data"><em>Data</em></h2>
<p>D2用megadepth数据集进行训练，megadepth提供了同一场景不同视角、光照、设备下的照片，以及深度信息，每个场景由COLMAP进行建图，由此获得2d-3d特征点的对应信息，利用sfm提供的信息，我们可以计算同一场景下两幅图像的overlap，在训练中，D2使用overlap&gt;0.5的图像对，并用depth信息进行验证，去除被遮挡的像素。</p>
<h2 id="loss-2"><em>Loss</em></h2>
<p>为了提升descriptor的区分度，需要让对应点的descriptor距离较小，非对应点的descriptor距离较大，所以D2使用了triplet margin loss。对于图1和图2中一对匹配点A和B，positive descriptor distance=<br>
<img src="https://jinyu-m.github.io/post-images/1610855457062.png" alt="" loading="lazy"></p>
<p>在计算negative descriptor distance时，先挑选hardest negatives：<br>
<img src="https://jinyu-m.github.io/post-images/1610855477079.png" alt="" loading="lazy"></p>
<p>直观理解，N1为图1中位于A的邻域之外，与B最相似的点。N2同理。<br>
然后就可以分别计算A与N2，B与N1的descriptor距离，得到negative descriptor distance<br>
<img src="https://jinyu-m.github.io/post-images/1610855500930.png" alt="" loading="lazy"></p>
<p>最后，triplet margin loss如下：<br>
<img src="https://jinyu-m.github.io/post-images/1610855536914.png" alt="" loading="lazy"></p>
<p>通过该loss可以让descriptor的distinctiveness提升，而为了挑选去更具重复性的特征，D2在triple margin loss前加了一个权重<br>
<img src="https://jinyu-m.github.io/post-images/1610855560325.png" alt="" loading="lazy"></p>
<p>这样的话，为了让loss降低，网络需要学习去提取区分度更高（m更小）并且可重复性更好（权重更大）的点，并且优化提取的descriptor。</p>
<h2 id="training-test"><em>Training &amp; Test</em></h2>
<p>D2采用了VGG-16网络模型（~conv4_3），加载imagenet预训练模型即可提取特征，如果进行finetune只需训练最后一层。在测试时，最后一个max-pooling改为average-pooling，并且stride改为1（不降低分辨率），conv4_1到conv4_3使用空洞卷积，这样得到的feature map是1/4大小的，D2使用SIFT中的local refinement方法去修正关键点位置，descriptor被双线性插值到矫正后的位置。</p>
<h2 id="evaluation"><em>Evaluation</em></h2>
<figure data-type="image" tabindex="4"><img src="https://jinyu-m.github.io/post-images/1610855731905.png" alt="" loading="lazy"></figure>
<p>在HPatches上，D2表现较差，threshold小于6px时的MMA很低。D2提取的特征较多，匹配数量也较多。在camera localization和3D reconstruction实验中效果较好。</p>
<h2 id="一些见解-2"><em>一些见解</em></h2>
<p>D2在strict matching上的表现较差，但是在localization和reconstruction任务上却表现不错。这其中的原因值得思考，我们一般做slam时要求特征更快更准，“更准”的要求真的必要么？<br>
在inference的时候，网络的forward速度很快，~x ms，但是detection和恢复position误差的部分都需要~x00 ms。感觉可以从detection的方法上改进一下。<br>
在我的试验中，发现D2其实提取的soft detection score还是很关注纹理复杂的区域的，但是这些区域很可能是dynamics，所以加入语义的方法进行筛选可能是个点。<br>
D2定位精度差的原因，我觉得是因为它是在1/8的feature map上进行训练，在1/4的feature map上进行inference，所以直接插值到原分辨率造成了这种差异，因为在hpatches上threshold大于6px时D2的效果还是不错。<br>
D2在训练时有考虑repeatable（因为直接用correspondence训练的）和disciminative，但是我觉得这种用triplets或者quadruplets去采样anchor、positive和negative会不会造成其实对disciminative的提升不大呢？</p>
<hr>
<h1 id="r2d2-pdf-code">R2D2 <a href="http://arxiv.org/abs/1906.06195">pdf</a> <a href="https://github.com/naver/r2d2">code</a></h1>
<h2 id="abstract-4"><em>Abstract</em></h2>
<p>作者在这篇工作中，提出一个观点：</p>
<blockquote>
<p>In this work, we argue that salient regions are not necessarily discriminative, and therefore an harm the performance of the description. Furthermore, we claim that descriptors should be learned only in regions for which matching can be performed with high confidence.</p>
</blockquote>
<p>简单来说，就是之前的训练detector的方法，都是更关注检测出的特征是否repeative，这样的特征可能不够discriminative，比如重复性的纹理。所以作者认为，这样的训练方法有弊端。并且由于提取的salient region不够discriminative，所以descriptor的训练也不够完善。所以这篇工作中，作者要提取sparse，repeative and disciminative特征，依旧使用detect-and-descibe的提取方法。</p>
<h2 id="introduction-3"><em>Introduction</em></h2>
<figure data-type="image" tabindex="5"><img src="https://jinyu-m.github.io/post-images/1610855776875.png" alt="" loading="lazy"></figure>
<p>作者先更详细直观地阐述了一下motivation，就像上面这两幅示例图。第一幅图中，对于detector来说，只有黑三角形附近的区域是有利于提取keypoint的，但是所有包含该三角形的patch都可以提取同等可靠的descriptor，所以匹配的时候会有误差。第二幅图中，对于detector，所有棋盘网格的角点都可以提取出同等可靠的keypoint，但是它们都不利于提取descriptor，因为完全重复，匹配的时候会出现混淆。<br>
所以，在这篇论文，作者认为detection和description是不可分割的，要一起训练（其实就是detect-and-descibe），并且提取的特征不关要repeatable还需要reliable for matching（感觉就是discrimative）。所以R2D2会分别根据basenet输出的feature map得到两张repeatability confidence map和reliability confidence map，然后综合两张map提取特征。</p>
<h2 id="methods"><em>Methods</em></h2>
<figure data-type="image" tabindex="6"><img src="https://jinyu-m.github.io/post-images/1610855799281.png" alt="" loading="lazy"></figure>
<p>R2D2采用全卷积网络结构，输入H x W大小的图像，输出三部分：第一部分D x H x W feature map X，视作H x W个D维局部特征，每个像素对应一个局部特征；第二部分是一个H x W heatmap S，每个位置上的值代表该点特征的sparse和repeatable，值在[0,1]之间，为了获得稀疏的特征，只提取S中局部最大值作为特征；第三部分是H x W heatmap R，对应特征的reliability或者说disciminativeness.<br>
网络的backbone选用L2-net（不降低分辨率），但是将最后一个8x8的卷积换做3个2x2卷积，来减少参数。D=128。为了获得S和R，在backbone后接了两个1x1卷积+softmax。</p>
<h2 id="loss-3"><em>Loss</em></h2>
<h3 id="repeatability">repeatability</h3>
<p>首先训练特征的repeatability，作者认为</p>
<blockquote>
<p>In fact, using supervision essentially boils down in this case to copying an existing detector rather than discovering better and easier keypoints.</p>
</blockquote>
<p>就是用监督学习的训练方法，只是在学习那些现成的detector的检测策略（这个意义上讲，superpoint其实也是这样的，只不过通过homographic adaptation进行了一个data augmentation，去提升性能）。所以作者希望直接训练S，让其跟随图像变换而一起变换。<br>
假设图1，图2，当图像是真实图像时，用optical flow或stereo matching的方法去获得两幅图像中像素级的对应关系U，当图像是虚拟的仿真图像时，那么U可以直接获得了。分别获得两幅图像的S1和S2，利用U将S2对应到S2U。如果S是covariant to transformations，那么S1和S2U应该是一致的。<br>
所以，可以直接对S1和S2U求取cosine相似度，相似度越大，说明S的表现越好，但是warp后可能会出现occlusions、warp artifacts or border effects，所以作者用了一个局部的cosine相似度，求取多个patch的cosine相似度：<br>
<img src="https://jinyu-m.github.io/post-images/1610855826572.png" alt="" loading="lazy"></p>
<p>Lcosine只能保证S1和S2U相似，但是容易导致S1和S2U变成常值。由于最后使用S是要挑选local maxima，所以还需要让S的局部峰值变大：<br>
<img src="https://jinyu-m.github.io/post-images/1610855848629.png" alt="" loading="lazy"></p>
<p>最后，训练repeatability的loss就是以上两部分的加权：<br>
<img src="https://jinyu-m.github.io/post-images/1610855870194.png" alt="" loading="lazy"></p>
<h3 id="reliability-ie-discriminativeness">Reliability, i.e., Discriminativeness</h3>
<p>这部分是为了让具有得到一个可以度量discriminative的score map，让具有discriminative descriptor的区域具有较大的可信度。<br>
使用Average Precision Loss进行训练descriptor，就是给一对ground-truth batch，计算batch1中每个descriptor与batch2中每个des之间的距离，然后计算batch中每个query的AP loss，用下面公式进行训练：<br>
<img src="https://jinyu-m.github.io/post-images/1610855909261.png" alt="" loading="lazy"></p>
<p>这篇论文中也用到了AP loss，区别在于原本AP loss使用标准的keypoint detector去提取ground-truth batch，而在这里根据前文可以知道，提供了U，所以直接用U就可以获得ground-truth batch了。<br>
在这一部分，作者还提出，想要提取利于匹配的特征，不光要考虑图像纹理的丰富度，还要考虑其是否discriminative。所以作者用R去筛选discriminative region中的特征，只有这部分特征会对网络训练产生影响。<br>
<img src="https://jinyu-m.github.io/post-images/1610855931430.png" alt="" loading="lazy"></p>
<p>使用这种loss，为了使loss减小，当AP(i,j)小于k时，即该点descriptor不够discriminative，那么Rij应当为0,；当该点descriptor足够discriminative时，Rij应当为1。</p>
<h2 id="test"><em>Test</em></h2>
<p>在测试时，也采用了图像金字塔去获取更丰富的特征，从原分辨率开始，逐渐下采样，直到图像小于128px。每次从图像中利用S的局部最大值提取特征，保存。最后从所有保存的特征中，根据SR挑选top-K特征。</p>
<h2 id="training-2"><em>Training</em></h2>
<p>R2D2需要获得图像间的ground-truth correspondence。所以作者提出两种方法，一种就是常规的图2是由图1经过一种确定的transformation变换而来的；另一种，是作者自己提出一种pipeline，区别于之前用完全利用sfm获得dense correspondence（感觉在说D2...），作者先用sfm生成图像的3D点与6DoF位姿（sparse），对于sufficient overlap图像，用sfm提供的2D correspondence计算F matrix（作者发现这比直接用图像位姿去算要更可靠），然后用EpicFlow获得高质量的dense correspondence，作者在DeepMatching中加入epipolar constraint去增强方法，在EpicFlow的第一步获得了semi-dense correspondence。但是光流法可能无法应对有遮挡的情况，所以对于DeepMatching的输出，作者计算了一个connected consistent neighbors的图，只保留属于较大（至少有20个matches）connected component的matches，然后用一个thresholded kernel density estimator在验证后的matches中估计一个mask，作为optical flow可信度的度量。</p>
<h2 id="data-2"><em>Data</em></h2>
<p>Oxford，Paris，Aachen Day-Night.</p>
<h2 id="results"><em>Results</em></h2>
<figure data-type="image" tabindex="7"><img src="https://jinyu-m.github.io/post-images/1610855953805.png" alt="" loading="lazy"></figure>
<p>这张图很直观的表现出r2d2的优点，对于repeatability来说（第2行图），天空是可重复性很高的，但是对于特征来说，由于天空有大量重复纹理或无纹理，所以不利于区分，所以其上的特征reliability很低，r2d2综合考虑了这两点，所以提取的特征比较好。</p>
<figure data-type="image" tabindex="8"><img src="https://jinyu-m.github.io/post-images/1610856008506.png" alt="" loading="lazy"></figure>
<p>在hseq上效果也很好。</p>
<h2 id="一些见解-3"><em>一些见解</em></h2>
<p>r2d2很明确的定义了特征的两种特性，repeatability和reliability，其中reliability就是discriminativeness。<br>
目前bag of others中据说效果很好的一种特征了，很显式的将特征的repeatable和disciminative纳入loss中，让网络去学习。<br>
完全没有人工标记的特征点了，所以是网络自己去学习判断和提取特征——superpoint<br>
在原分辨率的feature map上提取特征，定位准确度高了——D2<br>
考虑到了local maxima可能并不全是利于匹配的特征，要考虑disciminative——D2+SuperPoint</p>
<hr>
<h1 id="sekd-pdf-code">SEKD <a href="http://arxiv.org/abs/2006.05077">pdf</a> <a href="https://github.com/aliyun/Self-Evolving-Keypoint-Demo">code</a></h1>
<h2 id="abstract-5"><em>Abstract</em></h2>
<p>论文提出，现存的一些特征提取方法（hand-crafted or learnt）都没有考虑到detector和descriptor之间的相互促进作用，所以导致效果或多或少不尽人意。所以这篇文章，其实是设计了一种自监督训练框架，强调repeatability和reliability，用完全无标注的自然图像去学习特征。</p>
<h2 id="introduction-4"><em>Introduction</em></h2>
<p>作者更加细化的分别定义了detector和descriptor的repeatability和reliability：<br>
<img src="https://jinyu-m.github.io/post-images/1610875758330.png" alt="" loading="lazy"></p>
<p>总的来说就是两大特性，细分为四部分：（1）Repeatability：detector的repeatability体现在如果两幅图像描述了同一场景，那么在图1中“看到”的一个keypoint在图2中也应该可以看到；descriptor的repeatability体现在相同真实位置的关键点在不同图像中应该是invariant；（2）Reliability（其实可以理解为我们常说的disciminativeness）：detector的reliability体现在给定描述子的计算方法，一个detected keypoint应该可靠的区别于其他点，直白点说就是应该落在利于分辨的区域，避开重复性纹理区域；descriptor的reliability体现在给定了detection方法，计算出的描述子应该足够区分这些detected keypoints。<br>
思考一下上面的这些特性，其实repeatability特性是detector和descriptor自己的inherent property，而reliability则体现了detector与descriptor之间的interactive property。<br>
这篇论文别出心裁，不一起训练detector和descriptor（SuperPoint是先训detector后训descriptor，D2和R2D2是一起训），而是采用了一种iterative training strategy。利用上面说的inherent and interactive property，去直到训练。<br>
简单的说，找出所有具有reliable descriptor的keypoints（descriptor repeatability），作为ground-truth去训练detector（detector reliability），用优化后的detector去检测keypoints（detector repeatability），基于这些keypoints训练descriptor（descriptor reliability）。重复这一过程，直到模型收敛。这就是self-evolving framework。整个训练过程不需要带有标注的数据。<br>
（其实，我感觉和SuperPoint中提到的Iterative Homographic Adaptation有些相似，不过SEKD将这个流程变为一个end-to-end的训练过程，从零开始训练了）</p>
<h2 id="architecture-2"><em>Architecture</em></h2>
<figure data-type="image" tabindex="9"><img src="https://jinyu-m.github.io/post-images/1610875782335.png" alt="" loading="lazy"></figure>
<p>SEKD采用了类似于SuperPoint的结构，backbone由1个卷积和9个ResNet_v2模块，得到1/4大小的feature map。detector branch由2个deconv和1个softmax构成，输出2 x H x W的map P，代表keypoint probability，为了提升定位精度，有两个来自低层feature map的shortcut。descriptor branch由1个ResNet_v2模块和1个bi_linear上采样层构成，输出C-d描述子。</p>
<h2 id="self-evolving"><em>Self-Evolving !</em></h2>
<figure data-type="image" tabindex="10"><img src="https://jinyu-m.github.io/post-images/1610875797640.png" alt="" loading="lazy"></figure>
<p>在训练过程中，网络利用两方面的监督：（1）关键点的选取，有可靠descriptor的point被认为是keypoint；（2）不同图像间的keypoints correspondence，这个通过用一张图像，经过affine transformation获得匹配图像，因此correspondence也可以直接获得。<br>
训练的流程基本分为四步：<br>
1.用detector branch得到keypoint probability map P，利用NMS筛选keypoint；<br>
2.在这些keypoint上，通过增强descriptor的repeatability和reliability来更新descriptor branch；<br>
3.计算keypoint，具有reliable（repeatable and distinct） descriptor的point被作为keypoints;<br>
4.在这些新的keypoint上，根据detector的repeatability和reliability来更新detector branch。</p>
<h3 id="1detect-keypoints-using-detector">1.Detect Keypoints using Detector</h3>
<figure data-type="image" tabindex="11"><img src="https://jinyu-m.github.io/post-images/1610875823497.png" alt="" loading="lazy"></figure>
<p>具有较高响应的点被视为可能的keypoint，经过NMS，每张图像可以获得1000个keypoint。但是由于不同图像条件下，可能没法取到一样的keypoint，所以作者采用了affine adaption方法，即对于原始图像进行random affine transformation和color jitter，获得新的图像后经过网络，获得不同图像条件下的P，最后映射回原图，取平均，得到最后的P.</p>
<h3 id="2update-keypoint-descriptor">2.Update Keypoint Descriptor</h3>
<p>根据上一节，获得了一张图像I中的keypoints Q，对I和Q进行random affine transformation和color jitter H，得到I^和Q^，并且可以获得特征的匹配关系&lt;Q,Q^&gt;，那么根据descriptor repeatability，匹配特征的des应该很靠近，根据descriptor reliability，不匹配的特征应该有很好的区分度。所以作者使用了triplet loss with hardest example mining去训练descriptor。<br>
<img src="https://jinyu-m.github.io/post-images/1610875850474.png" alt="" loading="lazy"></p>
<p>除此之外，由于网络使用共享参数的backbone，所以为了保证detection的结果不会变化，作者还加入了一个损失函数：<br>
<img src="https://jinyu-m.github.io/post-images/1610875864336.png" alt="" loading="lazy"></p>
<p>其中N’表示更新后的N。所以，用于更新descriptor的总loss为：<br>
<img src="https://jinyu-m.github.io/post-images/1610875877898.png" alt="" loading="lazy"></p>
<h3 id="3compute-keypoints-via-descriptor">3.Compute Keypoints via Descriptor</h3>
<p>更新了descriptor后，下一步是要从descriptor map中提取keypoint。特征的reliability可从repeatability和distinctiveness两方面度量。对于repeatability：<br>
<img src="https://jinyu-m.github.io/post-images/1610875894075.png" alt="" loading="lazy"></p>
<p>D越低，说明descriptor在相同位置上更靠近，repeatability更好。而对于distinctiveness：<br>
<img src="https://jinyu-m.github.io/post-images/1610875901166.png" alt="" loading="lazy"></p>
<p>D‘越大，说明descriptor在不同位置的差异越大，distinctiveness更好。所以综合两点，特征的reliability定义为：<br>
<img src="https://jinyu-m.github.io/post-images/1610875908312.png" alt="" loading="lazy"></p>
<p>R越大，说明特征更reliable。<br>
由于匹配的图像对是用affine transformation获得的，所以图像中可能一些点没有对应的R，所以这里依然采用了之前所用的affine adaption方法来获得一张average R。<br>
另外，计算D‘的计算量很大，所以作者在邻域内计算D'：<br>
<img src="https://jinyu-m.github.io/post-images/1610875919455.png" alt="" loading="lazy"></p>
<p>在实验中，作者在1/4，1倍分辨率的descriptor map上分别计算R，然后将两个map融合，一起使用，以获得足够精细的R。</p>
<h3 id="4update-keypoint-detector">4.Update Keypoint detector</h3>
<p>根据descriptor计算出的keypoint可以看作ground-truth对detector进行训练，作者使用了focal loss：<br>
<img src="https://jinyu-m.github.io/post-images/1610875934008.png" alt="" loading="lazy"></p>
<p>同时，为了减小匹配图像对上detection结果的差异，作者加入了：<br>
<img src="https://jinyu-m.github.io/post-images/1610875941039.png" alt="" loading="lazy"></p>
<p>来训练detector的repeatability。并且还需要保证descriptor在这期间不受干扰，所以加入了：<br>
<img src="https://jinyu-m.github.io/post-images/1610875946516.png" alt="" loading="lazy"></p>
<p>最后综合三部分，训练detector的loss为：<br>
<img src="https://jinyu-m.github.io/post-images/1610875952090.png" alt="" loading="lazy"></p>
<h2 id="training-3"><em>Training</em></h2>
<p>特征在MS COCO验证集上完成训练。<br>
训练进行了5个iteration，每个iteration中分别训练detector和descriptor20个epoches</p>
<h2 id="model-size"><em>Model Size</em></h2>
<figure data-type="image" tabindex="12"><img src="https://jinyu-m.github.io/post-images/1610875962237.png" alt="" loading="lazy"></figure>
<h2 id="performance"><em>Performance</em></h2>
<figure data-type="image" tabindex="13"><img src="https://jinyu-m.github.io/post-images/1610875967248.png" alt="" loading="lazy"></figure>
<hr>
<h1 id="l2-net-2017-pdf-code">L2-Net (2017) <a href="https://ieeexplore.ieee.org/document/8100132">pdf</a> <a href="https://github.com/yuruntian/L2-Net">code</a></h1>
<h2 id="abstract-6"><em>Abstract</em></h2>
<p>这篇论文提出了一种在欧拉空间中表现很好的CNN特征，突出点有四点：（1）提出了一种渐进的采样策略，使得网络可以在很少epoch内获得数以亿计的训练样本；（2）重视descriptor之间的相对距离；（3）对中间的feature map有格外的监督；（4）考虑des的compactness。</p>
<h2 id="architecture-3"><em>Architecture</em></h2>
<figure data-type="image" tabindex="14"><img src="https://jinyu-m.github.io/post-images/1610875975445.png" alt="" loading="lazy"></figure>
<p>网络结构如上图，在BN层中，作者设置权重为1，方差为0，不进行更新。在输出层，作者使用了local response normalization layer（LRN）来输出单位des。L2-Net将32 x 32的patch转变为128维的des。作者也使用了central-surround L2-Net，将两个L2-Net concat，左边的网络输入的是原始输入，右边的网络输入的是原本patch经过crop和resize后的中心部分（据说是可以处理scale不变性）。</p>
<h2 id="training-data"><em>Training data</em></h2>
<p>L2-Net用Hpatches和Brown数据集进行训练，这两个数据集都提供了matched pairs。<br>
在加载训练数据时，从P个3D点中挑选p1个点，然后从P-p1中挑选p2个点，得到了p(p1+p2)个点，对每个p，随机获取一个匹配的patch，这样就获得了2p个训练数据作为网络的输入，记为X，X是32 x 32 x 2p维的。网路的输出记为Y，Y是128 x 2p维的。由于网络的输出经过了normalization，所以可以定义距离矩阵<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>D</mi><mo>=</mo><mi>s</mi><mi>q</mi><mi>r</mi><mi>t</mi><mo>(</mo><mn>2</mn><mi>x</mi><mo>(</mo><mn>1</mn><mo>−</mo><msubsup><mi>Y</mi><mn>1</mn><mi>T</mi></msubsup><msub><mi>Y</mi><mn>2</mn></msub><mo>)</mo><mo>)</mo></mrow><annotation encoding="application/x-tex">D=sqrt(2 x (1 - Y_1^T Y_2))</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">D</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault">s</span><span class="mord mathdefault" style="margin-right:0.03588em;">q</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mord mathdefault">t</span><span class="mopen">(</span><span class="mord">2</span><span class="mord mathdefault">x</span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.0913309999999998em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.22222em;">Y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-2.4518920000000004em;margin-left:-0.22222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">T</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.24810799999999997em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.22222em;">Y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.22222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mclose">)</span></span></span></span>。<br>
D中包含了p x p个pairs，对角线上的p个pair是positive matched pair，非对角线上的pair是negative pairs。<strong>(Q: 点都是随机取得，那在原本的p点中就可能会出现相互匹配的点，那么非对角线上的pair也不一定都是negative吧)</strong></p>
<h2 id="loss-function"><em>Loss function</em></h2>
<p>损失函数由三部分构成，第一部分，作者利用相对距离去约束匹配和非匹配的pair；第二部分，作者强调des的紧凑性，即des的各维信息之间应该没有相互关系；第三部分，作者对中间的feature map进行了约束。</p>
<h3 id="descriptor-similarity">descriptor similarity</h3>
<p>des之间的相互距离在pair是匹配的时候最小，所以体现在D中，就是对角线上的元素应当是行、列中最小的。定义行相似矩阵和列相似矩阵：<br>
<img src="https://jinyu-m.github.io/post-images/1610875987633.png" alt="" loading="lazy"></p>
<p><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>S</mi><mi>c</mi></msup></mrow><annotation encoding="application/x-tex">S^c</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.664392em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">c</span></span></span></span></span></span></span></span></span></span></span>可以理解维<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>y</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">y_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>匹配到<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>y</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">y_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>的概率，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>S</mi><mi>r</mi></msup></mrow><annotation encoding="application/x-tex">S^r</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.664392em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">r</span></span></span></span></span></span></span></span></span></span></span>可以理解维<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>y</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">y_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>匹配到<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>y</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">y_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>的概率。为了让匹配的des之间距离减小，loss设计为：<br>
<img src="https://jinyu-m.github.io/post-images/1610875993516.png" alt="" loading="lazy"></p>
<h3 id="descriptor-compactness">descriptor compactness</h3>
<p>作者发现过拟合问题是由于des各维度之间的correlation（我理解的是des出现了冗余）。所以作者加入了对des compactness的考虑。<br>
作者设计了一个correlation matrix R：<br>
<img src="https://jinyu-m.github.io/post-images/1610876001934.png" alt="" loading="lazy"></p>
<p>其中bi表示q个patch的des中第i维元素的集合，是个行向量。（我理解是对des的每一维调整均值后，计算cosine相似度，r=0，说明计算的两维des间正交，不相关）所以R的非对角线位置的元素需要靠近0。所以des compactness的loss为：<br>
<img src="https://jinyu-m.github.io/post-images/1610876008803.png" alt="" loading="lazy"></p>
<p>如果加入了LRN后，每维数据的均值为0，所以Rs的计算可以简化为：<br>
<img src="https://jinyu-m.github.io/post-images/1610876023108.png" alt="" loading="lazy"></p>
<h4 id="intermediate-feature-maps">Intermediate feature maps</h4>
<p>用E1的loss去计算网络中间的feature map上的similarity matrix G，然后构建了loss：<br>
<img src="https://jinyu-m.github.io/post-images/1610876030491.png" alt="" loading="lazy"></p>
<p>作者称之为Discriminative Intermediate Feature maps (DIF)，并且发现在BN层后面加入DIF会提升效果，所以作者在第一个和最后一个BN层后计算了DIF。</p>
<hr>
<h1 id="doap-2018-paperap-loss-code">DOAP (2018) <a href="https://openaccess.thecvf.com/content_cvpr_2018/papers/He_Local_Descriptors_Optimized_CVPR_2018_paper.pdf">paper</a><a href="https://github.com/kunhe/FastAP-metric-learning/blob/master/pytorch/FastAP_loss.py">AP loss code</a></h1>
<p>为了看懂r2d2的AP loss，特地去看了这篇论文，算是用AP loss描述子的开山之作。</p>
<h2 id="abstract-7"><em>Abstract</em></h2>
<p>特征匹配，本质上就是特征描述子的最近邻检索。在这篇工作中，作者用神经网络直接优化ranking-based retrieval的指标，Average Precision。这一通用的方法可以视作比传统的local ranking方法更先进的listwise learning方法。</p>
<h2 id="introduction-5"><em>Introduction</em></h2>
<p>作者认为，特征的训练应该与其要嵌入的任务结合在一起。观察特征匹配任务，作者发现这其实就是一个最近邻检索问题。因此，作者基于对ranking-based retreval评价指标Average Precision（AP）的直接优化提出一种listwise learning方法，通过训练特征描述子来学习对特征进行排序（匹配）。本文的特征有二进制和浮点数两种形式的描述子。<br>
本文工作的一大特点是其通用性，即模型直接优化的是与任务无关的最近邻匹配阶段。虽然如此，为了获得用于特征匹配的描述子，作者还是加入了一些专用于某些任务的改进。首先，作者利用Spatial Transformer Module来在不需要额外监督的情况下，有效地处理几何噪声，提升匹配的鲁棒性。在有挑战性的HPatches上，作者设计了一种基于聚类的方法，来挖掘patch-level的监督，以此提升描述子在图像匹配任务中的表现。</p>
<h2 id="optimizing-descriptor-for-matching"><em>Optimizing Descriptor for Matching</em></h2>
<p>这一节作者先指出描述子匹配就是最近邻检索，然后讨论了一种learning to rank方法来优化ranking-based检索表现。</p>
<h3 id="nearest-neighbor-matching">Nearest Neighbor Matching</h3>
<p><img src="https://jinyu-m.github.io/post-images/1610876069384.png" alt="" loading="lazy"><br>
图1展示了由两幅图像计算F矩阵的流程，其中特征匹配过程可以描述为：每幅图中有M个特征，计算两幅图像的pairwise距离矩阵，矩阵共<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>M</mi><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">M^2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141079999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.10903em;">M</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span>个元素，对于图1中的每个特征，在图2中搜索其最近邻。相互为最近邻的匹配被当作候选匹配，输入之后的流程（如RANSAC）。<br>
作者指出，这一匹配流程就是最近邻检索：图1的每个特征被用于检索数据库，数据库是由图2中特征构成的。为了获得好的表现，正确的匹配应该作为top retrieval输出，错误的匹配则应该尽可能“排名较低”。匹配的表现直接反映了描述子的优劣。为了评估最近邻匹配的表现，作者采用了Average Precision（AP)来作为评价指标。AP是基于二值化相关性假设来评估检索表现的，即检索结果与query相关或不相关。这与特征匹配是相适应的。</p>
<h3 id="optimizing-average-precision">Optimizing Average Precision</h3>
<p>令<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi mathvariant="script">X</mi></mrow><annotation encoding="application/x-tex">\mathcal{X}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord"><span class="mord mathcal" style="margin-right:0.14643em;">X</span></span></span></span></span>为图像块空间，而<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>S</mi><mo>⊂</mo><mi mathvariant="script">X</mi></mrow><annotation encoding="application/x-tex">S \subset \mathcal{X}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.72243em;vertical-align:-0.0391em;"></span><span class="mord mathdefault" style="margin-right:0.05764em;">S</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">⊂</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord"><span class="mord mathcal" style="margin-right:0.14643em;">X</span></span></span></span></span>为database。对于每个query patch <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>q</mi><mo>∈</mo><mi mathvariant="script">X</mi></mrow><annotation encoding="application/x-tex">q \in \mathcal{X}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7335400000000001em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">q</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord"><span class="mord mathcal" style="margin-right:0.14643em;">X</span></span></span></span></span>，令<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msubsup><mi>S</mi><mi>q</mi><mo>+</mo></msubsup></mrow><annotation encoding="application/x-tex">S^+_q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.154439em;vertical-align:-0.383108em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.771331em;"><span style="top:-2.4530000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03588em;">q</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">+</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.383108em;"><span></span></span></span></span></span></span></span></span></span>为它在<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>S</mi></mrow><annotation encoding="application/x-tex">S</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.05764em;">S</span></span></span></span>匹配的patches，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msubsup><mi>S</mi><mi>q</mi><mo>−</mo></msubsup></mrow><annotation encoding="application/x-tex">S^-_q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.154439em;vertical-align:-0.383108em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.771331em;"><span style="top:-2.4530000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03588em;">q</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">−</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.383108em;"><span></span></span></span></span></span></span></span></span></span>为非匹配的。给定距离度量方式D，令<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mo>(</mo><msub><mi>x</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>x</mi><mn>2</mn></msub><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo separator="true">,</mo><msub><mi>x</mi><mi>n</mi></msub><mo>)</mo></mrow><annotation encoding="application/x-tex">(x_1,x_2,...,x_n)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>为<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msubsup><mi>S</mi><mi>q</mi><mo>+</mo></msubsup><mo>⋃</mo><msubsup><mi>S</mi><mi>q</mi><mo>−</mo></msubsup></mrow><annotation encoding="application/x-tex">S^+_q \bigcup S^-_q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.154439em;vertical-align:-0.383108em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.771331em;"><span style="top:-2.4530000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03588em;">q</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">+</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.383108em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop op-symbol small-op" style="position:relative;top:-0.0000050000000000050004em;">⋃</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.771331em;"><span style="top:-2.4530000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03588em;">q</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">−</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.383108em;"><span></span></span></span></span></span></span></span></span></span>中所有元素依照与q的距离从小到大的排列。给定这一排序，AP是在不同位置测得准确度(<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>P</mi><mi>r</mi><mi>e</mi><mi>c</mi><mi mathvariant="normal">@</mi><mi>K</mi></mrow><annotation encoding="application/x-tex">Prec@K</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mord mathdefault">e</span><span class="mord mathdefault">c</span><span class="mord">@</span><span class="mord mathdefault" style="margin-right:0.07153em;">K</span></span></span></span>)的平均值：<br>
<img src="https://jinyu-m.github.io/post-images/1610876077110.png" alt="" loading="lazy"><br>
AP只有当所有来自<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msubsup><mi>S</mi><mi>q</mi><mo>+</mo></msubsup></mrow><annotation encoding="application/x-tex">S^+_q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.154439em;vertical-align:-0.383108em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.771331em;"><span style="top:-2.4530000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03588em;">q</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">+</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.383108em;"><span></span></span></span></span></span></span></span></span></span>的patch都排在<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msubsup><mi>S</mi><mi>q</mi><mo>−</mo></msubsup></mrow><annotation encoding="application/x-tex">S^-_q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.154439em;vertical-align:-0.383108em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.771331em;"><span style="top:-2.4530000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03588em;">q</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">−</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.383108em;"><span></span></span></span></span></span></span></span></span></span>之前时，会达到最优值。</p>
<p>AP的优化也可以当作一个metric learning问题，其目标是学习一个可以让AP在retrieval时达到最优的距离度量D。理想的来说，如果上述过程都可以用可微的方式表示出来，那么AP就可以利用链式法则来优化。然而，排序过程是不可微的，连续变化的输入会引起AP值不连续的跳变。因此，appropriate smoothing对于引出可微的近似AP很重要。</p>
<h4 id="binary-descriptor">Binary Descriptor</h4>
<p>二进制描述子在应用中所需内存较少，匹配更快。<br>
在这里，一个神经网络F被用于模拟一种映射，将patches映射到一个低维的hamming空间中，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>F</mi><mo>:</mo><mi mathvariant="script">X</mi><mo>→</mo><msup><mrow><mo>{</mo><mo>−</mo><mn>1</mn><mo separator="true">,</mo><mn>1</mn><mo>}</mo></mrow><mi>b</mi></msup></mrow><annotation encoding="application/x-tex">F: \mathcal{X} \rightarrow {\{-1,1\}}^b</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">F</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord"><span class="mord mathcal" style="margin-right:0.14643em;">X</span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">→</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.2390079999999999em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord"><span class="mopen">{</span><span class="mord">−</span><span class="mord">1</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">1</span><span class="mclose">}</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9890079999999999em;"><span style="top:-3.2029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">b</span></span></span></span></span></span></span></span></span></span></span>，对于hamming距离，它取{0,1,...,b}间的整数，AP可以通过直方图<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>h</mi><mo>+</mo></msup><mo>=</mo><mo>(</mo><msubsup><mi>h</mi><mn>0</mn><mo>+</mo></msubsup><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo separator="true">,</mo><msubsup><mi>h</mi><mi>b</mi><mo>+</mo></msubsup><mo>)</mo></mrow><annotation encoding="application/x-tex">h^+=(h^+_0,...,h^+_b)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.771331em;vertical-align:0em;"></span><span class="mord"><span class="mord mathdefault">h</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.771331em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">+</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.1127699999999998em;vertical-align:-0.3013079999999999em;"></span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.811462em;"><span style="top:-2.433692em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span><span style="top:-3.1031310000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">+</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.266308em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.811462em;"><span style="top:-2.3986920000000005em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">b</span></span></span><span style="top:-3.1031310000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">+</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3013079999999999em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>的元素来封闭式计算，其中<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msubsup><mi>h</mi><mi>k</mi><mo>+</mo></msubsup><mo>=</mo><msub><mo>∑</mo><mrow><mi>x</mi><mo>∈</mo><msubsup><mi>S</mi><mi>q</mi><mo>+</mo></msubsup></mrow></msub><mtext mathvariant="bold">1</mtext><mo>[</mo><mi>D</mi><mo>(</mo><mi>q</mi><mo separator="true">,</mo><mi>x</mi><mo>)</mo><mo>=</mo><mi>k</mi><mo>]</mo></mrow><annotation encoding="application/x-tex">h^+_k=\sum_{x \in S^+_q} \textbf{1}[D(q,x)=k]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.1127699999999998em;vertical-align:-0.3013079999999999em;"></span><span class="mord"><span class="mord mathdefault">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.811462em;"><span style="top:-2.3986920000000005em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span><span style="top:-3.1031310000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">+</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3013079999999999em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.34713em;vertical-align:-0.5971299999999999em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:-0.0000050000000000050004em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.19215499999999985em;"><span style="top:-2.40029em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">x</span><span class="mrel mtight">∈</span><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7026642857142856em;"><span style="top:-2.214em;margin-left:-0.05764em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03588em;">q</span></span></span><span style="top:-2.786em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mbin mtight">+</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.42488571428571426em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.5971299999999999em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord text"><span class="mord textbf">1</span></span><span class="mopen">[</span><span class="mord mathdefault" style="margin-right:0.02778em;">D</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.03588em;">q</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.03148em;">k</span><span class="mclose">]</span></span></span></span>。封闭式的AP可以进一步被连续化放宽并对于<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>h</mi><mo>+</mo></msup></mrow><annotation encoding="application/x-tex">h^+</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.771331em;vertical-align:0em;"></span><span class="mord"><span class="mord mathdefault">h</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.771331em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">+</span></span></span></span></span></span></span></span></span></span></span>可微。<br>
链式法则的下一步是要让<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>h</mi><mo>+</mo></msup></mrow><annotation encoding="application/x-tex">h^+</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.771331em;vertical-align:0em;"></span><span class="mord"><span class="mord mathdefault">h</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.771331em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">+</span></span></span></span></span></span></span></span></span></span></span>中的项关于网络F可微，直方图合并操作可以近似为：<br>
<img src="https://jinyu-m.github.io/post-images/1610876087085.png" alt="" loading="lazy"><br>
利用一个可微函数<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>δ</mi></mrow><annotation encoding="application/x-tex">\delta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.03785em;">δ</span></span></span></span>（在D(q,x)=k时出现峰值）来代替二进制标志函数。这样，可以得到近似的梯度：<br>
<img src="https://jinyu-m.github.io/post-images/1610876093729.png" alt="" loading="lazy"><br>
注意到hamming距离的偏微分可以通过可导方程获得：<br>
<img src="https://jinyu-m.github.io/post-images/1610876100409.png" alt="" loading="lazy"><br>
最后，获得二进制比特数的阈值处理可以用tanh方程近似：<br>
<img src="https://jinyu-m.github.io/post-images/1610876105122.png" alt="" loading="lazy"><br>
其中，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>f</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">f_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.10764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>为浮点数神经网络激活函数。由以上近似过程，网络可以端到端训练。</p>
<h4 id="real-valued-descriptor">Real-Valued Descriptor</h4>
<p>作者也提供了真值描述子的推导过程。作者将描述子定义为一个真值神经网络响应的向量，并用L2 normalization进行处理。在这种情况下，欧拉距离D可以由此给出：<br>
<img src="https://jinyu-m.github.io/post-images/1610876111716.png" alt="" loading="lazy"><br>
优化浮点数描述子的AP最大的挑战在于不可微的排序过程，但是浮点数排序没有一个简单的替代形式。课是，直方图合并可以作为一个近似：作者利用直方图合并量化了浮点数距离，获得直方图<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>h</mi><mo>+</mo></msup></mrow><annotation encoding="application/x-tex">h^+</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.771331em;vertical-align:0em;"></span><span class="mord"><span class="mord mathdefault">h</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.771331em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">+</span></span></span></span></span></span></span></span></span></span></span>，然后将优化问题化为之前的二进制描述子的优化问题。对于L2-normalized向量，量化过程可以简单的根据[0,2]间欧拉距离来处理：作者将[0,2]间均匀的划分为b+1个bin。在应用链式法则时，只有公式4和5需要修改。<br>
与二进制描述子的优化不同，这里的b成为一个可调的参数。较大的b可以减少量化的误差，但是计算梯度时其计算复杂度与b呈线性。因此，在这篇论文里，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>b</mi><mo>≤</mo><mn>25</mn></mrow><annotation encoding="application/x-tex">b\leq 25</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83041em;vertical-align:-0.13597em;"></span><span class="mord mathdefault">b</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">≤</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">2</span><span class="mord">5</span></span></span></span>.</p>
<h3 id="comparison-with-other-ranking-approaches">Comparison with Other Ranking Approaches</h3>
<p>triplets定义了local pairwise ranking losses，而本文的方法属于listwise，因为优化的评估指标AP是在一个ranked list上定义的。<br>
作者指出，triplets是难以训练的，所以需要hardest negative mining，anchor swap， distance-weighted sampling等操作。如图2所示，listwise指标对于位置是敏感的，而local loss是不敏感的；在一个triplet中出现的错误，如果它出现在list的顶部，那么会对整个结果产生很大影响。因此，需要启发式的方法来减少high-rank errors。相反的，本文的方法直接优化了listwise评估指标，AP，所以不需要这些启发式方法。listwise优化已经隐性的包含了hard negative mining：因为它强制匹配的patches排在非匹配的之前，这一过程自动要求了hardest triplet的正确分类，而无需显性的使用它。<br>
<img src="https://jinyu-m.github.io/post-images/1610876118607.png" alt="" loading="lazy"></p>
<h2 id="task-specific-improvements"><em>Task-Specific Improvements</em></h2>
<h3 id="handling-geometric-noise">Handling Geometric Noise</h3>
<p>为了提升特征在匹配时的鲁棒性，保证描述子对几何噪声的不敏感型很重要。作者使用了Spatial Transformer，通过预测6-DOF 仿射变化来对齐patches，无需额外的监督。在本文的实验中，他被用于矫正几何畸变，提升效果。</p>
<h3 id="label-mining-for-image-matching">Label Mining for Image Matching</h3>
<p>前面的优化过程是根据patch retrieval任务设计的，但是它也适用于更高层的任务。作者在HPatches上测试了算法，来验证算法在image matching任务上的表现。HPatches数据集的image matching任务与patch retrieval任务类似，都是从一些干扰项中检索匹配的图像（块）。但是，在patch retrieval任务中，不会挑选与query位于同一图像序列的图像块作为干扰项，以防止图像具有重复的纹理（干扰项看起来确实与query一样）。在image matching任务中，图像与同一序列的其他图像相匹配，所有干扰项都来自于同一序列。因此，图像匹配的表现可以用将同一序列干扰项加入优化patch retrieval来优化。<br>
作者在优化HPatches上的patch retrieval时用label mining来增强干扰项。为了避免重复结构带来的有噪声的标签，作者用了一个简单的启发式方法：聚类。对于每个图像序列，作者根据视觉外观将所有patches聚类，然后，具有较高类内距离的patches被记为彼此的干扰项（要经过3D的验证）。要注意，label mining与hard negative mining无关，它的目的是增加额外的监督。</p>
<h2 id="experiments"><em>Experiments</em></h2>
<p>作者使用了L2Net的结构，网络的输入是32x32的灰度图，当加入Spatial Transformer module时，输入的尺寸被增加到42x42，用3个卷积层来预测一个6-DOF仿射变换，这一变换被用于采样32x32的patch。</p>
]]></content>
    </entry>
</feed>