<html>
  <head>
    <meta charset="utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>Traditional Place Recognition | 年少万兜鍪</title>
<link rel="shortcut icon" href="https://jinyu-m.github.io/favicon.ico?v=1615340624098">
<link href="https://cdn.jsdelivr.net/npm/remixicon@2.3.0/fonts/remixicon.css" rel="stylesheet">
<link rel="stylesheet" href="https://jinyu-m.github.io/styles/main.css">
<link rel="alternate" type="application/atom+xml" title="Traditional Place Recognition | 年少万兜鍪 - Atom Feed" href="https://jinyu-m.github.io/atom.xml">
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Droid+Serif:400,700">



    <meta name="description" content="
Online Visual Vocabulary for Robot Navigation and Mapping (IROS 2019) pdf

Abstract
Introduction
Visual Vocabulary

Voc..." />
    <meta name="keywords" content="" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0/katex.min.css">
    <script src="https://cdn.bootcss.com/highlight.js/9.12.0/highlight.min.js"></script>
  </head>
  <body>
    <div class="main">
      <div class="main-content">
        <div class="site-header">
  <a href="https://jinyu-m.github.io">
  <img class="avatar" src="https://jinyu-m.github.io/images/avatar.png?v=1615340624098" alt="">
  </a>
  <h1 class="site-title">
    年少万兜鍪
  </h1>
  <p class="site-description">
    少年吔
尘世恰好，有诗有酒刚好吐槽
  </p>
  <div class="menu-container">
    
      
        <a href="/" class="menu">
          首页
        </a>
      
    
      
        <a href="/archives" class="menu">
          文章
        </a>
      
    
      
        <a href="/tags" class="menu">
          标签
        </a>
      
    
      
        <a href="/post/about" class="menu">
          关于
        </a>
      
    
  </div>
  <div class="social-container">
    
      
    
      
    
      
    
      
    
      
    
  </div>
</div>

        <div class="post-detail">
          <article class="post">
            <h2 class="post-title">
              Traditional Place Recognition
            </h2>
            <div class="post-info">
              <span>
                2020-12-25
              </span>
              <span>
                23 min read
              </span>
              
            </div>
            
            <div class="post-content-wrapper">
              <div class="post-content">
                <p><ul class="markdownIt-TOC">
<li><a href="#online-visual-vocabulary-for-robot-navigation-and-mapping-iros-2019-pdf">Online Visual Vocabulary for Robot Navigation and Mapping (IROS 2019) pdf</a>
<ul>
<li><a href="#abstract"><em>Abstract</em></a></li>
<li><a href="#introduction"><em>Introduction</em></a></li>
<li><a href="#visual-vocabulary"><em>Visual Vocabulary</em></a>
<ul>
<li><a href="#vocabulary-building">Vocabulary Building</a></li>
<li><a href="#cluster-characterization">Cluster Characterization</a></li>
<li><a href="#cluster-merging">Cluster Merging</a></li>
<li><a href="#convergence-criterion">Convergence criterion</a></li>
<li><a href="#vocabulary-update">Vocabulary update</a></li>
<li><a href="#linear-discriminant-analysis-lda">Linear Discriminant Analysis (LDA)</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#online-visual-vocabulary-tro-2012-pdf">Online Visual Vocabulary (TRO 2012) pdf</a>
<ul>
<li><a href="#abstract-2"><em>Abstract</em></a></li>
<li><a href="#introduction-2"><em>Introduction</em></a></li>
<li><a href="#methods"><em>Methods</em></a>
<ul>
<li><a href="#agglomerative-clustering">Agglomerative clustering</a></li>
<li><a href="#vocabulary-building-2">Vocabulary building</a></li>
<li><a href="#cluster-characterization-2">Cluster characterization</a>
<ul>
<li><a href="#cluster-updating">Cluster updating</a></li>
</ul>
</li>
<li><a href="#cluster-merging-criterion">Cluster merging criterion</a></li>
<li><a href="#adding-new-clusters">Adding New Clusters</a></li>
<li><a href="#linear-disciminant-analysis-uu">Linear Disciminant Analysis <u>(?)</u></a></li>
<li><a href="#vocabulary-update-criterion">Vocabulary Update Criterion</a></li>
<li><a href="#cluster-association">Cluster Association</a>
<ul>
<li><a href="#image-reindexing">Image Reindexing</a></li>
</ul>
</li>
<li><a href="#image-similarity">Image similarity</a></li>
<li><a href="#increasing-vocabulary-efficiency">Increasing vocabulary efficiency</a></li>
<li><a href="#experiments"><em>Experiments</em></a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#dbow-tro-pdf">DBoW (TRO) pdf</a>
<ul>
<li><a href="#introduction-3"><em>Introduction</em></a></li>
<li><a href="#image-database"><em>Image Database</em></a></li>
<li><a href="#loop-detection-algorithm"><em>Loop Detection Algorithm</em></a>
<ul>
<li><a href="#database-query">Database query</a></li>
<li><a href="#match-grouping">Match grouping</a></li>
<li><a href="#temporal-consistency">Temporal consistency</a></li>
<li><a href="#efficient-geometrical-consistency">Efficient geometrical consistency</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#fast-and-effective-visual-place-recognition-using-binary-codes-and-disparity-information-iros-2014-pdf">Fast and Effective Visual Place Recognition using Binary Codes and Disparity Information (IROS 2014) pdf</a>
<ul>
<li><a href="#abstract-3"><strong>Abstract</strong></a></li>
<li><a href="#introduction-4"><strong>Introduction</strong></a></li>
<li><a href="#binary-descriptor"><strong>Binary Descriptor</strong></a>
<ul>
<li><a href="#proposed-method"><strong>Proposed Method</strong></a>
<ul>
<li><a href="#binary-code-calculation"><strong>Binary code calculation</strong></a></li>
<li><a href="#binary-codes-matching"><strong>Binary codes matching</strong></a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</p>
<hr>
<h1 id="online-visual-vocabulary-for-robot-navigation-and-mapping-iros-2019-pdf">Online Visual Vocabulary for Robot Navigation and Mapping (IROS 2019) <a href="http://eia.udg.edu/~rafa/papers/iros-2009.pdf">pdf</a></h1>
<h2 id="abstract"><em>Abstract</em></h2>
<p>受到content-based image retrieval算法的启发，回环检测算法使用visual vocabularies来度量图像间的相似度。但是这类算法有两个缺陷：（1）他们需要很强的人工干预，即通过trial-and-error的方法来训练和调试参数，（2）他们只适合批处理数据，即所有数据在处理前都是已经获得的（应该是指算法只在见过的场景中表现良好）。因此，作者提出了一个算法，在线构建和更新vocabularies，来高效地表示场景中的图像，并且词典构建过程不需要人工干预。</p>
<h2 id="introduction"><em>Introduction</em></h2>
<p>在这篇论文中，作者提出了一个增量式构建视觉词典的框架。该算法不需要人工干预，不需要关于环境的先验信息。在导航过程中，当视觉信息输入到系统中，系统会构建一个简化的词典。该词典会进行更新，以正确地对场景中出现的视觉信息建模。该词典使用一种考虑视觉数据的全局分布的方法来构建，提升了效率。并且，作者提出了一种新的用于特征-聚类之间的联合方法和图像检索方法，适合在线的检测。<br>
提出的方法被应用在水下导航和建图的SFM算法中，视觉词典被用于量化帧间的相似度，从而进行回环检测。<br>
<img src="https://jinyu-m.github.io/post-images/1615277597694.png" alt="" loading="lazy"></p>
<h2 id="visual-vocabulary"><em>Visual Vocabulary</em></h2>
<p>当前sota的算法都处于一个off-line的阶段，这一阶段需要实现从场景中获取视觉特征。这些特征然后通过某种聚类方法被用于构建视觉词典。典型的off-line词典构建方法使用K-means，K-medians或者fixed-radius clustering方法，这些方法需要使用者去设置许多参数，比如聚类簇数。为一个最优的词典找到合适的参数是一项繁琐的任务，需要不同的试错。比如，一个拥有过多单词的词典不会有足够的抽象能力来检测图像间的相似度，反之，一个单词太少的词典将受到混淆，单词过于泛化导致无法区分。</p>
<blockquote>
<p>the adequate parameters for an optimum vocabulary is a tedious task which generally involves a trial and error approach. For example, a vocabulary with too many words would not have enough abstraction power to detect similarities between images. In contrast, a vocabulary with too few words would be too confusing and generalized to be discriminant.</p>
</blockquote>
<p>作者提出了一种先进的视觉词典构建方法，它是可扩展的（scalable，因此适用于on-line检测）和自动的（automatic）。为此，作者使用了修改版的agglomerative clustering。agglomerative algorithm从将每个element作为独立的cluster（以下称之为elementary clusters）开始，然后利用某种相似度度量方法将它们合并为更大的clusters中，直到达到一些收敛条件（比如最小clusters数量，最大cluster半径等）。</p>
<h3 id="vocabulary-building">Vocabulary Building</h3>
<p>在本方法中，elementary clusters是通过对场景点的视觉跟踪（T. Nicosevici and R. Garcia. Online Robust 3D Mapping Using Structure from Motion Cues. In MTS/IEEE OCEANS Conference, pages 1–7, 2008.）产生的，一个elementary cluster对应着一个追踪的特征。视觉词典通过增量式地合并这些clusters。词典构建过程可以总结为两步：<br>
（1）词典初始化阶段。词典由前m张图像中的elementary cluster初始化，这些cluster逐渐合并，直到收敛（合并的准则在后文中详细描述）；<br>
（2）词典更新阶段。当机器人移动，机器人获得了场景中的更多视觉信息，这些信需要包含到词典中。因此，对于每m张图像，新的elementary cluster被提取出来。这些cluster被加入到词典中，然后全部clusters逐渐合并，直到收敛。这一步每输入m张图像重复一次。<br>
<img src="https://jinyu-m.github.io/post-images/1615277763160.png" alt="" loading="lazy"></p>
<h3 id="cluster-characterization">Cluster Characterization</h3>
<p>词典中每个cluster由它在N维空间中的位置和大小（半径）定义。这样提供了关于cluster分布和clusters间交互的完整信息。因为elementary cluster是由特征跟踪获得的，我们这样定义：<br>
<img src="https://jinyu-m.github.io/post-images/1615278043519.png" alt="" loading="lazy"><br>
其中，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>C</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">C_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.07153em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>是cluster的中心值，由图像<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.65952em;vertical-align:0em;"></span><span class="mord mathdefault">i</span></span></span></span>中场景点<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.03148em;">k</span></span></span></span>的平均特征向量给出。<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>R</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">R_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.00773em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>是点<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.03148em;">k</span></span></span></span>的协方差矩阵。</p>
<p>每次cluster合并是指两个cluster的合并（如图2）。新产生的cluster的参数直接从合并的clusters中获得，不需要重新从初始数据开始计算。这样做，节省了计算时间和内存消耗，尤其是在某些大的cluster中。新cluster的位置和大小由下式给出:<br>
<img src="https://jinyu-m.github.io/post-images/1615278465223.png" alt="" loading="lazy"><br>
其中，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>C</mi><mi>a</mi></msub></mrow><annotation encoding="application/x-tex">C_a</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.07153em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">a</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>和<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>C</mi><mi>b</mi></msub></mrow><annotation encoding="application/x-tex">C_b</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.07153em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">b</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>分别为要合并的两个cluster的中心值，这两个cluster分别有<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>n</mi><mi>a</mi></msub></mrow><annotation encoding="application/x-tex">n_a</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">n</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">a</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>和<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>n</mi><mi>b</mi></msub></mrow><annotation encoding="application/x-tex">n_b</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">n</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">b</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>个elements。</p>
<h3 id="cluster-merging">Cluster Merging</h3>
<p>一般的距离方法依赖于相似度度量方法，比如欧拉距离、曼哈顿距离、切比雪夫距离、马氏距离、向量夹角等，但是这些距离只是局部的分析了数据，所以在高维的聚类空间中是次优的。因此，作者提出一种新的距离方法，将数据的全局分布也考虑进来。该方法基于Fisher's linear disciminant，将数据聚类来最大化目标函数：<br>
<img src="https://jinyu-m.github.io/post-images/1615279001618.png" alt="" loading="lazy"><br>
其中<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>t</mi><mi>r</mi><mo>(</mo><mo>)</mo></mrow><annotation encoding="application/x-tex">tr()</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault">t</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mopen">(</span><span class="mclose">)</span></span></span></span>求得迹，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>S</mi><mi>B</mi></msub></mrow><annotation encoding="application/x-tex">S_B</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.05017em;">B</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>表示<strong>between clusters scatter matrix</strong>，而<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>S</mi><mi>W</mi></msub></mrow><annotation encoding="application/x-tex">S_W</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">W</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>表示<strong>within clusters scatter matrix</strong>，由下式求得<br>
<img src="https://jinyu-m.github.io/post-images/1615279185925.png" alt="" loading="lazy"><br>
其中C是所有数据的全局中心值。N表示所有element的数量，而<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>n</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">n_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">n</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>是cluster k中包含的element数量。<br>
实际上，合并过程可以描述为：<br>
（1）对于每个cluster，我们用kd-tree的方法搜索欧式空间中的邻近cluster，作为合并的待选；<br>
（2）对于每对可能要进行合并的clusters，我们计算两个cluster合并后目标函数的值<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>Q</mi><mo mathvariant="normal">′</mo></msup></mrow><annotation encoding="application/x-tex">Q&#x27;</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.946332em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathdefault">Q</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.751892em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span></span></span></span>。如果目标函数的值增大，那么两个cluster被合并，同时<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>S</mi><mi>B</mi></msub><mo separator="true">,</mo><msub><mi>S</mi><mi>W</mi></msub></mrow><annotation encoding="application/x-tex">S_B,S_W</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8777699999999999em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.05017em;">B</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">W</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>随之更新。（实际上，在合并时，作者对于所有可能合并的cluster都计算了Q的增益，将其从高到低排序，然后按照这一顺序进行合并。这样做，合并过程就和分析cluster的顺序无关了。）<br>
每一个合并都会改变词典中数据的分布，需要重新计算<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>S</mi><mi>B</mi></msub></mrow><annotation encoding="application/x-tex">S_B</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.05017em;">B</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>和<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>S</mi><mi>W</mi></msub></mrow><annotation encoding="application/x-tex">S_W</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">W</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>。直接重新计算会非常耗时，我们提出了一种增量式的更新策略：<br>
<img src="https://jinyu-m.github.io/post-images/1615279929545.png" alt="" loading="lazy"></p>
<h3 id="convergence-criterion">Convergence criterion</h3>
<p>上述合并过程将重复进行，逐渐合并clusters，直到没有可以让Q增加的合并。通过这种方法，本算法提供了一种自然的收敛标准，不需要任何人工参数。</p>
<h3 id="vocabulary-update">Vocabulary update</h3>
<p>在词典更新阶段，新的elementary clusters加入，包含新的视觉特征。对于每个新加入的elementary cluster <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>ζ</mi><mi>e</mi></msub></mrow><annotation encoding="application/x-tex">\zeta_e</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07378em;">ζ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.07378em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">e</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>S</mi><mi>B</mi></msub></mrow><annotation encoding="application/x-tex">S_B</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.05017em;">B</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>和<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>S</mi><mi>W</mi></msub></mrow><annotation encoding="application/x-tex">S_W</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">W</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>必须相应的更新。为了避免重复计算scatter matrix，作者提出了一种新的更新方法。<br>
更新<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>S</mi><mi>W</mi></msub></mrow><annotation encoding="application/x-tex">S_W</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">W</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>只涉及<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>ζ</mi><mi>e</mi></msub></mrow><annotation encoding="application/x-tex">\zeta_e</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07378em;">ζ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.07378em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">e</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>的covariance matrix<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>R</mi><mi>e</mi></msub></mrow><annotation encoding="application/x-tex">R_e</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.00773em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">e</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>，用element的数量<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>n</mi><mi>e</mi></msub></mrow><annotation encoding="application/x-tex">n_e</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">n</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">e</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>（每个elementary cluster中elements的数量是指特征跟踪中的帧数）加权：<br>
<img src="https://jinyu-m.github.io/post-images/1615280758589.png" alt="" loading="lazy"><br>
<strong>这里为什么不是<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><msup><mi>S</mi><mo mathvariant="normal">′</mo></msup><mi>W</mi></msub><mo>=</mo><mfrac><mrow><mi>N</mi><msub><mi>S</mi><mi>W</mi></msub><mo>+</mo><msub><mi>n</mi><mi>e</mi></msub><msub><mi>R</mi><mi>e</mi></msub></mrow><mrow><mi>N</mi><mo>+</mo><msub><mi>n</mi><mi>e</mi></msub></mrow></mfrac></mrow><annotation encoding="application/x-tex">{S&#x27;}_W=\frac{NS_W+n_eR_e}{N+n_e}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.901892em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord"><span class="mord"><span class="mord mathdefault" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.751892em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">W</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.3337359999999998em;vertical-align:-0.44509999999999994em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8886359999999999em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.10903em;">N</span><span class="mbin mtight">+</span><span class="mord mtight"><span class="mord mathdefault mtight">n</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.16454285714285719em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathdefault mtight">e</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.410305em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.10903em;">N</span><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3567071428571427em;margin-left:-0.05764em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">W</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.14329285714285717em;"><span></span></span></span></span></span></span><span class="mbin mtight">+</span><span class="mord mtight"><span class="mord mathdefault mtight">n</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.16454285714285719em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathdefault mtight">e</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.16454285714285719em;"><span style="top:-2.357em;margin-left:-0.00773em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathdefault mtight">e</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.44509999999999994em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span>呀，有点没看懂诶....</strong><br>
增加新的cluster会影响全局的数据中心<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>C</mi></mrow><annotation encoding="application/x-tex">C</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.07153em;">C</span></span></span></span>，新的中心值<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>C</mi><mo mathvariant="normal">′</mo></msup></mrow><annotation encoding="application/x-tex">C&#x27;</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.751892em;vertical-align:0em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.751892em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span></span></span></span>为：<br>
<img src="https://jinyu-m.github.io/post-images/1615281745215.png" alt="" loading="lazy"><br>
考虑到C的变化，那么<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>S</mi><mi>B</mi></msub></mrow><annotation encoding="application/x-tex">S_B</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.05017em;">B</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>应该更新为：<br>
<img src="https://jinyu-m.github.io/post-images/1615281792324.png" alt="" loading="lazy"><br>
其中，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>δ</mi><mi>C</mi></msub><mo>=</mo><msup><mi>C</mi><mo mathvariant="normal">′</mo></msup><mo>−</mo><mi>C</mi></mrow><annotation encoding="application/x-tex">\delta_C=C&#x27;-C</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03785em;">δ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03785em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.07153em;">C</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.835222em;vertical-align:-0.08333em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.751892em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.07153em;">C</span></span></span></span>，V是每个新加入的cluster与全局中心值之间差异的加权和。V可以增量式地获取：<br>
<img src="https://jinyu-m.github.io/post-images/1615281993246.png" alt="" loading="lazy"><br>
<strong>懵了，这些公式都没推导过...</strong></p>
<h3 id="linear-discriminant-analysis-lda">Linear Discriminant Analysis (LDA)</h3>
<p>对于视觉词典中包含的cluster信息，我们需要找到一种数据变换方法来是cluster的区分度最大，并且可以让我们减少数据的维度，来提升词典构建和图像检索的速度。因此，作者最大化以下LDA目标函数：</p>
<hr>
<h1 id="online-visual-vocabulary-tro-2012-pdf">Online Visual Vocabulary (TRO 2012) <a href="https://doi.org/10.1109/TRO.2012.2192013">pdf</a></h1>
<h2 id="abstract-2"><em>Abstract</em></h2>
<blockquote>
<p>Detecting already-visited regions based on their visual appearance helps reduce drift and position uncertainties in robot navigation and mapping. Inspired from content-based image retrieval, an efficient approach is the use of visual vocabularies to measure similarities between images. This way, images corresponding to the same scene region can be associated.  <strong>State-of-the-art proposals that address this topic use prebuilt vocabularies that generally require a priori knowledge of the environment</strong>. We propose a novel method for appearance-based navigation and mapping where the visual vocabularies are built online, thus eliminating the need for prebuilt data. We also show that the proposed technique allows efficient loop-closure detection, even at small vocabulary sizes, resulting in a higher computational efficiency.</p>
</blockquote>
<p>SLAM系统一般会将回环检测任务当作一个2D-2D的图像检索任务来完成，bag-of-word模型是一个高效的解决方案，但是现存SOTA的算法是现在一个训练集上训练一个pre-built vocabulary，这里就需要用到人类对于环境的先验认知（比如室内还是室外，词典的规模等）。这篇论文提出了一种在线训练词典的方法，所以无需训练数据集。</p>
<h2 id="introduction-2"><em>Introduction</em></h2>
<p>传统BoW的算法流程大致分为两部分：1.离线部分，从训练集中提取特征完成聚类，构建视觉词典，特征的聚类被当作描述图像的视觉单词；2.在线部分，提取当前图像的特征，量化到视觉单词上，用视觉单词的直方图向量来描述图像，完成图像相似度的计算。</p>
<blockquote>
<p>BoW image representation employs two stages: 1) In the training stage, sets of visual features are grouped or clustered together to generate visual vocabularies, i.e., collections of generalized visual features or visual words; 2) in the second stage, the images are represented as histograms of visual word occurrences.</p>
</blockquote>
<p>当前BoW模型的缺点之一就是使用了静态的pre-built vocabulary，需要先验的知识，但是在复杂、大型的场景中，这一定是不合理的（我们的试验也证明了这一点，室内场景构建的词典在室外检测效果不好，室外训练的词典在室内效果不好）。<br>
作者提出了一种无需先验和人工设计参数的增量式词典训练方法，online visual vocabulary(OVV)。另外，作者也设计了一种新的聚类房啊，用一种新的、考虑到整个聚类分布的聚类收敛标准。<br>
<img src="https://jinyu-m.github.io/post-images/1610877239498.png" alt="" loading="lazy"></p>
<h2 id="methods"><em>Methods</em></h2>
<blockquote>
<p>Finding the adequate parameters for an optimum vocabulary is a tedious task which generally involves a trial-and-error approach. For instance, a vocabulary with too many words would not have enough abstraction power to detect similarities between images. In contrast, a vocabulary with too few words would be too confusing and generalized to be discriminative.</p>
</blockquote>
<p>作者先提出了static pre-built vocabulary的一个弊端，就是词典的规模完全由人工反复实验获得，耗时且不一定最优。而且对于词典树来说，当词典的规模过大，特征的鲁棒性下降了，对于视觉的干扰过于敏感；反之，当词典的规模过小，特征的disciminativeness下降，特征容易误匹配。<br>
作者因此提出了一种增量式的视觉词典训练方法，为了实现这一点，作者采用一种修改后的聚类方法（Agglomerative clustering）.</p>
<h3 id="agglomerative-clustering">Agglomerative clustering</h3>
<p>该聚类方法是一种自底向上的层次聚类方法，过程如：（1）先将每个元素单独定为一类（elementary clusters），（2）合并指定距离最小的类，（3）重复（2）直到所有元素都归为同一类。</p>
<h3 id="vocabulary-building-2">Vocabulary building</h3>
<p>在这篇论文中，首先跟踪图像中的特征点，用这些跟踪到的点作为elementary clusters，减少了用于构建词典树的特征数量。词典树通过增量式的合并这些clusters来构建，构建过程可以总结为两点：<br>
1.初始化：词典先用前m张图像提取到的tracked features去初始化一个词典，然后由底向上构建词典树；<br>
2.更新：我理解的是，OVV用了一种滑动窗的概念，每m张图像提取出的elementary clusters都被加入到词典树中，然后整个词典树重新由底向上完成构建。这样，新出现的场景中的特征也会被更新到词典树中。</p>
<h3 id="cluster-characterization-2">Cluster characterization</h3>
<p>每个cluster具有两个属性，聚类中心值Ck，和协方差矩阵**<u>(?)</u>**Rk。Ck反映了聚类的分布，Rk反映了聚类之间的关系。<br>
<img src="https://jinyu-m.github.io/post-images/1610877261587.png" alt="" loading="lazy"></p>
<h4 id="cluster-updating">Cluster updating</h4>
<p>每个聚类都是通过合并两个聚类来获得的，所以新的聚类属性可以根据原本的两个聚类的属性来获得。<br>
<img src="https://jinyu-m.github.io/post-images/1610877270139.png" alt="" loading="lazy"></p>
<p>这样可以节省运算的消耗。</p>
<h3 id="cluster-merging-criterion">Cluster merging criterion</h3>
<p>作者认为原本在Agglomerative clustering度量距离的方法是局部最优的，没有考虑到特征的全局分布。所以作者提出了新的聚类方法，在聚类时，同时增加各类之间的间距和类中的compactness。<br>
新的聚类方法基于Fisher’s linear discriminant。先计算了两个矩阵：<br>
<img src="https://jinyu-m.github.io/post-images/1610877281134.png" alt="" loading="lazy"></p>
<p>其中C是所有数据的中心值，N表示所有数据的数量，nk表示在cluster_k中包含的数据的数量。Sb代表了between clusters scatter matrix，我理解的是体现了类与类之间的分散程度（类间距离）；Sw代表了within clusters scatter matrix，是体现了类内数据的分散程度（类内紧密度）。<br>
然后用Sb和Sw的迹的比值作为损失函数:<br>
<img src="https://jinyu-m.github.io/post-images/1610877295645.png" alt="" loading="lazy"></p>
<p>合并发生在两步：（1）对于每个cluster，利用kd-tree在它的领域内（欧拉空间中）搜索可能合并的candidate；（2）对于每个candidate，计算合并前后的Q，如果Q有提升，那么将两个cluster合并，并且更新相应的Sb、Sw。<br>
由于每次合并都会引起Sb、Sw的更新，所需的计算量较大。所以作者提出一种增量式的更新方案：<br>
<img src="https://jinyu-m.github.io/post-images/1610877301528.png" alt="" loading="lazy"></p>
<p>在算法中，重复合并处理，直到Q值无法提升。此时，词典的repetitiveness和disciminative power都达到了最大。</p>
<h3 id="adding-new-clusters">Adding New Clusters</h3>
<p>在词典更新阶段，新的elementary cluster被加入。对于每个新加入的elementary cluster EC，Sb和Sw要相应的更新，为了减少更新时的计算量，作者使用：<br>
<img src="https://jinyu-m.github.io/post-images/1610877309931.png" alt="" loading="lazy"></p>
<p>Re是EC的covariance matrix，nc是其element的数量。在本文中，nc表示对于特定特征，可以跟踪到的帧数。<br>
向词典中添加cluster会改变全部特征的中心值C，所以C的更新如下：<br>
<img src="https://jinyu-m.github.io/post-images/1610877314955.png" alt="" loading="lazy"></p>
<p>所以Sb的更新如下：<br>
<img src="https://jinyu-m.github.io/post-images/1610877321430.png" alt="" loading="lazy"></p>
<p>其中delta_C=C'-C，V是先添加的cluster的中心与全部数据的中心之间的差异的加权和。V可以增量式获得:<br>
<img src="https://jinyu-m.github.io/post-images/1610877327864.png" alt="" loading="lazy"></p>
<h3 id="linear-disciminant-analysis-uu">Linear Disciminant Analysis <u>(?)</u></h3>
<p>为了得到一个最大化cluster之间的可分离度以及减少数据的维度的data transformation，作者最大化：<br>
<img src="https://jinyu-m.github.io/post-images/1610877334370.png" alt="" loading="lazy"></p>
<p>其中w是决定最大cluster可分离度的趋势。最大化J(w)可以当做一个一般的求特征值问题，从w的特征向量中作者获得了一个data transformation。挑选G中对应w最大值的m列，作者将数据的维度降低到s维。</p>
<h3 id="vocabulary-update-criterion">Vocabulary Update Criterion</h3>
<p>在实际操作中，词典不是间隔固定时间更新一次的，而是自适应的更新。在图像检索过程中，当特征的每个维度都满足：<br>
<img src="https://jinyu-m.github.io/post-images/1610877346064.png" alt="" loading="lazy"></p>
<p>则认为该特征落入当前cluster。当特征落入cluster的比率小于90%，则更新词典。</p>
<h3 id="cluster-association">Cluster Association</h3>
<p>在cluster merging的过程中，词典的repetitiveness和disciminative得到最大化。但是还需要考虑词典的stability，即同一特征，在更新前后应当associate同一cluster。<br>
本文提出的feature-cluster association方法基于树，在词典训练的同时，建立树，树的节点表示cluster，分支表示cluster的层次，树的根节点对应着visual word<u><strong>(?)</strong></u>，树的叶节点对应elementary cluster。<br>
在association过程中，树由上自下被访问，计算特征与节点之间的欧氏距离。为了减少遍历的树的个数，只搜索满足以下条件的树：<br>
<img src="https://jinyu-m.github.io/post-images/1610877363078.png" alt="" loading="lazy"></p>
<h4 id="image-reindexing">Image Reindexing</h4>
<p>词典更新后，图像的index也会变化，本文定义了transformation T去体现这种变化，这样就不用了每次计算图像的index了：<br>
<img src="https://jinyu-m.github.io/post-images/1610877478309.png" alt="" loading="lazy"></p>
<p>其中，W是图像的indexing。具体步骤如下：<br>
<img src="https://jinyu-m.github.io/post-images/1610877482833.png" alt="" loading="lazy"></p>
<p>示例：<br>
<img src="https://jinyu-m.github.io/post-images/1610877487348.png" alt="" loading="lazy"></p>
<h3 id="image-similarity">Image similarity</h3>
<p>计算图像相似度用：<br>
<img src="https://jinyu-m.github.io/post-images/1610877501357.png" alt="" loading="lazy"></p>
<p>为了体现visual word的disciminative，用TF-IDF加权。</p>
<h3 id="increasing-vocabulary-efficiency">Increasing vocabulary efficiency</h3>
<p>为了进一步提升OVV的计算效率，作者对包含较少信息的节点进行了剪枝。当<br>
<img src="https://jinyu-m.github.io/post-images/1610877509249.png" alt="" loading="lazy"><br>
时，进行剪枝。</p>
<h3 id="experiments"><em>Experiments</em></h3>
<p><img src="https://jinyu-m.github.io/post-images/1610877518916.png" alt="" loading="lazy"><br>
OVV的词典会随着环境的增大而逐渐增大。<strong>（值得改进）</strong><br>
<img src="https://jinyu-m.github.io/post-images/1610877528466.png" alt="" loading="lazy"><br>
作者比较了incremental indexing和full indexing的表现（对应着image reindexing节），相差不大。</p>
<hr>
<h1 id="dbow-tro-pdf">DBoW (TRO) <a href="https://doi.org/10.1109/TRO.2012.2197158">pdf</a></h1>
<h2 id="introduction-3"><em>Introduction</em></h2>
<p>贡献点可以总结为几点：<br>
1.使用了一种改进的FAST+BEIFF二进制特征；<br>
2.把邻近图像联系起来，组成island，防止过于靠近的图像被匹配到（算是一种temporal constrant）；<br>
3.在词典树中加入inverse index来实现快速的图像检索，加入direct index来保留图像间的correspondence，加快geometrical check的速度。</p>
<h2 id="image-database"><em>Image Database</em></h2>
<p>由于作者使用二进制描述子，所以构建了二进制词典树，使用K-means++ seeding初始化K-means的初始medians，medians中非二进制值得被置为0。<br>
计算两个BoW向量得相似度时使用了L1分数：<br>
<img src="https://jinyu-m.github.io/post-images/1610877562404.png" alt="" loading="lazy"></p>
<p>在词典树中，作者使用了inverse index table来保留该单词出现过的图像索引值。当一张新的图像加入database，inverse index table会随之更新。<br>
作者来使用了direct index table，对于每张图像，作者在direct index table中储存了该图像出现过的单词所属的位于l层的节点，以及该节点包含的局部特征。此结构可以用于在获得candidate loop时，准备进行geometrical check时计算同属于一个word或者同属于一个节点的特征的correspondence。</p>
<h2 id="loop-detection-algorithm"><em>Loop Detection Algorithm</em></h2>
<h3 id="database-query">Database query</h3>
<p>对于每个query图像，利用词典树，搜索到一系列匹配的candidates以及对应的分数，由于这些分数受query image和它其中的单词分布影响，所以作者对分数进行了归一化：<br>
<img src="https://jinyu-m.github.io/post-images/1610877572685.png" alt="" loading="lazy"></p>
<h3 id="match-grouping">Match grouping</h3>
<p>为了避免相邻的图像被匹配，作者将相邻图像构成了island，将其视为一个匹配。如果query匹配到的candidate的时间戳之间差距很小，那么就将这些candidate视为一个island，其匹配分数为：<br>
<img src="https://jinyu-m.github.io/post-images/1610877580156.png" alt="" loading="lazy"></p>
<p>具有最高匹配分数的island被挑选出来作为matching group，进入下一步的验证。</p>
<h3 id="temporal-consistency">Temporal consistency</h3>
<p>当获得最好的matching island后，对其进行时间一致性的检验，即其之前的k个query也必须被匹配到，当其通过检验后，挑选island中具有最高匹配分数的一个image作为当前query的匹配。</p>
<h3 id="efficient-geometrical-consistency">Efficient geometrical consistency</h3>
<p>作者的几何检验思路是计算匹配图像对的F矩阵，利用RANSAC，至少需要有12个匹配点对。为了加快特征匹配，作者用direct index去粗略搜索。</p>
<hr>
<h1 id="fast-and-effective-visual-place-recognition-using-binary-codes-and-disparity-information-iros-2014-pdf">Fast and Effective Visual Place Recognition using Binary Codes and Disparity Information (IROS 2014) <a href="https://www.researchgate.net/publication/263298223">pdf</a></h1>
<h2 id="abstract-3"><strong>Abstract</strong></h2>
<p>这篇工作提出了一个基于二进制code和视差信息的双目场景识别算法。算法（ABLE-S）在全局框架中使用Local Difference Binary（LDB）描述子来获得鲁棒的全局图像描述，该描述是基于图像像素对间亮度和梯度之间差异的。LDB相比其他描述子，如仅依赖于图像亮度的BRIEF，有更好的描述能力。除此之外，作者还讲视差信息加入了二进制描述子（D-LDB）。视差可以提供一些有用的信息，来解决场景识别中常见的问题，如perceptual aliasing。<br>
论文用KITTI数据集测试算法。并且，作者提供了一个回环的真值，以方便回环检测算法表现的比较。</p>
<h2 id="introduction-4"><strong>Introduction</strong></h2>
<p>作者提出FAB-MAP有一些缺陷，即需要事先训练环境的视觉词典和相关联的概率方法，使得算法无法适应实时的应用。<br>
在这篇论文中，作者提出了一个用于视觉回环检测和场景识别的算法，该算法使用基于像素对的亮度、梯度和视差比较的全局二进制描述子，如图1所示。作者将视差信息加入了LDB，得到了D-LDB。在实验中，作者证明了视差的加入提供了更准确的视觉定位，减少了视觉场景识别中的常见问题，如perceptual aliasing。最后的实验证明，ABLE-S算法获得了超过FAB-MAP、WI-SURF、BRIEF-Gist的表现，并且计算消耗更低。<br>
<img src="https://jinyu-m.github.io/post-images/1610877655376.png" alt="" loading="lazy"></p>
<h2 id="binary-descriptor"><strong>Binary Descriptor</strong></h2>
<p>二进制描述子最好的性质为可以用hamming距离进行高效的匹配。假设一个平滑后的图像块p，其中心为关键点(x,y)，那么二进制检测可以定义为：<br>
<img src="https://jinyu-m.github.io/post-images/1610877660015.png" alt="" loading="lazy"><br>
其中，f(i)是一个函数，返回p中特定pixel或cell的图像特征响应。f(i)可以采用如BRIEF、ORB和BRISK中二进制描述子一样的平滑后的图像灰度值。除此之外，f(i)也可以是如LDB和M-LDB中不同二进制比较结构的串联，比如平均图像灰度、p中特定cell的图像梯度Gx和Gy。<br>
<img src="https://jinyu-m.github.io/post-images/1610877671571.png" alt="" loading="lazy"></p>
<p>为了减少场景识别问题中perceptual aliasing等问题的干扰，作者拓展了LDB，加入了平均视差Davg的二进制比较结构：<br>
<img src="https://jinyu-m.github.io/post-images/1610877681169.png" alt="" loading="lazy"></p>
<p>最后，合成的描述子<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>d</mi><mi>n</mi></msub><mo>(</mo><mi>p</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">d_n(p)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathdefault">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathdefault">p</span><span class="mclose">)</span></span></span></span>为一个n次二进制检测的向量，n是描述子的维度，通常被矫正为：<br>
<img src="https://jinyu-m.github.io/post-images/1610877692854.png" alt="" loading="lazy"></p>
<h3 id="proposed-method"><strong>Proposed Method</strong></h3>
<h4 id="binary-code-calculation"><strong>Binary code calculation</strong></h4>
<p>在本文中，作者采用了LDB，因为LDB相对BRIEF加入了梯度信息。作者还加入了视差信息，得到D-LDB。视差是通过SGBM(Semi Global Block Matching)获得的。</p>
<p>作者将图像块的大小定义为64x64，在提取全局二进制描述子之前将图像缩放到这一尺寸。更小的图像块会削弱场景识别算法的有效性，更大的分辨率也没有得到更好的表现。另外，作者将二进制描述子的维度定义为256比特。描述子通过LDB的随机比特挑选方法来满足维度要求。</p>
<p>该全局描述子将缩放后图像块的中心作为关键点，来进行计算，没有显性的旋转和缩放。然而，可以采用其他替代方法，将图像划分为多个grids，将每个grid的中心视为关键点，然后计算每个grid的二进制描述子，拼接到一起得到最后的二进制code。这一方法可以考虑采用不同宽和高的grid(<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>g</mi><mi>w</mi></msub><mo>×</mo><msub><mi>g</mi><mi>h</mi></msub></mrow><annotation encoding="application/x-tex">g_w \times g_h</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7777700000000001em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.02691em;">w</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">h</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>)。</p>
<h4 id="binary-codes-matching"><strong>Binary codes matching</strong></h4>
<p>对要分析的m个场景，提取二进制描述子，构成向量v。计算二进制描述子之间的hamming距离，得到距离矩阵M</p>

              </div>
              <div class="toc-container">
                <ul class="markdownIt-TOC">
<li><a href="#online-visual-vocabulary-for-robot-navigation-and-mapping-iros-2019-pdf">Online Visual Vocabulary for Robot Navigation and Mapping (IROS 2019) pdf</a>
<ul>
<li><a href="#abstract"><em>Abstract</em></a></li>
<li><a href="#introduction"><em>Introduction</em></a></li>
<li><a href="#visual-vocabulary"><em>Visual Vocabulary</em></a>
<ul>
<li><a href="#vocabulary-building">Vocabulary Building</a></li>
<li><a href="#cluster-characterization">Cluster Characterization</a></li>
<li><a href="#cluster-merging">Cluster Merging</a></li>
<li><a href="#convergence-criterion">Convergence criterion</a></li>
<li><a href="#vocabulary-update">Vocabulary update</a></li>
<li><a href="#linear-discriminant-analysis-lda">Linear Discriminant Analysis (LDA)</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#online-visual-vocabulary-tro-2012-pdf">Online Visual Vocabulary (TRO 2012) pdf</a>
<ul>
<li><a href="#abstract-2"><em>Abstract</em></a></li>
<li><a href="#introduction-2"><em>Introduction</em></a></li>
<li><a href="#methods"><em>Methods</em></a>
<ul>
<li><a href="#agglomerative-clustering">Agglomerative clustering</a></li>
<li><a href="#vocabulary-building-2">Vocabulary building</a></li>
<li><a href="#cluster-characterization-2">Cluster characterization</a>
<ul>
<li><a href="#cluster-updating">Cluster updating</a></li>
</ul>
</li>
<li><a href="#cluster-merging-criterion">Cluster merging criterion</a></li>
<li><a href="#adding-new-clusters">Adding New Clusters</a></li>
<li><a href="#linear-disciminant-analysis-uu">Linear Disciminant Analysis <u>(?)</u></a></li>
<li><a href="#vocabulary-update-criterion">Vocabulary Update Criterion</a></li>
<li><a href="#cluster-association">Cluster Association</a>
<ul>
<li><a href="#image-reindexing">Image Reindexing</a></li>
</ul>
</li>
<li><a href="#image-similarity">Image similarity</a></li>
<li><a href="#increasing-vocabulary-efficiency">Increasing vocabulary efficiency</a></li>
<li><a href="#experiments"><em>Experiments</em></a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#dbow-tro-pdf">DBoW (TRO) pdf</a>
<ul>
<li><a href="#introduction-3"><em>Introduction</em></a></li>
<li><a href="#image-database"><em>Image Database</em></a></li>
<li><a href="#loop-detection-algorithm"><em>Loop Detection Algorithm</em></a>
<ul>
<li><a href="#database-query">Database query</a></li>
<li><a href="#match-grouping">Match grouping</a></li>
<li><a href="#temporal-consistency">Temporal consistency</a></li>
<li><a href="#efficient-geometrical-consistency">Efficient geometrical consistency</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#fast-and-effective-visual-place-recognition-using-binary-codes-and-disparity-information-iros-2014-pdf">Fast and Effective Visual Place Recognition using Binary Codes and Disparity Information (IROS 2014) pdf</a>
<ul>
<li><a href="#abstract-3"><strong>Abstract</strong></a></li>
<li><a href="#introduction-4"><strong>Introduction</strong></a></li>
<li><a href="#binary-descriptor"><strong>Binary Descriptor</strong></a>
<ul>
<li><a href="#proposed-method"><strong>Proposed Method</strong></a>
<ul>
<li><a href="#binary-code-calculation"><strong>Binary code calculation</strong></a></li>
<li><a href="#binary-codes-matching"><strong>Binary codes matching</strong></a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>

              </div>
            </div>
          </article>
        </div>

        
          <div class="next-post">
            <div class="next">下一篇</div>
            <a href="https://jinyu-m.github.io/post/fastap/">
              <h3 class="post-title">
                Loss Function
              </h3>
            </a>
          </div>
        

        
          
            <link rel="stylesheet" href="https://unpkg.com/gitalk/dist/gitalk.css">
<script src="https://unpkg.com/gitalk/dist/gitalk.min.js"></script>

<div id="gitalk-container"></div>

<script>

  var gitalk = new Gitalk({
    clientID: 'e0833a79ae313ee43ee5',
    clientSecret: 'b56f2b325b4ecd49f15ddec8d4795a0013debc77',
    repo: 'jinyu-m.github.io',
    owner: 'Jinyu-M',
    admin: ['Jinyu-M'],
    id: (location.pathname).substring(0, 49),      // Ensure uniqueness and length less than 50
    distractionFreeMode: false  // Facebook-like distraction free mode
  })

  gitalk.render('gitalk-container')

</script>

          

          
        

        <div class="site-footer">
  Powered by <a href="https://github.com/getgridea/gridea" target="_blank">Gridea</a>
  <a class="rss" href="https://jinyu-m.github.io/atom.xml" target="_blank">
    <i class="ri-rss-line"></i> RSS
  </a>
</div>

      </div>
    </div>

    <script>
      hljs.initHighlightingOnLoad()

      let mainNavLinks = document.querySelectorAll(".markdownIt-TOC a");

      // This should probably be throttled.
      // Especially because it triggers during smooth scrolling.
      // https://lodash.com/docs/4.17.10#throttle
      // You could do like...
      // window.addEventListener("scroll", () => {
      //    _.throttle(doThatStuff, 100);
      // });
      // Only not doing it here to keep this Pen dependency-free.

      window.addEventListener("scroll", event => {
        let fromTop = window.scrollY;

        mainNavLinks.forEach((link, index) => {
          let section = document.getElementById(decodeURI(link.hash).substring(1));
          let nextSection = null
          if (mainNavLinks[index + 1]) {
            nextSection = document.getElementById(decodeURI(mainNavLinks[index + 1].hash).substring(1));
          }
          if (section.offsetTop <= fromTop) {
            if (nextSection) {
              if (nextSection.offsetTop > fromTop) {
                link.classList.add("current");
              } else {
                link.classList.remove("current");    
              }
            } else {
              link.classList.add("current");
            }
          } else {
            link.classList.remove("current");
          }
        });
      });

    </script>
  </body>
</html>
