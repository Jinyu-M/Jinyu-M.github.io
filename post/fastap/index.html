<html>
  <head>
    <meta charset="utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>Loss Function | 年少万兜鍪</title>
<link rel="shortcut icon" href="https://jinyu-m.github.io/favicon.ico?v=1615362149817">
<link href="https://cdn.jsdelivr.net/npm/remixicon@2.3.0/fonts/remixicon.css" rel="stylesheet">
<link rel="stylesheet" href="https://jinyu-m.github.io/styles/main.css">
<link rel="alternate" type="application/atom+xml" title="Loss Function | 年少万兜鍪 - Atom Feed" href="https://jinyu-m.github.io/atom.xml">
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Droid+Serif:400,700">



    <meta name="description" content="AP-Loss pdf code
目前基于深度学习的特征算法大多使用metric learning来进行训练，一般会使用pair-based，triplet-based的损失函数来进行无监督或弱监督的训练。doap和r2d2中使用了rank..." />
    <meta name="keywords" content="" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0/katex.min.css">
    <script src="https://cdn.bootcss.com/highlight.js/9.12.0/highlight.min.js"></script>
  </head>
  <body>
    <div class="main">
      <div class="main-content">
        <div class="site-header">
  <a href="https://jinyu-m.github.io">
  <img class="avatar" src="https://jinyu-m.github.io/images/avatar.png?v=1615362149817" alt="">
  </a>
  <h1 class="site-title">
    年少万兜鍪
  </h1>
  <p class="site-description">
    少年吔
尘世恰好，有诗有酒刚好吐槽
  </p>
  <div class="menu-container">
    
      
        <a href="/" class="menu">
          首页
        </a>
      
    
      
        <a href="/archives" class="menu">
          文章
        </a>
      
    
      
        <a href="/tags" class="menu">
          标签
        </a>
      
    
      
        <a href="/post/about" class="menu">
          关于
        </a>
      
    
  </div>
  <div class="social-container">
    
      
    
      
    
      
    
      
    
      
    
  </div>
</div>

        <div class="post-detail">
          <article class="post">
            <h2 class="post-title">
              Loss Function
            </h2>
            <div class="post-info">
              <span>
                2020-12-13
              </span>
              <span>
                15 min read
              </span>
              
            </div>
            
            <div class="post-content-wrapper">
              <div class="post-content">
                <h1 id="ap-loss-pdf-code">AP-Loss <a href="http://openaccess.thecvf.com/content_CVPR_2019/papers/Cakir_Deep_Metric_Learning_to_Rank_CVPR_2019_paper.pdf">pdf</a> <a href="https://github.com/kunhe/FastAP-metric-learning">code</a></h1>
<p>目前基于深度学习的特征算法大多使用metric learning来进行训练，一般会使用pair-based，triplet-based的损失函数来进行无监督或弱监督的训练。doap和r2d2中使用了rank-based <strong>A</strong>verage <strong>P</strong>recision loss，很好的提升了效果。FastAP是doap作者在doap之后发表的一篇论文，是一种高效的AP loss，我感觉和doap中的损失函数有很多共同之处(btw, doap没有提供训练代码，r2d2中讲解不详细)，所以我研读了一下这篇论文，希望可以搞懂AP loss，用于自己的模型中。</p>
<h2 id="abstract">Abstract</h2>
<p>作者基于learning to rank的方法提出了一种新的深度学习方法，FastAP，通过一种源自距离量化的近似方法来优化<strong>rank-based Average Precision</strong>。FastAP具有较低的复杂度，适应于stochastic gradient descent (SGD)。为了全面探索该方法的优势，作者还提出了一种新的minibatch sampling策略，一种允许large-batch training的新启发式方法。</p>
<h2 id="introduction">Introduction</h2>
<p>metric learning中最重要的应用领域就是nearest neighbor retrieval。对于该问题，几乎所有metric learning都基于相同的指导原则：<em>the true &quot;neighbors&quot; of a reference object should be closer than its &quot;non-neighbors&quot; in the learned metric space.</em><br>
作者将metric learning视为一种learning to rank问题，其目标是优化受learned metric影响的整体目标排序。直接优化排序相比其他算法有两个主要的优势：1.可以避免训练集的高阶爆炸，并且可以关注于对距离畸变不敏感的排序；2.值得特别注意的是，可以避免使用高度敏感的超参，如距离阈值或margin。<br>
这篇论文的主要贡献为提出一种优化AP的方法，AP被广泛用于information retrieval任务的评估，为了实现这个rank-based and non-decomposable优化目标，作者使用了一种高效的基于量化的近似方法，并让算法适应于SGD。这个方法被称为FastAP。</p>
<h2 id="learning-to-rank-with-average-precision">Learning to Rank with Average Precision</h2>
<p>假设设置一个标准的信息检索任务，给定特征空间<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>χ</mi></mrow><annotation encoding="application/x-tex">\chi</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathdefault">χ</span></span></span></span>，有一个query <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>q</mi><mo>∈</mo><mi>χ</mi></mrow><annotation encoding="application/x-tex">q \in \chi</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7335400000000001em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">q</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathdefault">χ</span></span></span></span>和一个检索数据集<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi mathvariant="script">R</mi><mo>⊂</mo><mi>χ</mi></mrow><annotation encoding="application/x-tex">\mathcal{R} \subset \chi</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.72243em;vertical-align:-0.0391em;"></span><span class="mord"><span class="mord mathcal">R</span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">⊂</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathdefault">χ</span></span></span></span>。我们的目标是训练一个神经网络<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi mathvariant="normal">Ψ</mi><mo>:</mo><mi>χ</mi><mo>→</mo><msup><mi mathvariant="double-struck">R</mi><mi>m</mi></msup></mrow><annotation encoding="application/x-tex">\Psi: \chi \rightarrow \mathbb{R}^{m}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord">Ψ</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathdefault">χ</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">→</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.68889em;vertical-align:0em;"></span><span class="mord"><span class="mord"><span class="mord mathbb">R</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.664392em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">m</span></span></span></span></span></span></span></span></span></span></span></span>，将输入嵌入到一个m维的欧拉空间中，并且在欧氏空间中优化AP。<br>
为了实现最近邻检索，我们首先要根据与q的距离对<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi mathvariant="script">R</mi></mrow><annotation encoding="application/x-tex">\mathcal{R}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord"><span class="mord mathcal">R</span></span></span></span></span>中的目标进行排序，得到一个有序的列表<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mo>{</mo><msub><mi>x</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>x</mi><mn>2</mn></msub><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo separator="true">,</mo><msub><mi>x</mi><mi>N</mi></msub><mo>}</mo></mrow><annotation encoding="application/x-tex">\{x_1, x_2,...,x_N\}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">{</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.10903em;">N</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">}</span></span></span></span>，其中<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>N</mi><mo>=</mo><mi mathvariant="normal">∣</mi><mi mathvariant="script">R</mi><mi mathvariant="normal">∣</mi></mrow><annotation encoding="application/x-tex">N=|\mathcal{R}|</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.10903em;">N</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">∣</span><span class="mord"><span class="mord mathcal">R</span></span><span class="mord">∣</span></span></span></span>。然后，我们可以得到Precision-Recall曲线：<br>
<img src="https://jinyu-m.github.io/post-images/1610854661572.png" alt="" loading="lazy"><br>
其中，Prec(i)和Rec(i)为有序列表中第i个位置上的准确率和召回率。由此，可以计算AP：<br>
<img src="https://jinyu-m.github.io/post-images/1610854670940.png" alt="" loading="lazy"><br>
为了方便，我们假设Prec(0)=Rec(0)=0.<br>
上述得到AP的方法有一个问题，就是为了获得p-r曲线，需要先获得一个有序的列表，而这一步中包含了离散的排序操作。对于基于梯度的优化来说，排序是主要的障碍：虽然排序几乎处处可微，它的倒数是0或者未定义的。相反，作者的主要观点为：AP会存在另一种解释，它是基于把准确率和召回率看作距离的函数这一观点的，而非基于有序的元素。</p>
<h3 id="fastap">FastAP</h3>
<p>在信息检索领域，AP也可以解释为the area under precision-recall curve (AUPR)。当公式3的基数趋于无穷，这一关系是存在的：<br>
<img src="https://jinyu-m.github.io/post-images/1610854680266.png" alt="" loading="lazy"><br>
其中<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi mathvariant="script">R</mi><mo>+</mo></msup><mo separator="true">,</mo><mo>(</mo><msup><mi mathvariant="script">R</mi><mo>−</mo></msup><mo>)</mo><mo>⊂</mo><mi mathvariant="script">R</mi></mrow><annotation encoding="application/x-tex">\mathcal{R}^+, (\mathcal{R}^-) \subset \mathcal{R}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.021331em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord"><span class="mord mathcal">R</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.771331em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">+</span></span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mopen">(</span><span class="mord"><span class="mord"><span class="mord mathcal">R</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.771331em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">−</span></span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">⊂</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord"><span class="mord mathcal">R</span></span></span></span></span>代表了q的匹配（非匹配）集合。AP的AUPR解释允许将准确率和召回率看作距离，而非有序元素的有参数函数。这样可以帮助我们避免不可微的排序操作，进而提出一种AP的近似方法。<br>
一个连续的p-r曲线（不是如公式1中那种有限的集合）可以定义为：<br>
<img src="https://jinyu-m.github.io/post-images/1610854688240.png" alt="" loading="lazy"><br>
其中z表示query与<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi mathvariant="script">R</mi></mrow><annotation encoding="application/x-tex">\mathcal{R}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord"><span class="mord mathcal">R</span></span></span></span></span>中元素的距离，z在区域<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi mathvariant="normal">Ω</mi></mrow><annotation encoding="application/x-tex">\Omega</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord">Ω</span></span></span></span>中。AP随之变为：<br>
<img src="https://jinyu-m.github.io/post-images/1610854696576.png" alt="" loading="lazy"><br>
接着，我们定义一些概率量化来计算公式7。令<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi mathvariant="script">Z</mi></mrow><annotation encoding="application/x-tex">\mathcal{Z}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord"><span class="mord mathcal" style="margin-right:0.07944em;">Z</span></span></span></span></span>为对应距离z的随机变量，那么<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi mathvariant="script">R</mi><mo>+</mo></msup><mo separator="true">,</mo><msup><mi mathvariant="script">R</mi><mo>−</mo></msup></mrow><annotation encoding="application/x-tex">\mathcal{R}^+, \mathcal{R}^-</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9657709999999999em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord"><span class="mord mathcal">R</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.771331em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">+</span></span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord"><span class="mord mathcal">R</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.771331em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">−</span></span></span></span></span></span></span></span></span></span></span>的距离分布可以定义为<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>p</mi><mo>(</mo><mi>z</mi><mi mathvariant="normal">∣</mi><msup><mi mathvariant="script">R</mi><mo>+</mo></msup><mo>)</mo><mo separator="true">,</mo><mi>p</mi><mo>(</mo><mi>z</mi><mi mathvariant="normal">∣</mi><msup><mi mathvariant="script">R</mi><mo>−</mo></msup><mo>)</mo></mrow><annotation encoding="application/x-tex">p(z|\mathcal{R}^+), p(z|\mathcal{R}^-)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.021331em;vertical-align:-0.25em;"></span><span class="mord mathdefault">p</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="mord">∣</span><span class="mord"><span class="mord"><span class="mord mathcal">R</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.771331em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">+</span></span></span></span></span></span></span></span><span class="mclose">)</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">p</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="mord">∣</span><span class="mord"><span class="mord"><span class="mord mathcal">R</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.771331em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">−</span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>。令<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>P</mi><mo>(</mo><msup><mi mathvariant="script">R</mi><mo>+</mo></msup><mo>)</mo></mrow><annotation encoding="application/x-tex">P(\mathcal{R}^+)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.021331em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord"><span class="mord"><span class="mord mathcal">R</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.771331em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">+</span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>和<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>P</mi><mo>(</mo><msup><mi mathvariant="script">R</mi><mo>−</mo></msup><mo>)</mo><mo>=</mo><mn>1</mn><mo>−</mo><mi>P</mi><mo>(</mo><msup><mi mathvariant="script">R</mi><mo>+</mo></msup><mo>)</mo></mrow><annotation encoding="application/x-tex">P(\mathcal{R}^-)=1-P(\mathcal{R}^+)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.021331em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord"><span class="mord"><span class="mord mathcal">R</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.771331em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">−</span></span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.021331em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord"><span class="mord"><span class="mord mathcal">R</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.771331em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">+</span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>为先验概率，表示了检索集合<span class='katex-error' title='ParseError: KaTeX parse error: Expected &#039;}&#039;, got &#039;EOF&#039; at end of input: \mathcal{R'>\mathcal{R</span>相对于query的偏度。最后，令<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>F</mi><mo>(</mo><mi>z</mi><mo>)</mo><mo>=</mo><mi>P</mi><mo>(</mo><mi mathvariant="script">Z</mi><mo>&lt;</mo><mi>z</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">F(z)=P(\mathcal{Z}&lt; z)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">F</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord"><span class="mord mathcal" style="margin-right:0.07944em;">Z</span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="mclose">)</span></span></span></span>来表示<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi mathvariant="script">Z</mi></mrow><annotation encoding="application/x-tex">\mathcal{Z}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord"><span class="mord mathcal" style="margin-right:0.07944em;">Z</span></span></span></span></span>的累积分布。<br>
基于以上定义，准确率和召回率可以定义为：<br>
<img src="https://jinyu-m.github.io/post-images/1610854704788.png" alt="" loading="lazy"><br>
带入公式7，得到：<br>
<img src="https://jinyu-m.github.io/post-images/1610854712132.png" alt="" loading="lazy"><br>
显然地，公式12可以用有限集合来近似估计。我们首先假设嵌入函数<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi mathvariant="normal">Ψ</mi></mrow><annotation encoding="application/x-tex">\Psi</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord">Ψ</span></span></span></span>的输出是L2-normalized，因此，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi mathvariant="normal">Ω</mi></mrow><annotation encoding="application/x-tex">\Omega</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord">Ω</span></span></span></span>或者说公式12的z是属于<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mo>[</mo><mn>0</mn><mo separator="true">,</mo><mn>2</mn><mo>]</mo></mrow><annotation encoding="application/x-tex">[0,2]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">[</span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">2</span><span class="mclose">]</span></span></span></span>的。然后，我们将<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mo>[</mo><mn>0</mn><mo separator="true">,</mo><mn>2</mn><mo>]</mo></mrow><annotation encoding="application/x-tex">[0,2]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">[</span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">2</span><span class="mclose">]</span></span></span></span>用有限集合量化为<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>Z</mi><mo>=</mo><mrow><msub><mi>z</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>z</mi><mn>2</mn></msub><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo separator="true">,</mo><msub><mi>z</mi><mi>L</mi></msub></mrow></mrow><annotation encoding="application/x-tex">Z={z_1,z_2,...,z_L}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.07153em;">Z</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord"><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.04398em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.04398em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.04398em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">L</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span>，令产生的离线概率分布函数PDF为P，最后我们定义这种新的近似为FastAP：<br>
<img src="https://jinyu-m.github.io/post-images/1610854719905.png" alt="" loading="lazy"><br>
接着，作者用直方图符号来重新说明FastAP。明确的来说，作者构建了一个距离直方图，每个bin的中心点（中值）为Z的每个元素。令<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>h</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">h_j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.980548em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span>为第j个bin中元素的数量，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>H</mi><mi>j</mi></msub><mo>=</mo><msub><mo>∑</mo><mrow><mi>k</mi><mo>≤</mo><mi>j</mi></mrow></msub><msub><mi>h</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">H_j=\sum_{k\le j}h_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.969438em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.08125em;">H</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.08125em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.185818em;vertical-align:-0.43581800000000004em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:-0.0000050000000000050004em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.18639799999999984em;"><span style="top:-2.40029em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span><span class="mrel mtight">≤</span><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.43581800000000004em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>为直方图的累积和。并且，令<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msubsup><mi>h</mi><mi>j</mi><mo>+</mo></msubsup></mrow><annotation encoding="application/x-tex">h^+_j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.224434em;vertical-align:-0.412972em;"></span><span class="mord"><span class="mord mathdefault">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.811462em;"><span style="top:-2.4231360000000004em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span><span style="top:-3.1031310000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">+</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.412972em;"><span></span></span></span></span></span></span></span></span></span>为第j个bin内query的正确匹配数量，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msubsup><mi>H</mi><mi>j</mi><mo>+</mo></msubsup></mrow><annotation encoding="application/x-tex">H^+_j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.224434em;vertical-align:-0.412972em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.08125em;">H</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.811462em;"><span style="top:-2.4231360000000004em;margin-left:-0.08125em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span><span style="top:-3.1031310000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">+</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.412972em;"><span></span></span></span></span></span></span></span></span></span>为其累积和。根据这些定义，我们可以重写公式13的概率量化，得到一个简单的表达式：<br>
<img src="https://jinyu-m.github.io/post-images/1610854727835.png" alt="" loading="lazy"><br>
进行histogram bining和计算FastAP的时间复杂度为O(NL)。</p>
<h2 id="stochastic-optimization">Stochastic Optimization</h2>
<p>AP被定义为关于query和retrieval set间的检索问题。在minibatches中，一个自然的选择是定义in-batch检索问题，其中检索集<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi mathvariant="script">R</mi></mrow><annotation encoding="application/x-tex">\mathcal{R}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord"><span class="mord mathcal">R</span></span></span></span></span>被限制在minibatch中。特别地，我们将每个样本都视为q，来从这个batch内其他样本中检索匹配。每个样本的检索都可以得到一个AP，一个minibatch内的整体目标即为它们的平均值mAP。<br>
为了使用梯度下降法优化目标，公式14内的直方图必须使用允许梯度下降的方法来构建。为此，我们使用了简单的线性插值技术来用一种可微的soft bining技术来代替一般的bining处理。这种插值使得整数型的bin计数变为连续的，定义为<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mover accent="true"><mi>h</mi><mo>^</mo></mover></mrow><annotation encoding="application/x-tex">\hat{h}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9578799999999998em;vertical-align:0em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9578799999999998em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault">h</span></span></span><span style="top:-3.26344em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.25em;">^</span></span></span></span></span></span></span></span></span>，累积和为<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mover accent="true"><mi>H</mi><mo>^</mo></mover></mrow><annotation encoding="application/x-tex">\hat{H}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9467699999999999em;vertical-align:0em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9467699999999999em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.08125em;">H</span></span></span><span style="top:-3.25233em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.19444em;">^</span></span></span></span></span></span></span></span></span>。基于这一可微的bining处理，我们现在可以获得FastAP的偏微分。<br>
并且，与doap中的bining不同，这篇论文中的FastAP可以直接用于训练浮点型描述子，而doap中对应部分其实是将浮点型描述子量化为与二进制描述子一样的直方图，然后用二进制描述子的优化方法去训练，会带来额外的损失。</p>
<h2 id="large-batch-training">Large-Batch Training</h2>
<p>作者首先说了，data parallelism对于FastAP是不可取的，因为FastAP是不可分解的：即每个样本目标函数的值是由这个batch内其他样本来决定的。<br>
作者提出一种启发式的方法来让FastAP可以进行large-batch training。The main insight is that the loss layer takes the embedding matrix of the minibatch as input (see supplementary material). Thus, a large batch can be first broken into smaller chunks to incrementally compute the embedding matrix. Then, we compute the gradients with respect to the embedding matrix, which is a relatively lightweight operation involving only the loss layer. Finally, gradients are back-propagated through the network, again in chunks. This solution works even with a single GPU.（没看懂.....）</p>
<h2 id="minibatch-sampling">Minibatch Sampling</h2>
<p><img src="https://jinyu-m.github.io/post-images/1610854736976.png" alt="" loading="lazy"><br>
大体上来讲，就是作者提出一种采样方法来让一个batch内的negatives更hard，作者利用categories这一概念，一个category包含一些class label对应于此的类，所以在采样一个batch的数据时，先挑选少量几个categories，再从每个category中挑选单独的类，这样一个category中不同类就构成了hard negatives。</p>
<h2 id="code-with-comments">code with comments</h2>
<p>代码是作者开源的，加了一些自己的注释方便理解。</p>
<pre><code class="language-python">import torch
from torch.autograd import Variable, Function

def softBinning(D, mid, Delta):
    &quot;&quot;&quot;
    Args:
        D:      torch.Tensor(N x N), distance matrix
        mid:    torch.Tensor(1), middle value of an interval in histogram
        Delta:  torch.Tensor(1), step of histogram
    &quot;&quot;&quot;
    y = 1 - torch.abs(D-mid)/Delta
    return torch.max(torch.Tensor([0]).cuda(), y)

def dSoftBinning(D, mid, Delta):
    side1 = (D &gt; (mid - Delta)).type(torch.float)
    side2 = (D &lt;= mid).type(torch.float)
    ind1 = (side1 * side2) #.type(torch.uint8)

    side1 = (D &gt; mid).type(torch.float)
    side2 = (D &lt;= (mid + Delta)).type(torch.float)
    ind2 = (side1 * side2) #.type(torch.uint8)

    return (ind1 - ind2)/Delta
    

class FastAP(torch.autograd.Function):
    &quot;&quot;&quot;
    FastAP - autograd function definition

    This class implements the FastAP loss from the following paper:
    &quot;Deep Metric Learning to Rank&quot;, 
    F. Cakir, K. He, X. Xia, B. Kulis, S. Sclaroff. CVPR 2019

    NOTE:
        Given a input batch, FastAP does not sample triplets from it as it's not 
        a triplet-based method. Therefore, FastAP does not take a Sampler as input. 
        Rather, we specify how the input batch is selected.
    &quot;&quot;&quot;

    @staticmethod
    def forward(ctx, input, target, num_bins):
        &quot;&quot;&quot;
        Args:
            input:     torch.Tensor(N x embed_dim), embedding matrix
            target:    torch.Tensor(N x 1), class labels
            num_bins:  int, number of bins in distance histogram
        &quot;&quot;&quot;
        N = target.size()[0]
        assert input.size()[0] == N, &quot;Batch size donesn't match!&quot;
        
        # 1. get affinity matrix
        Y   = target.unsqueeze(1) # shape(N)
        Aff = 2 * (Y == Y.t()).type(torch.float) - 1 # shape(N, N), value{-1, 1}, 1:matched, -1:unmatched
        Aff.masked_fill_(torch.eye(N, N).byte(), 0)  # set diagonal to 0

        I_pos = (Aff &gt; 0).type(torch.float).cuda() # bool, positive matches
        I_neg = (Aff &lt; 0).type(torch.float).cuda() # bool, negatives
        N_pos = torch.sum(I_pos, 1) # the number of positives for each query

        # 2. compute distances from embeddings
        # squared Euclidean distance with range [0,4]
        dist2 = 2 - 2 * torch.mm(input, input.t()) # shape(N, N), value[0, 4], less -&gt; more similar

        # 3. estimate discrete histograms
        Delta = torch.tensor(4. / num_bins).cuda() # step
        Z     = torch.linspace(0., 4., steps=num_bins+1).cuda() # histograms
        L     = Z.size()[0] # length of histograms
        h_pos = torch.zeros((N, L)).cuda() # shape(N, L)
        h_neg = torch.zeros((N, L)).cuda() # shape(N, L)
        for l in range(L): # for each interval of histogram
            pulse    = softBinning(dist2, Z[l], Delta) # shape(N, N), the distance ratio related to corresponding interval
            h_pos[:,l] = torch.sum(pulse * I_pos, 1) # number of positives locating in corresponding interval
            h_neg[:,l] = torch.sum(pulse * I_neg, 1) # number of negatives locating in corresponding interval

        H_pos = torch.cumsum(h_pos, 1) # shape(N, L), number of positive matches for each query under threshold (precision)
        h     = h_pos + h_neg # shape(N, L)
        H     = torch.cumsum(h, 1) # shape(N, L), number of total matches for each query under threshold (base)
        
        # 4. compate FastAP, as in paper &quot;Deep Metric Learning to Rank&quot;
        FastAP = h_pos * H_pos / H
        FastAP[torch.isnan(FastAP) | torch.isinf(FastAP)] = 0
        FastAP = torch.sum(FastAP,1) / N_pos
        FastAP = FastAP[ ~torch.isnan(FastAP) ]
        loss   = 1 - torch.mean(FastAP)
        if torch.rand(1) &gt; 0.99:
            print(&quot;loss value (1-mean(FastAP)): &quot;, loss.item())

        # 6. save for backward
        ctx.save_for_backward(input, target)
        ctx.Z     = Z
        ctx.Delta = Delta
        ctx.dist2 = dist2
        ctx.I_pos = I_pos
        ctx.I_neg = I_neg
        ctx.h_pos = h_pos
        ctx.h_neg = h_neg
        ctx.H_pos = H_pos
        ctx.N_pos = N_pos
        ctx.h     = h
        ctx.H     = H
        ctx.L     = torch.tensor(L)
        
        return loss

    
    @staticmethod
    def backward(ctx, grad_output):
        input, target = ctx.saved_tensors

        Z     = Variable(ctx.Z     , requires_grad = False)
        Delta = Variable(ctx.Delta , requires_grad = False)
        dist2 = Variable(ctx.dist2 , requires_grad = False)
        I_pos = Variable(ctx.I_pos , requires_grad = False)
        I_neg = Variable(ctx.I_neg , requires_grad = False)
        h     = Variable(ctx.h     , requires_grad = False)
        H     = Variable(ctx.H     , requires_grad = False)
        h_pos = Variable(ctx.h_pos , requires_grad = False)
        h_neg = Variable(ctx.h_neg , requires_grad = False)
        H_pos = Variable(ctx.H_pos , requires_grad = False)
        N_pos = Variable(ctx.N_pos , requires_grad = False)

        L     = Z.size()[0]
        H2    = torch.pow(H,2)
        H_neg = H - H_pos

        # 1. d(FastAP)/d(h+)
        LTM1 = torch.tril(torch.ones(L,L), -1)  # lower traingular matrix
        tmp1 = h_pos * H_neg / H2
        tmp1[torch.isnan(tmp1)] = 0

        d_AP_h_pos = (H_pos * H + h_pos * H_neg) / H2 
        d_AP_h_pos = d_AP_h_pos + torch.mm(tmp1, LTM1.cuda())
        d_AP_h_pos = d_AP_h_pos / N_pos.repeat(L,1).t()
        d_AP_h_pos[torch.isnan(d_AP_h_pos) | torch.isinf(d_AP_h_pos)] = 0


        # 2. d(FastAP)/d(h-)
        LTM0 = torch.tril(torch.ones(L,L), 0)  # lower triangular matrix
        tmp2 = -h_pos * H_pos / H2
        tmp2[torch.isnan(tmp2)] = 0

        d_AP_h_neg = torch.mm(tmp2, LTM0.cuda())
        d_AP_h_neg = d_AP_h_neg / N_pos.repeat(L,1).t()
        d_AP_h_neg[torch.isnan(d_AP_h_neg) | torch.isinf(d_AP_h_neg)] = 0


        # 3. d(FastAP)/d(embedding)
        d_AP_x = 0
        for l in range(L):
            dpulse = dSoftBinning(dist2, Z[l], Delta)
            dpulse[torch.isnan(dpulse) | torch.isinf(dpulse)] = 0
            ddp = dpulse * I_pos
            ddn = dpulse * I_neg

            alpha_p = torch.diag(d_AP_h_pos[:,l]) # N*N
            alpha_n = torch.diag(d_AP_h_neg[:,l])
            Ap = torch.mm(ddp, alpha_p) + torch.mm(alpha_p, ddp)
            An = torch.mm(ddn, alpha_n) + torch.mm(alpha_n, ddn)

            # accumulate gradient 
            d_AP_x = d_AP_x - torch.mm(input.t(), (Ap+An))

        grad_input = -d_AP_x
        return grad_input.t(), None, None    


class FastAPLoss(torch.nn.Module):
    &quot;&quot;&quot;
    FastAP - loss layer definition

    This class implements the FastAP loss from the following paper:
    &quot;Deep Metric Learning to Rank&quot;, 
    F. Cakir, K. He, X. Xia, B. Kulis, S. Sclaroff. CVPR 2019
    &quot;&quot;&quot;
    def __init__(self, num_bins=10):
        super(FastAPLoss, self).__init__()
        self.num_bins = num_bins

    def forward(self, batch, labels):
        return FastAP.apply(batch, labels, self.num_bins)
</code></pre>

              </div>
              <div class="toc-container">
                <ul class="markdownIt-TOC">
<li><a href="#ap-loss-pdf-code">AP-Loss pdf code</a>
<ul>
<li><a href="#abstract">Abstract</a></li>
<li><a href="#introduction">Introduction</a></li>
<li><a href="#learning-to-rank-with-average-precision">Learning to Rank with Average Precision</a>
<ul>
<li><a href="#fastap">FastAP</a></li>
</ul>
</li>
<li><a href="#stochastic-optimization">Stochastic Optimization</a></li>
<li><a href="#large-batch-training">Large-Batch Training</a></li>
<li><a href="#minibatch-sampling">Minibatch Sampling</a></li>
<li><a href="#code-with-comments">code with comments</a></li>
</ul>
</li>
</ul>

              </div>
            </div>
          </article>
        </div>

        
          <div class="next-post">
            <div class="next">下一篇</div>
            <a href="https://jinyu-m.github.io/post/dataset/">
              <h3 class="post-title">
                Dataset
              </h3>
            </a>
          </div>
        

        
          
            <link rel="stylesheet" href="https://unpkg.com/gitalk/dist/gitalk.css">
<script src="https://unpkg.com/gitalk/dist/gitalk.min.js"></script>

<div id="gitalk-container"></div>

<script>

  var gitalk = new Gitalk({
    clientID: 'e0833a79ae313ee43ee5',
    clientSecret: 'b56f2b325b4ecd49f15ddec8d4795a0013debc77',
    repo: 'jinyu-m.github.io',
    owner: 'Jinyu-M',
    admin: ['Jinyu-M'],
    id: (location.pathname).substring(0, 49),      // Ensure uniqueness and length less than 50
    distractionFreeMode: false  // Facebook-like distraction free mode
  })

  gitalk.render('gitalk-container')

</script>

          

          
        

        <div class="site-footer">
  Powered by <a href="https://github.com/getgridea/gridea" target="_blank">Gridea</a>
  <a class="rss" href="https://jinyu-m.github.io/atom.xml" target="_blank">
    <i class="ri-rss-line"></i> RSS
  </a>
</div>

      </div>
    </div>

    <script>
      hljs.initHighlightingOnLoad()

      let mainNavLinks = document.querySelectorAll(".markdownIt-TOC a");

      // This should probably be throttled.
      // Especially because it triggers during smooth scrolling.
      // https://lodash.com/docs/4.17.10#throttle
      // You could do like...
      // window.addEventListener("scroll", () => {
      //    _.throttle(doThatStuff, 100);
      // });
      // Only not doing it here to keep this Pen dependency-free.

      window.addEventListener("scroll", event => {
        let fromTop = window.scrollY;

        mainNavLinks.forEach((link, index) => {
          let section = document.getElementById(decodeURI(link.hash).substring(1));
          let nextSection = null
          if (mainNavLinks[index + 1]) {
            nextSection = document.getElementById(decodeURI(mainNavLinks[index + 1].hash).substring(1));
          }
          if (section.offsetTop <= fromTop) {
            if (nextSection) {
              if (nextSection.offsetTop > fromTop) {
                link.classList.add("current");
              } else {
                link.classList.remove("current");    
              }
            } else {
              link.classList.add("current");
            }
          } else {
            link.classList.remove("current");
          }
        });
      });

    </script>
  </body>
</html>
