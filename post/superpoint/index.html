<html>
  <head>
    <meta charset="utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>Deep Local Features: SuperPoint | 年少万兜鍪</title>
<link rel="shortcut icon" href="https://jinyu-m.github.io/favicon.ico?v=1604542530524">
<link href="https://cdn.jsdelivr.net/npm/remixicon@2.3.0/fonts/remixicon.css" rel="stylesheet">
<link rel="stylesheet" href="https://jinyu-m.github.io/styles/main.css">
<link rel="alternate" type="application/atom+xml" title="Deep Local Features: SuperPoint | 年少万兜鍪 - Atom Feed" href="https://jinyu-m.github.io/atom.xml">
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Droid+Serif:400,700">



    <meta name="description" content="作者在MagicPoint的基础上增加了提取descriptor的部分，提出了homographic adaptation的数据增强方法，用来训练detector的repeatability，并且使得训练数据可以从虚拟的仿真数据拓展到MS-..." />
    <meta name="keywords" content="Deep learning" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0/katex.min.css">
    <script src="https://cdn.bootcss.com/highlight.js/9.12.0/highlight.min.js"></script>
  </head>
  <body>
    <div class="main">
      <div class="main-content">
        <div class="site-header">
  <a href="https://jinyu-m.github.io">
  <img class="avatar" src="https://jinyu-m.github.io/images/avatar.png?v=1604542530524" alt="">
  </a>
  <h1 class="site-title">
    年少万兜鍪
  </h1>
  <p class="site-description">
    Jinyu Miao
尘世恰好，有诗有酒刚好吐槽
  </p>
  <div class="menu-container">
    
      
        <a href="/" class="menu">
          首页
        </a>
      
    
      
        <a href="/archives" class="menu">
          文章
        </a>
      
    
      
        <a href="/tags" class="menu">
          标签
        </a>
      
    
      
        <a href="/post/about" class="menu">
          关于
        </a>
      
    
  </div>
  <div class="social-container">
    
      
    
      
    
      
    
      
    
      
    
  </div>
</div>

        <div class="post-detail">
          <article class="post">
            <h2 class="post-title">
              Deep Local Features: SuperPoint
            </h2>
            <div class="post-info">
              <span>
                2020-11-05
              </span>
              <span>
                4 min read
              </span>
              
                <a href="https://jinyu-m.github.io/tag/dJ8NdBIXq/" class="post-tag">
                  # Deep learning
                </a>
              
            </div>
            
            <div class="post-content-wrapper">
              <div class="post-content">
                <p>作者在MagicPoint的基础上增加了提取descriptor的部分，提出了homographic adaptation的数据增强方法，用来训练detector的repeatability，并且使得训练数据可以从虚拟的仿真数据拓展到MS-COCO等真实数据。</p>
<!-- more -->
<h1 id="superpoint-magic-leap-pdf-official-code-society-code">SuperPoint (Magic Leap) <a href="https://arxiv.org/abs/1712.07629.pdf">pdf</a> <a href="https://github.com/magicleap/SuperPointPretrainedNetwork">official code</a> <a href="https://github.com/rpautrat/SuperPoint">society code</a></h1>
<h2 id="introduction"><em>Introduction</em></h2>
<p>作者认为deep feature训练的关键在于带有标签的数据，但是人工标注的数据中，关键点往往是ill-defined，所以作者提出自监督方法训练，用网络本身去标注一批伪真值关键点，在此基础上进行训练，这样做，关键点更丰富，标注成本也更低。</p>
<figure data-type="image" tabindex="1"><img src="https://jinyu-m.github.io/post-images/1604541876168.png" alt="" loading="lazy"></figure>
<p>第一步，其实就是之前提到的训练MagicPoint，先构建了一个仿真数据集Synthetic Shapes，训练了MagicPoint(b)。虽然之前的论文提到MagicPoint在应对各种干扰时重复率和准确率都很高，但是它丢失了一些潜在的关键点，为了解决这个问题，作者用Homographic Adaption去增强了MagicPoint标注的真实图像，得到了一个更符合预期的真实数据(b)，并用此去训练一个新的网络SuperPoint(c).</p>
<h2 id="architecture"><em>Architecture</em></h2>
<figure data-type="image" tabindex="2"><img src="https://jinyu-m.github.io/post-images/1604541894356.png" alt="" loading="lazy"></figure>
<p>SuperPoint由一个共享参数的encoder和两个task-specific decoders构成，采用vgg结构，图像(H x W)通过encoder，得到一个1/8大小(Hc x Wc)的feature map。</p>
<p>在<strong>interest point decoder</strong>中，网络依旧延续MagicPoint的做法，采用非参数的上采样过程，feature map通过head降维到65 x Hc x Wc维，分别代表原图中与之对应的8x8区域内每个点是关键点的概率以及一个dustbin通道，dustbin用以表示该8x8区域内无关键点。</p>
<p>在<strong>descriptor decoder</strong>中，网络先提取了Hc x Wc的semi-dense descriptor，每个descriptor代表与之对应的8x8区域内关键点的256-d descriptor（根据interest point detector，每8x8区域内只可能存在1/0个关键点），然后采用bi-cubic插值恢复到原分辨率。</p>
<h2 id="loss"><em>Loss</em></h2>
<p>训练interest point detector依旧采用对每个cell计算cross-entropy loss的方法：</p>
<figure data-type="image" tabindex="3"><img src="https://jinyu-m.github.io/post-images/1604542024924.png" alt="" loading="lazy"></figure>
<p>为了使这部分Lp降低，需要让Y中为1的位置（即该点为关键点）在X中有较大的值，即增大该点为关键点的概率。</p>
<p>训练descriptor extractor时，需要先找到匹配的点，然后用匹配点的descriptor来计算loss，所以先找判断图1(h,w)和图2(h',w')是否是一组匹配点：</p>
<figure data-type="image" tabindex="4"><img src="https://jinyu-m.github.io/post-images/1604542034183.png" alt="" loading="lazy"></figure>
<p>p是cell的中心位置，H是真值homography，所以上式就是判断两个cell在原图中中心是否是符合真值homography的，如果是，则这两个位置时一对匹配点，可以计算它们descriptor的距离了：</p>
<figure data-type="image" tabindex="5"><img src="https://jinyu-m.github.io/post-images/1604542039512.png" alt="" loading="lazy"></figure>
<p>上式中当图1和图2中两个点是匹配点时，s=1，则两个点的descriptor之间的cosine距离应该越大越好；而当两个点不匹配时，s=0，两个点的descriptor间的cosine距离越小越好。此处作者采用了hinge loss。</p>
<p>综上，SuperPoint训练使用的loss：</p>
<figure data-type="image" tabindex="6"><img src="https://jinyu-m.github.io/post-images/1604542045657.png" alt="" loading="lazy"></figure>
<p>分别计算图1和图2与真值图像的interest point loss，再计算图1与图2间的descriptor loss。</p>
<h2 id="training"><em>Training</em></h2>
<p>作者先训练了SuperPoint中提取关键点的detector pathway，其实就是MagicPoint，发现在虚拟数据集上MP表现很好，在真实数据中，当场景中有大量角点时，效果很好，但是在自然场景中，MP效果不如传统特征，所以作者提出<strong>用自监督方法在真实场景中训练网络</strong>，即Homographic Adaptation。</p>
<h2 id="homographic-adaptation"><em>Homographic Adaptation</em></h2>
<figure data-type="image" tabindex="7"><img src="https://jinyu-m.github.io/post-images/1604542062673.png" alt="" loading="lazy"></figure>
<p>可通过iterative homographic adaptation来提升效果。100次random homography效果较好。</p>
<h2 id="一些见解"><em>一些见解</em></h2>
<p>作为MagicPoint的升级版，SuperPoint我感觉其实是作者发现了MagicPoint只是单纯的去学习检测人工标注的那些点，比较局限，所以提出了homographic adaptation去进一步提升自己。并且加入了descriptor decoder，让整个系统更完整了。但是对比后续出现的特征，SuperPoint特征在训练时依旧采用监督的方法去训练detector，导致效果有待提升。在我的试验中，Bag of SuperPoint会提升loop closure的表现，但是用于SLAM系统（ORB-SLAM2）时，SuperPoint从一幅图像提取的特征过少，可能无法满足SLAM初始化的要求。</p>

              </div>
              <div class="toc-container">
                <ul class="markdownIt-TOC">
<li><a href="#superpoint-magic-leap-pdf-official-code-society-code">SuperPoint (Magic Leap) pdf official code society code</a>
<ul>
<li><a href="#introduction"><em>Introduction</em></a></li>
<li><a href="#architecture"><em>Architecture</em></a></li>
<li><a href="#loss"><em>Loss</em></a></li>
<li><a href="#training"><em>Training</em></a></li>
<li><a href="#homographic-adaptation"><em>Homographic Adaptation</em></a></li>
<li><a href="#%E4%B8%80%E4%BA%9B%E8%A7%81%E8%A7%A3"><em>一些见解</em></a></li>
</ul>
</li>
</ul>

              </div>
            </div>
          </article>
        </div>

        
          <div class="next-post">
            <div class="next">下一篇</div>
            <a href="https://jinyu-m.github.io/post/deep-local-features-magicpoint/">
              <h3 class="post-title">
                Deep Local Features: MagicPoint
              </h3>
            </a>
          </div>
        

        

        <div class="site-footer">
  Powered by <a href="https://github.com/getgridea/gridea" target="_blank">Gridea</a>
  <a class="rss" href="https://jinyu-m.github.io/atom.xml" target="_blank">
    <i class="ri-rss-line"></i> RSS
  </a>
</div>

      </div>
    </div>

    <script>
      hljs.initHighlightingOnLoad()

      let mainNavLinks = document.querySelectorAll(".markdownIt-TOC a");

      // This should probably be throttled.
      // Especially because it triggers during smooth scrolling.
      // https://lodash.com/docs/4.17.10#throttle
      // You could do like...
      // window.addEventListener("scroll", () => {
      //    _.throttle(doThatStuff, 100);
      // });
      // Only not doing it here to keep this Pen dependency-free.

      window.addEventListener("scroll", event => {
        let fromTop = window.scrollY;

        mainNavLinks.forEach((link, index) => {
          let section = document.getElementById(decodeURI(link.hash).substring(1));
          let nextSection = null
          if (mainNavLinks[index + 1]) {
            nextSection = document.getElementById(decodeURI(mainNavLinks[index + 1].hash).substring(1));
          }
          if (section.offsetTop <= fromTop) {
            if (nextSection) {
              if (nextSection.offsetTop > fromTop) {
                link.classList.add("current");
              } else {
                link.classList.remove("current");    
              }
            } else {
              link.classList.add("current");
            }
          } else {
            link.classList.remove("current");
          }
        });
      });

    </script>
  </body>
</html>
