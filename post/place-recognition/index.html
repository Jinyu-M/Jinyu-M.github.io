<html>
  <head>
    <meta charset="utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>Place Recognition/Loop Closure Detection | 年少万兜鍪</title>
<link rel="shortcut icon" href="https://jinyu-m.github.io/favicon.ico?v=1615445259424">
<link href="https://cdn.jsdelivr.net/npm/remixicon@2.3.0/fonts/remixicon.css" rel="stylesheet">
<link rel="stylesheet" href="https://jinyu-m.github.io/styles/main.css">
<link rel="alternate" type="application/atom+xml" title="Place Recognition/Loop Closure Detection | 年少万兜鍪 - Atom Feed" href="https://jinyu-m.github.io/atom.xml">
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Droid+Serif:400,700">



    <meta name="description" content="写在前面
这篇日志是自己在回环检测领域看过的一些论文，有离线训练词典的，有增量式构建词典的，不一而足。就我个人感觉而言，回环检测目前的趋势还是增量式检测在SLAM中的应用，当前的SLAM系统大多还停留在离线训练词典的阶段，但是在我的实验中，..." />
    <meta name="keywords" content="" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0/katex.min.css">
    <script src="https://cdn.bootcss.com/highlight.js/9.12.0/highlight.min.js"></script>
  </head>
  <body>
    <div class="main">
      <div class="main-content">
        <div class="site-header">
  <a href="https://jinyu-m.github.io">
  <img class="avatar" src="https://jinyu-m.github.io/images/avatar.png?v=1615445259424" alt="">
  </a>
  <h1 class="site-title">
    年少万兜鍪
  </h1>
  <p class="site-description">
    少年吔
尘世恰好，有诗有酒刚好吐槽
  </p>
  <div class="menu-container">
    
      
        <a href="/" class="menu">
          首页
        </a>
      
    
      
        <a href="/archives" class="menu">
          文章
        </a>
      
    
      
        <a href="/tags" class="menu">
          标签
        </a>
      
    
      
        <a href="/post/about" class="menu">
          关于
        </a>
      
    
  </div>
  <div class="social-container">
    
      
    
      
    
      
    
      
    
      
    
  </div>
</div>

        <div class="post-detail">
          <article class="post">
            <h2 class="post-title">
              Place Recognition/Loop Closure Detection
            </h2>
            <div class="post-info">
              <span>
                2020-12-25
              </span>
              <span>
                33 min read
              </span>
              
            </div>
            
            <div class="post-content-wrapper">
              <div class="post-content">
                <h1 id="写在前面">写在前面</h1>
<p>这篇日志是自己在回环检测领域看过的一些论文，有离线训练词典的，有增量式构建词典的，不一而足。就我个人感觉而言，回环检测目前的趋势还是增量式检测在SLAM中的应用，当前的SLAM系统大多还停留在离线训练词典的阶段，但是在我的实验中，我发现词典训练存在太多先验经验和trick，导致词典对应不同场景的适应性较差。因此如何高效地检索，如何构建泛化性较强的词典，如何解决回环检测中感知混淆问题，是这个领域尚待解决的课题。</p>
<hr>
<h1 id="总结">总结</h1>
<h2 id="iros-2009-online-visual-vocabulary-for-robot-navigation-and-mapping">[IROS 2009] <strong>Online Visual Vocabulary for Robot Navigation and Mapping</strong></h2>
<p>这篇论文提出了一个很完整的增量式构建词典树的方法，利用特征跟踪获得基本单元，自下而上构建词典树，词典树的根节点为视觉单词，叶节点为基本单元，词典树（视觉单词）的数量由一个目标函数优化得到，无需人工干预，很新颖。词典的更新构成采用了增量式地更新，利用一些方法避免了重复计算。使用LDA对特征进行降维。应用场景为水下场景的SfM算法。</p>
<h2 id="tro-2012-automatic-visual-bag-of-words-for-online-robot-navigation-and-mapping">[TRO 2012] <strong>Automatic Visual Bag-of-Words for Online Robot Navigation and Mapping</strong></h2>
<p>这篇论文是在[OVV IROS 2009]的基础上拓展的期刊论文，在这篇论文中，作者对于词典的更新间隔进行了改进，不再是每隔m张图像更新一次词典，而是通过判断特征与单词的关联率来判断词典是否需要更新。并且，对于具有较少信息的分支，词典进行了剪枝，使得结构更加紧凑。</p>
<hr>
<h1 id="目录">目录</h1>
<p><ul class="markdownIt-TOC">
<li><a href="#%E5%86%99%E5%9C%A8%E5%89%8D%E9%9D%A2">写在前面</a></li>
<li><a href="#%E6%80%BB%E7%BB%93">总结</a>
<ul>
<li><a href="#iros-2009-online-visual-vocabulary-for-robot-navigation-and-mapping">[IROS 2009] <strong>Online Visual Vocabulary for Robot Navigation and Mapping</strong></a></li>
<li><a href="#tro-2012-automatic-visual-bag-of-words-for-online-robot-navigation-and-mapping">[TRO 2012] <strong>Automatic Visual Bag-of-Words for Online Robot Navigation and Mapping</strong></a></li>
</ul>
</li>
<li><a href="#%E7%9B%AE%E5%BD%95">目录</a></li>
<li><a href="#online-visual-vocabulary-for-robot-navigation-and-mapping-iros-2019-pdf">Online Visual Vocabulary for Robot Navigation and Mapping (IROS 2019) pdf</a>
<ul>
<li><a href="#abstract">Abstract</a></li>
<li><a href="#introduction">Introduction</a></li>
<li><a href="#visual-vocabulary">Visual Vocabulary</a>
<ul>
<li><a href="#vocabulary-building">Vocabulary Building</a></li>
<li><a href="#cluster-characterization">Cluster Characterization</a></li>
<li><a href="#cluster-merging">Cluster Merging</a></li>
<li><a href="#convergence-criterion">Convergence criterion</a></li>
<li><a href="#vocabulary-update">Vocabulary update</a></li>
<li><a href="#linear-discriminant-analysis-lda">Linear Discriminant Analysis (LDA)</a></li>
</ul>
</li>
<li><a href="#image-indexing">Image Indexing</a>
<ul>
<li><a href="#cluster-association">Cluster association</a></li>
<li><a href="#image-re-indexing">Image re-indexing</a></li>
<li><a href="#image-similarity">Image similarity</a></li>
<li><a href="#cross-over-detection">Cross-over detection</a></li>
</ul>
</li>
<li><a href="#experimental-results">Experimental Results</a></li>
</ul>
</li>
<li><a href="#automatic-visual-bag-of-words-for-online-robot-navigation-and-mapping-tro-2012-pdf">Automatic Visual Bag-of-Words for Online Robot Navigation and Mapping (TRO 2012) pdf</a>
<ul>
<li><a href="#abstract-2">Abstract</a></li>
<li><a href="#introduction-2">Introduction</a></li>
<li><a href="#visual-vocabulary-2">Visual Vocabulary</a>
<ul>
<li><a href="#agglomerative-clustering">Agglomerative clustering</a></li>
<li><a href="#vocabulary-building-2">Vocabulary building</a></li>
<li><a href="#cluster-characterization-2">Cluster characterization</a>
<ul>
<li><a href="#cluster-updating">Cluster updating</a></li>
</ul>
</li>
<li><a href="#cluster-merging-criterion">Cluster merging criterion</a></li>
<li><a href="#convergence-criterion-2">Convergence Criterion</a></li>
<li><a href="#adding-new-clusters">Adding New Clusters</a></li>
<li><a href="#linear-disciminant-analysis">Linear Disciminant Analysis</a></li>
<li><a href="#vocabulary-update-criterion">Vocabulary Update Criterion</a></li>
</ul>
</li>
<li><a href="#image-indexing-2">Image Indexing</a>
<ul>
<li><a href="#cluster-association-2">Cluster Association</a>
<ul>
<li><a href="#image-reindexing">Image Reindexing</a></li>
</ul>
</li>
<li><a href="#image-similarity-2">Image similarity</a></li>
</ul>
</li>
<li><a href="#increasing-vocabulary-efficiency">Increasing Vocabulary Efficiency</a></li>
<li><a href="#experiments">Experiments</a></li>
</ul>
</li>
<li><a href="#dbow-tro-pdf">DBoW (TRO) pdf</a>
<ul>
<li><a href="#introduction-3"><em>Introduction</em></a></li>
<li><a href="#image-database"><em>Image Database</em></a></li>
<li><a href="#loop-detection-algorithm"><em>Loop Detection Algorithm</em></a>
<ul>
<li><a href="#database-query">Database query</a></li>
<li><a href="#match-grouping">Match grouping</a></li>
<li><a href="#temporal-consistency">Temporal consistency</a></li>
<li><a href="#efficient-geometrical-consistency">Efficient geometrical consistency</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#fast-and-effective-visual-place-recognition-using-binary-codes-and-disparity-information-iros-2014-pdf">Fast and Effective Visual Place Recognition using Binary Codes and Disparity Information (IROS 2014) pdf</a>
<ul>
<li><a href="#abstract-3"><strong>Abstract</strong></a></li>
<li><a href="#introduction-4"><strong>Introduction</strong></a></li>
<li><a href="#binary-descriptor"><strong>Binary Descriptor</strong></a>
<ul>
<li><a href="#proposed-method"><strong>Proposed Method</strong></a>
<ul>
<li><a href="#binary-code-calculation"><strong>Binary code calculation</strong></a></li>
<li><a href="#binary-codes-matching"><strong>Binary codes matching</strong></a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><a href="#calc-pdf-code">CALC pdf code</a>
<ul>
<li><a href="#abstract-4"><em>Abstract</em></a></li>
<li><a href="#method"><em>Method</em></a></li>
<li><a href="#performance"><em>Performance</em></a></li>
<li><a href="#%E4%B8%80%E7%82%B9%E7%9C%8B%E6%B3%95">一点看法</a></li>
</ul>
</li>
</ul>
</p>
<hr>
<h1 id="online-visual-vocabulary-for-robot-navigation-and-mapping-iros-2019-pdf">Online Visual Vocabulary for Robot Navigation and Mapping (IROS 2019) <a href="http://eia.udg.edu/~rafa/papers/iros-2009.pdf">pdf</a></h1>
<h2 id="abstract">Abstract</h2>
<p>受到content-based image retrieval算法的启发，回环检测算法使用visual vocabularies来度量图像间的相似度。但是这类算法有两个缺陷：（1）他们需要很强的人工干预，即通过trial-and-error的方法来训练和调试参数，（2）他们只适合批处理数据，即所有数据在处理前都是已经获得的（应该是指算法只在见过的场景中表现良好）。因此，作者提出了一个算法，在线构建和更新vocabularies，来高效地表示场景中的图像，并且词典构建过程不需要人工干预。</p>
<h2 id="introduction">Introduction</h2>
<p>在这篇论文中，作者提出了一个增量式构建视觉词典的框架。该算法不需要人工干预，不需要关于环境的先验信息。在导航过程中，当视觉信息输入到系统中，系统会构建一个简化的词典。该词典会进行更新，以正确地对场景中出现的视觉信息建模。该词典使用一种考虑视觉数据的全局分布的方法来构建，提升了效率。并且，作者提出了一种新的用于特征-聚类之间的联合方法和图像检索方法，适合在线的检测。<br>
提出的方法被应用在水下导航和建图的SFM算法中，视觉词典被用于量化帧间的相似度，从而进行回环检测。<br>
<img src="https://jinyu-m.github.io/post-images/1615277597694.png" alt="" loading="lazy"></p>
<h2 id="visual-vocabulary">Visual Vocabulary</h2>
<p>当前sota的算法都处于一个off-line的阶段，这一阶段需要实现从场景中获取视觉特征。这些特征然后通过某种聚类方法被用于构建视觉词典。典型的off-line词典构建方法使用K-means，K-medians或者fixed-radius clustering方法，这些方法需要使用者去设置许多参数，比如聚类簇数。为一个最优的词典找到合适的参数是一项繁琐的任务，需要不同的试错。比如，一个拥有过多单词的词典不会有足够的抽象能力来检测图像间的相似度，反之，一个单词太少的词典将受到混淆，单词过于泛化导致无法区分。</p>
<blockquote>
<p>the adequate parameters for an optimum vocabulary is a tedious task which generally involves a trial and error approach. For example, a vocabulary with too many words would not have enough abstraction power to detect similarities between images. In contrast, a vocabulary with too few words would be too confusing and generalized to be discriminant.</p>
</blockquote>
<p>作者提出了一种先进的视觉词典构建方法，它是可扩展的（scalable，因此适用于on-line检测）和自动的（automatic）。为此，作者使用了修改版的agglomerative clustering。agglomerative algorithm从将每个element作为独立的cluster（以下称之为elementary clusters）开始，然后利用某种相似度度量方法将它们合并为更大的clusters中，直到达到一些收敛条件（比如最小clusters数量，最大cluster半径等）。</p>
<h3 id="vocabulary-building">Vocabulary Building</h3>
<p>在本方法中，elementary clusters是通过对场景点的视觉跟踪产生的，一个elementary cluster对应着一个追踪的特征。视觉词典通过增量式地合并这些clusters。词典构建过程可以总结为两步：</p>
<ol>
<li>词典初始化阶段。词典由前m张图像中的elementary cluster初始化，这些cluster逐渐合并，直到收敛（合并的准则在后文中详细描述）；</li>
<li>词典更新阶段。当机器人移动，机器人获得了场景中的更多视觉信息，这些信需要包含到词典中。因此，对于每m张图像，新的elementary cluster被提取出来。这些cluster被加入到词典中，然后全部clusters逐渐合并，直到收敛。这一步每输入m张图像重复一次。<br>
<img src="https://jinyu-m.github.io/post-images/1615277763160.png" alt="" loading="lazy"></li>
</ol>
<h3 id="cluster-characterization">Cluster Characterization</h3>
<p>词典中每个cluster由它在N维空间中的位置和大小（半径）定义。这样提供了关于cluster分布和clusters间交互的完整信息。因为elementary cluster是由特征跟踪获得的，我们这样定义：<br>
<img src="https://jinyu-m.github.io/post-images/1615278043519.png" alt="" loading="lazy"><br>
其中，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>C</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">C_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.07153em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>是cluster的中心值，由图像<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.65952em;vertical-align:0em;"></span><span class="mord mathdefault">i</span></span></span></span>中场景点<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.03148em;">k</span></span></span></span>的平均特征向量给出。<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>R</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">R_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.00773em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>是点<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.03148em;">k</span></span></span></span>的协方差矩阵。</p>
<p>每次cluster合并是指两个cluster的合并（如图2）。新产生的cluster的参数直接从合并的clusters中获得，不需要重新从初始数据开始计算。这样做，节省了计算时间和内存消耗，尤其是在某些大的cluster中。新cluster的位置和大小由下式给出:<br>
<img src="https://jinyu-m.github.io/post-images/1615278465223.png" alt="" loading="lazy"><br>
其中，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>C</mi><mi>a</mi></msub></mrow><annotation encoding="application/x-tex">C_a</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.07153em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">a</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>和<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>C</mi><mi>b</mi></msub></mrow><annotation encoding="application/x-tex">C_b</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.07153em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">b</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>分别为要合并的两个cluster的中心值，这两个cluster分别有<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>n</mi><mi>a</mi></msub></mrow><annotation encoding="application/x-tex">n_a</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">n</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">a</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>和<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>n</mi><mi>b</mi></msub></mrow><annotation encoding="application/x-tex">n_b</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">n</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">b</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>个elements。</p>
<h3 id="cluster-merging">Cluster Merging</h3>
<p>一般的距离方法依赖于相似度度量方法，比如欧拉距离、曼哈顿距离、切比雪夫距离、马氏距离、向量夹角等，但是这些距离只是局部的分析了数据，所以在高维的聚类空间中是次优的。因此，作者提出一种新的距离方法，将数据的全局分布也考虑进来。该方法基于Fisher's linear disciminant，将数据聚类来最大化目标函数：<br>
<img src="https://jinyu-m.github.io/post-images/1615279001618.png" alt="" loading="lazy"><br>
其中<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>t</mi><mi>r</mi><mo>(</mo><mo>)</mo></mrow><annotation encoding="application/x-tex">tr()</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault">t</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mopen">(</span><span class="mclose">)</span></span></span></span>求得迹，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>S</mi><mi>B</mi></msub></mrow><annotation encoding="application/x-tex">S_B</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.05017em;">B</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>表示<strong>between clusters scatter matrix</strong>，而<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>S</mi><mi>W</mi></msub></mrow><annotation encoding="application/x-tex">S_W</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">W</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>表示<strong>within clusters scatter matrix</strong>，由下式求得<br>
<img src="https://jinyu-m.github.io/post-images/1615279185925.png" alt="" loading="lazy"><br>
其中C是所有数据的全局中心值。N表示所有element的数量，而<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>n</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">n_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">n</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>是cluster k中包含的element数量。<br>
实际上，合并过程可以描述为：</p>
<ol>
<li>对于每个cluster，我们用kd-tree的方法搜索欧式空间中的邻近cluster，作为合并的待选；</li>
<li>对于每对可能要进行合并的clusters，我们计算两个cluster合并后目标函数的值<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>Q</mi><mo mathvariant="normal">′</mo></msup></mrow><annotation encoding="application/x-tex">Q&#x27;</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.946332em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathdefault">Q</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.751892em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span></span></span></span>。如果目标函数的值增大，那么两个cluster被合并，同时<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>S</mi><mi>B</mi></msub><mo separator="true">,</mo><msub><mi>S</mi><mi>W</mi></msub></mrow><annotation encoding="application/x-tex">S_B,S_W</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8777699999999999em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.05017em;">B</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">W</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>随之更新。（实际上，在合并时，作者对于所有可能合并的cluster都计算了Q的增益，将其从高到低排序，然后按照这一顺序进行合并。这样做，合并过程就和分析cluster的顺序无关了。）<br>
每一个合并都会改变词典中数据的分布，需要重新计算<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>S</mi><mi>B</mi></msub></mrow><annotation encoding="application/x-tex">S_B</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.05017em;">B</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>和<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>S</mi><mi>W</mi></msub></mrow><annotation encoding="application/x-tex">S_W</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">W</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>。直接重新计算会非常耗时，我们提出了一种增量式的更新策略：<br>
<img src="https://jinyu-m.github.io/post-images/1615279929545.png" alt="" loading="lazy"></li>
</ol>
<h3 id="convergence-criterion">Convergence criterion</h3>
<p>上述合并过程将重复进行，逐渐合并clusters，直到没有可以让Q增加的合并。通过这种方法，本算法提供了一种自然的收敛标准，不需要任何人工参数。</p>
<h3 id="vocabulary-update">Vocabulary update</h3>
<p>在词典更新阶段，新的elementary clusters加入，包含新的视觉特征。对于每个新加入的elementary cluster <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>ζ</mi><mi>e</mi></msub></mrow><annotation encoding="application/x-tex">\zeta_e</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07378em;">ζ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.07378em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">e</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>S</mi><mi>B</mi></msub></mrow><annotation encoding="application/x-tex">S_B</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.05017em;">B</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>和<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>S</mi><mi>W</mi></msub></mrow><annotation encoding="application/x-tex">S_W</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">W</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>必须相应的更新。为了避免重复计算scatter matrix，作者提出了一种新的更新方法。<br>
更新<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>S</mi><mi>W</mi></msub></mrow><annotation encoding="application/x-tex">S_W</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">W</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>只涉及<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>ζ</mi><mi>e</mi></msub></mrow><annotation encoding="application/x-tex">\zeta_e</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07378em;">ζ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.07378em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">e</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>的covariance matrix<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>R</mi><mi>e</mi></msub></mrow><annotation encoding="application/x-tex">R_e</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.00773em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">e</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>，用element的数量<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>n</mi><mi>e</mi></msub></mrow><annotation encoding="application/x-tex">n_e</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">n</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">e</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>（每个elementary cluster中elements的数量是指特征跟踪中的帧数）加权：<br>
<img src="https://jinyu-m.github.io/post-images/1615280758589.png" alt="" loading="lazy"><br>
<strong>这里为什么不是<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><msup><mi>S</mi><mo mathvariant="normal">′</mo></msup><mi>W</mi></msub><mo>=</mo><mfrac><mrow><mi>N</mi><msub><mi>S</mi><mi>W</mi></msub><mo>+</mo><msub><mi>n</mi><mi>e</mi></msub><msub><mi>R</mi><mi>e</mi></msub></mrow><mrow><mi>N</mi><mo>+</mo><msub><mi>n</mi><mi>e</mi></msub></mrow></mfrac></mrow><annotation encoding="application/x-tex">{S&#x27;}_W=\frac{NS_W+n_eR_e}{N+n_e}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.901892em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord"><span class="mord"><span class="mord mathdefault" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.751892em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">W</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.3337359999999998em;vertical-align:-0.44509999999999994em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8886359999999999em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.10903em;">N</span><span class="mbin mtight">+</span><span class="mord mtight"><span class="mord mathdefault mtight">n</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.16454285714285719em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathdefault mtight">e</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.410305em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.10903em;">N</span><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3567071428571427em;margin-left:-0.05764em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">W</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.14329285714285717em;"><span></span></span></span></span></span></span><span class="mbin mtight">+</span><span class="mord mtight"><span class="mord mathdefault mtight">n</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.16454285714285719em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathdefault mtight">e</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.16454285714285719em;"><span style="top:-2.357em;margin-left:-0.00773em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathdefault mtight">e</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.44509999999999994em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span>呀，有点没看懂诶....</strong><br>
增加新的cluster会影响全局的数据中心<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>C</mi></mrow><annotation encoding="application/x-tex">C</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.07153em;">C</span></span></span></span>，新的中心值<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>C</mi><mo mathvariant="normal">′</mo></msup></mrow><annotation encoding="application/x-tex">C&#x27;</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.751892em;vertical-align:0em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.751892em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span></span></span></span>为：<br>
<img src="https://jinyu-m.github.io/post-images/1615281745215.png" alt="" loading="lazy"><br>
考虑到C的变化，那么<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>S</mi><mi>B</mi></msub></mrow><annotation encoding="application/x-tex">S_B</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.05017em;">B</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>应该更新为：<br>
<img src="https://jinyu-m.github.io/post-images/1615281792324.png" alt="" loading="lazy"><br>
其中，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>δ</mi><mi>C</mi></msub><mo>=</mo><msup><mi>C</mi><mo mathvariant="normal">′</mo></msup><mo>−</mo><mi>C</mi></mrow><annotation encoding="application/x-tex">\delta_C=C&#x27;-C</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03785em;">δ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03785em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.07153em;">C</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.835222em;vertical-align:-0.08333em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.751892em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.07153em;">C</span></span></span></span>，V是每个新加入的cluster与全局中心值之间差异的加权和。V可以增量式地获取：<br>
<img src="https://jinyu-m.github.io/post-images/1615281993246.png" alt="" loading="lazy"><br>
<strong>懵了，这些公式都没推导过...</strong></p>
<h3 id="linear-discriminant-analysis-lda">Linear Discriminant Analysis (LDA)</h3>
<p>对于视觉词典中包含的cluster信息，我们需要找到一种数据变换方法来是cluster的区分度最大，并且可以让我们减少数据的维度，来提升词典构建和图像检索的速度。因此，作者最大化以下LDA目标函数：<br>
<img src="https://jinyu-m.github.io/post-images/1615341122606.png" alt="" loading="lazy"><br>
其中，w是一个决定最大cluster分散度方向的向量。将最大化J(w)当做一个一般的特征值问题，我们得到一个特征向量对应着w的数据变换。选取G中对应着w中较大值的m列，我们可以将数据的维度降低到s维。<br>
<strong>为什么会降低到s维？不是m维</strong></p>
<h2 id="image-indexing">Image Indexing</h2>
<p>一般来说，有两个方面决定了视觉词典的有效性：</p>
<ol>
<li>相似的图像特征应当被对应到相同的cluster（可重复性）；</li>
<li>不相似的图像特征应该对应着不同的clusters（区分能力）。</li>
</ol>
<blockquote>
<p>Generally, there are two aspects that define the efficiency of a visual vocabulary: (i) similar image features should be associated with the same clusters (repetitiveness) and (ii) dissimilar image features have to be associated with different clusters (discriminative power).</p>
</blockquote>
<p>在on-line词典中，作者定义了第三种特性：stability。因为词典一直在更新，作者的目的是相似的特征应当在词典更新的不同阶段都对应着相同的cluster。</p>
<h3 id="cluster-association">Cluster association</h3>
<p>特征与视觉单词间的对应是通过比较每个特征与词典中所有cluster来获得的。特征被对应到最相似的cluster。大多数图像检索方法利用特征空间中的距离来计算特征和clusters之间的距离。这种方法适合在静态预训练好的词典中使用。<br>
<img src="https://jinyu-m.github.io/post-images/1615342470093.png" alt="" loading="lazy"><br>
如图3所示，传统的特征association方法是不适用于on-line词典的（<strong>很棒的关注点！</strong>）。因此，作者提出的feature-cluster association方法是基于树的。在前文的词典构建过程中，词典树被构建好，树的节点对应着clusters，而树的分支对应着cluster的合并层次。树的根节点对应着视觉单词，树的叶节点对应着elementary clusters（从图像中tracking得到的基本单元）。<br>
<img src="https://jinyu-m.github.io/post-images/1615342741631.png" alt="" loading="lazy"><br>
在feature-cluster association过程中，自顶向下遍历树，计算特征和node之间的欧式距离。为了加速，算法只访问与特征相近的分支，为此，作者计算特征和视觉单词之间的距离，并选取满足：<br>
<img src="https://jinyu-m.github.io/post-images/1615343028338.png" alt="" loading="lazy"><br>
的树，其中<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>D</mi><mo>(</mo><mi>f</mi><mo separator="true">,</mo><msub><mi>ζ</mi><mi>k</mi></msub><mo>)</mo></mrow><annotation encoding="application/x-tex">D(f,\zeta_k)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">D</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07378em;">ζ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.07378em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>是特征f与<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>ζ</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">\zeta_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07378em;">ζ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.07378em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>之间的距离，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>D</mi><mi>m</mi></msub></mrow><annotation encoding="application/x-tex">D_m</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">m</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>是特征f与视觉单词之间的最小距离，而<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>τ</mi></mrow><annotation encoding="application/x-tex">\tau</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.1132em;">τ</span></span></span></span>是一个大于1的预设常值。<br>
被选取的树将被并行访问，为了提升效率，算法使用了一个类似于式15的停止准则，不需要访问离f较远的分支。特征最后被关联到最相似的叶节点对应的视觉单词上。（就是自顶向下查找，找到最相似的叶节点，这一颗树的根节点，即视觉单词，被关联到特征）</p>
<h3 id="image-re-indexing">Image re-indexing</h3>
<p>在更新阶段，词典的设置被改变了。因此，无法计算在不同更新阶段索引的图像之间的相似性，而且在每次词典更新后对图像进行索引不是一个可行的解决方案，因为它的计算成本很大。<br>
作者为此提出了一个转换<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mrow></mrow><mi>p</mi></msup><msub><mi>T</mi><mrow><mi>p</mi><mo>−</mo><mn>1</mn></mrow></msub></mrow><annotation encoding="application/x-tex">{}^pT_{p-1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.969438em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord"></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.664392em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">p</span></span></span></span></span></span></span></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.301108em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">p</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span>来体现更新阶段词典的变化。这个转换可以实现对image re-indexing，而不需要重新进行image indexing：<br>
<img src="https://jinyu-m.github.io/post-images/1615343875714.png" alt="" loading="lazy"><br>
其中<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msubsup><mi>H</mi><mi>I</mi><mrow><mi>p</mi><mo>−</mo><mn>1</mn></mrow></msubsup></mrow><annotation encoding="application/x-tex">H^{p-1}_{I}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.225547em;vertical-align:-0.293531em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.08125em;">H</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.932016em;"><span style="top:-2.4064690000000004em;margin-left:-0.08125em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.07847em;">I</span></span></span></span><span style="top:-3.1809080000000005em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">p</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.293531em;"><span></span></span></span></span></span></span></span></span></span>是图像I在p-1词典更新阶段时的检索，而<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mover accent="true"><msubsup><mi>H</mi><mi>I</mi><mi>p</mi></msubsup><mo stretchy="true">‾</mo></mover></mrow><annotation encoding="application/x-tex">\overline{H^{p}_{I}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.2758310000000002em;vertical-align:-0.293531em;"></span><span class="mord overline"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9823000000000001em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathdefault" style="margin-right:0.08125em;">H</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7823em;"><span style="top:-2.4064690000000004em;margin-left:-0.08125em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.07847em;">I</span></span></span></span><span style="top:-3.1809080000000005em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">p</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.293531em;"><span></span></span></span></span></span></span></span></span><span style="top:-3.9023em;"><span class="pstrut" style="height:3em;"></span><span class="overline-line" style="border-bottom-width:0.04em;"></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.293531em;"><span></span></span></span></span></span></span></span></span>是图像I在p-1词典更新阶段时的近似检索。<br>
在更新阶段，词典经历了以下改变：</p>
<ol>
<li>添加elementary clusters。如果新的cluster没有被其他已存在的clusters吸收，它们将包含新的视觉信息。在这种情况下，任何图像的特征在更新之前都不太可能与它们相关联。因此，这部分<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mover accent="true"><msubsup><mi>H</mi><mi>I</mi><mi>k</mi></msubsup><mo stretchy="true">‾</mo></mover></mrow><annotation encoding="application/x-tex">\overline{H^{k}_{I}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.324439em;vertical-align:-0.29353099999999993em;"></span><span class="mord overline"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.030908em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathdefault" style="margin-right:0.08125em;">H</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.830908em;"><span style="top:-2.4064690000000004em;margin-left:-0.08125em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.07847em;">I</span></span></span></span><span style="top:-3.0448000000000004em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.29353099999999993em;"><span></span></span></span></span></span></span></span></span><span style="top:-3.950908em;"><span class="pstrut" style="height:3em;"></span><span class="overline-line" style="border-bottom-width:0.04em;"></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.29353099999999993em;"><span></span></span></span></span></span></span></span></span>被初始化为0；</li>
<li>cluster合并。在这种情况下，两个或多个clusters合并，所有之前关联到这些cluster的特征将被关联到新合成的cluster上。因此，与新cluster关联的出现elements数是正在合并的clusters的elements数之和。<br>
为了反映这些变化，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mrow></mrow><mi>p</mi></msup><msub><mi>T</mi><mrow><mi>p</mi><mo>−</mo><mn>1</mn></mrow></msub></mrow><annotation encoding="application/x-tex">{}^pT_{p-1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.969438em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord"></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.664392em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">p</span></span></span></span></span></span></span></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.301108em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">p</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span>需要初始化对应着新添加的cluster的直方图元素，求和对应着合并的clusters的元素。举个例子：<br>
<img src="https://jinyu-m.github.io/post-images/1615345181242.png" alt="" loading="lazy"></li>
</ol>
<h3 id="image-similarity">Image similarity</h3>
<p><img src="https://jinyu-m.github.io/post-images/1615345809486.png" alt="" loading="lazy"><br>
作者还使用了TF-IDF权重。</p>
<h3 id="cross-over-detection">Cross-over detection</h3>
<figure data-type="image" tabindex="1"><img src="https://jinyu-m.github.io/post-images/1615346135592.png" alt="" loading="lazy"></figure>
<h2 id="experimental-results">Experimental Results</h2>
<p>该回环检测算法被应用在一个SfM算法（T. Nicosevici and R. Garcia. Online Robust 3D Mapping Using Structure from Motion Cues. In MTS/IEEE OCEANS Conference, pages 1–7, 2008.）中。SfM算法应用SIFT、SURF、MSER、Harris等特征进行特征跟踪。</p>
<p>第一个实验在实验室中进行，使用了一个包含书、箱子和杂志的相对平坦的场景。场景的视觉组成是<br>
复杂的，结合了无纹理区域、自然场景、几何图像和抽象的画。测试集包含215张640x480的图像，利用Canon G9 compact camera采集。算法利用SURF提取特征，特征描述子为64维，反映了特征附近的Haar小波响应。词典用前20张图像进行初始化，然后每10张图像更新一次。<br>
<img src="https://jinyu-m.github.io/post-images/1615346729684.png" alt="" loading="lazy"><br>
<img src="https://jinyu-m.github.io/post-images/1615346752503.png" alt="" loading="lazy"><br>
在序列的末端，词典的规模增长速度逐渐变慢。<br>
<img src="https://jinyu-m.github.io/post-images/1615346927451.png" alt="" loading="lazy"><br>
作者采用了一个直接的data association方法，来测试数据聚类的质量和所提出索引方法的效率。对于每个图像特征，我们直接将其与欧式距离小的elementary cluster相关联。然后，利用词典树检索该图像特征，如果该特征最后检索到了与相关联的elementary cluster对应的叶节点，被认为是一次“命中”，否则是一次“错失”。作者测试了不同LDA维度缩减和<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>τ</mi></mrow><annotation encoding="application/x-tex">\tau</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.1132em;">τ</span></span></span></span>值，最后得到，当LDA将特征维度从64降到24，并且<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>τ</mi><mo>=</mo><mn>1.4</mn></mrow><annotation encoding="application/x-tex">\tau=1.4</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.1132em;">τ</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span><span class="mord">.</span><span class="mord">4</span></span></span></span>时，错失率为0.96%。这一参数设置可以很好地减少计算耗时，同时很好的保留词典的能力。在这个序列上，词典更新的平均时间为每次更新1.36秒，图像检索的平均时间为每帧0.23秒。<br>
<img src="https://jinyu-m.github.io/post-images/1615347676267.png" alt="" loading="lazy"><br>
回环检测的结果使用similarity matrix给出的.</p>
<p>第二个实验是在水下数据集进行的，该数据集包含235张720x530的图像。回环检测结果依然由similarity matrix给出。（好像早期的研究偏向于similarity matrix做直观的显示，没有p-r曲线和p@r=1这样的指标）<br>
<img src="https://jinyu-m.github.io/post-images/1615347862825.png" alt="" loading="lazy"></p>
<hr>
<h1 id="automatic-visual-bag-of-words-for-online-robot-navigation-and-mapping-tro-2012-pdf">Automatic Visual Bag-of-Words for Online Robot Navigation and Mapping (TRO 2012) <a href="https://doi.org/10.1109/TRO.2012.2192013">pdf</a></h1>
<p>本文是Online Visual Vocabulary for Robot Navigation and Mapping (IROS 2009)论文的期刊版。</p>
<h2 id="abstract-2">Abstract</h2>
<blockquote>
<p>Detecting already-visited regions based on their visual appearance helps reduce drift and position uncertainties in robot navigation and mapping. Inspired from content-based image retrieval, an efficient approach is the use of visual vocabularies to measure similarities between images. This way, images corresponding to the same scene region can be associated.  <strong>State-of-the-art proposals that address this topic use prebuilt vocabularies that generally require a priori knowledge of the environment</strong>. We propose a novel method for appearance-based navigation and mapping where the visual vocabularies are built online, thus eliminating the need for prebuilt data. We also show that the proposed technique allows efficient loop-closure detection, even at small vocabulary sizes, resulting in a higher computational efficiency.</p>
</blockquote>
<p>SLAM系统一般会将回环检测任务当作一个2D-2D的图像检索任务来完成，bag-of-word模型是一个高效的解决方案，但是现存SOTA的算法是现在一个训练集上训练一个pre-built vocabulary，这里就需要用到人类对于环境的先验认知（比如室内还是室外，词典的规模等）。这篇论文提出了一种在线训练词典的方法，所以无需训练数据集。实验结果证明了提出的算法即使使用一个比较小的词典，也可以达到不错的回环检测效果，计算效率非常高。</p>
<h2 id="introduction-2">Introduction</h2>
<p>传统BoW的算法流程大致分为两部分：1.离线部分，从训练集中提取特征完成聚类，构建视觉词典，特征的聚类被当作描述图像的视觉单词；2.在线部分，提取当前图像的特征，量化到视觉单词上，用视觉单词的直方图向量来描述图像，完成图像相似度的计算。</p>
<blockquote>
<p>BoW image representation employs two stages: 1) In the training stage, sets of visual features are grouped or clustered together to generate visual vocabularies, i.e., collections of generalized visual features or visual words; 2) in the second stage, the images are represented as histograms of visual word occurrences.</p>
</blockquote>
<p>当前BoW模型的缺点之一就是使用了静态的pre-built vocabulary，需要先验的知识，但是在复杂、大型的场景中，这一定是不合理的（我们的试验也证明了这一点，室内场景构建的词典在室外检测效果不好，室外训练的词典在室内效果不好）。<br>
作者提出了一种无需先验和人工设计参数的增量式词典训练方法，online visual vocabulary(OVV)。另外，作者也设计了一种新的聚类方法，用一种新的、考虑到整个聚类分布的聚类收敛标准。<br>
<img src="https://jinyu-m.github.io/post-images/1610877239498.png" alt="" loading="lazy"></p>
<h2 id="visual-vocabulary-2">Visual Vocabulary</h2>
<blockquote>
<p>Finding the adequate parameters for an optimum vocabulary is a tedious task which generally involves a trial-and-error approach. For instance, a vocabulary with too many words would not have enough abstraction power to detect similarities between images. In contrast, a vocabulary with too few words would be too confusing and generalized to be discriminative.</p>
</blockquote>
<p>作者先提出了static pre-built vocabulary的一个弊端，就是词典的规模完全由人工反复实验获得，耗时且不一定最优。而且对于词典树来说，当词典的规模过大，特征的鲁棒性下降了，对于视觉的干扰过于敏感；反之，当词典的规模过小，特征的disciminativeness下降，特征容易误匹配。<br>
作者因此提出了一种增量式的视觉词典训练方法，为了实现这一点，作者采用一种修改后的聚类方法（Agglomerative clustering）.</p>
<h3 id="agglomerative-clustering">Agglomerative clustering</h3>
<p>该聚类方法是一种自底向上的层次聚类方法，过程如：</p>
<ol>
<li>先将每个元素单独定为一类（elementary clusters）；</li>
<li>合并指定距离最小的类；</li>
<li>重复（2）直到所有元素都归为同一类。</li>
</ol>
<h3 id="vocabulary-building-2">Vocabulary building</h3>
<p>在这篇论文中，首先跟踪图像中的特征点，用这些跟踪到的点作为elementary clusters，减少了用于构建词典树的特征数量。词典树通过增量式的合并这些clusters来构建，构建过程可以总结为两点：</p>
<ol>
<li>初始化：词典先用前m张图像提取到的tracked features去初始化一个词典，然后由底向上构建词典树；</li>
<li>更新：我理解的是，OVV用了一种滑动窗的概念，每m张图像中提取出的elementary clusters都被加入到词典树中，然后整个词典树继续由底向上完成构建。这样，新出现的场景中的特征也会被更新到词典树中。</li>
</ol>
<h3 id="cluster-characterization-2">Cluster characterization</h3>
<p>每个cluster具有两个属性，聚类中心值<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>C</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">C_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.07153em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>，和协方差矩阵<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>R</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">R_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.00773em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>。<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>C</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">C_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.07153em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>反映了cluster在整个t为特征空间中的分布，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>R</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">R_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.00773em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>反映了cluster内被合并的子cluster之间的关系。<br>
<img src="https://jinyu-m.github.io/post-images/1610877261587.png" alt="" loading="lazy"></p>
<h4 id="cluster-updating">Cluster updating</h4>
<p>每个聚类都是通过合并两个聚类来获得的，所以新的聚类属性可以根据原本的两个聚类的属性来获得。<br>
<img src="https://jinyu-m.github.io/post-images/1610877270139.png" alt="" loading="lazy"><br>
这样可以节省运算的消耗。</p>
<h3 id="cluster-merging-criterion">Cluster merging criterion</h3>
<p>作者认为原本在Agglomerative clustering度量距离的方法是局部最优的，没有考虑到特征的全局分布。所以作者提出了新的聚类方法，在聚类时，同时增加各类之间的间距和类内的compactness。这一点至关重要，因为视觉词典的有效性由两个方面决定：1) repetitiveness，即相似的图像特征应当被关联到相同的cluster，2) discriminative power，即不想似的图像特征应当被关联到不同的cluster上。新的聚类方法基于Fisher’s linear discriminant。先计算了两个矩阵：<br>
<img src="https://jinyu-m.github.io/post-images/1610877281134.png" alt="" loading="lazy"><br>
其中C是所有数据的中心值，N表示所有数据的数量，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>n</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">n_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">n</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>表示在第k个cluster中包含数据的数量。<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>S</mi><mi>B</mi></msub></mrow><annotation encoding="application/x-tex">S_B</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.05017em;">B</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>代表了between clusters scatter matrix，我理解的是体现了类与类之间的分散程度（类间距离），这个值越大越好；<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>S</mi><mi>W</mi></msub></mrow><annotation encoding="application/x-tex">S_W</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">W</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>代表了within clusters scatter matrix，是体现了类内数据的分散程度（类内紧密度），这个值越小越好。然后用<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>S</mi><mi>B</mi></msub></mrow><annotation encoding="application/x-tex">S_B</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.05017em;">B</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>和<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>S</mi><mi>W</mi></msub></mrow><annotation encoding="application/x-tex">S_W</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">W</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>的迹的比值作为目标函数，在聚类时应使目标函数尽可能大:<br>
<img src="https://jinyu-m.github.io/post-images/1610877295645.png" alt="" loading="lazy"><br>
实际上，合并分两步进行：</p>
<ol>
<li>对于每个cluster，利用kd-tree在它的领域内（欧拉空间中）搜索可能合并的candidate；</li>
<li>对于每个candidate，计算合并前后的Q，如果Q有提升，那么将两个cluster合并，并且更新相应的<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>S</mi><mi>B</mi></msub></mrow><annotation encoding="application/x-tex">S_B</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.05017em;">B</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>和<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>S</mi><mi>W</mi></msub></mrow><annotation encoding="application/x-tex">S_W</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">W</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>。<br>
由于每次合并都会引起<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>S</mi><mi>B</mi></msub></mrow><annotation encoding="application/x-tex">S_B</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.05017em;">B</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>和<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>S</mi><mi>W</mi></msub></mrow><annotation encoding="application/x-tex">S_W</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">W</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>的更新，所需的计算量较大。所以作者提出一种增量式的更新方案：<br>
<img src="https://jinyu-m.github.io/post-images/1610877301528.png" alt="" loading="lazy"></li>
</ol>
<h3 id="convergence-criterion-2">Convergence Criterion</h3>
<p>在算法中，重复上一节的合并过程，直到Q值无法提升。此时，词典的repetitiveness和disciminative power都达到了最大。这样的收敛标准无需人工干预。</p>
<h3 id="adding-new-clusters">Adding New Clusters</h3>
<p>在词典更新阶段，新的elementary cluster被加入。对于每个新加入的elementary cluster <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>ζ</mi><mi>e</mi></msub></mrow><annotation encoding="application/x-tex">\zeta_e</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07378em;">ζ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.07378em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">e</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>S</mi><mi>B</mi></msub></mrow><annotation encoding="application/x-tex">S_B</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.05017em;">B</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>和<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>S</mi><mi>W</mi></msub></mrow><annotation encoding="application/x-tex">S_W</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">W</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>要相应的更新，为了减少更新时的计算量，作者使用增量式更新的方法，和之前iros会议版本的方法一样。</p>
<h3 id="linear-disciminant-analysis">Linear Disciminant Analysis</h3>
<p>与之前iros会议版本的方法一样。</p>
<h3 id="vocabulary-update-criterion">Vocabulary Update Criterion</h3>
<p>在实际操作中，词典不是间隔固定时间更新一次的，而是自适应的更新。在图像检索过程中，特征被关联到词典中的clusters上。对于每个特征<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>f</mi><mi>l</mi></msub></mrow><annotation encoding="application/x-tex">f_l</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.10764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>和cluster <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>ζ</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">\zeta_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07378em;">ζ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.07378em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>之间的关联，我们检查特征是否当特征是否属于该cluster：<br>
<img src="https://jinyu-m.github.io/post-images/1610877346064.png" alt="" loading="lazy"><br>
其中，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>δ</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">\delta_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03785em;">δ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.03785em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>为cluster <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>ζ</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">\zeta_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07378em;">ζ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.07378em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>的标准方差，| |表示每个维度上的绝对值比较。即特征的每个维度都符合式15的条件时，我们认为该特征属于该cluster。在每一个特征更新阶段，当特征落入cluster的比率小于90%，则更新词典。（<strong>相对会议论文的改进</strong>）</p>
<h2 id="image-indexing-2">Image Indexing</h2>
<h3 id="cluster-association-2">Cluster Association</h3>
<p>与之前iros会议版本的方法一样。</p>
<h4 id="image-reindexing">Image Reindexing</h4>
<p>与之前iros会议版本的方法一样。</p>
<h3 id="image-similarity-2">Image similarity</h3>
<p>与之前iros会议版本的方法一样。</p>
<h2 id="increasing-vocabulary-efficiency">Increasing Vocabulary Efficiency</h2>
<p>在导航和建图过程中，新的视觉特征被加入，OVV的规模会一直增大。作者在词典构建和图像检索过程中使用了approximate nearest neighbor techniques来提高效率。同时，为了进一步提升OVV的计算效率，作者对包含较少信息的节点进行了剪枝。当<br>
<img src="https://jinyu-m.github.io/post-images/1610877509249.png" alt="" loading="lazy"><br>
时，进行剪枝。其中<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msubsup><mi>R</mi><mi>k</mi><mi>i</mi></msubsup></mrow><annotation encoding="application/x-tex">R^{i}_{k}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.1077719999999998em;vertical-align:-0.2831079999999999em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.824664em;"><span style="top:-2.4168920000000003em;margin-left:-0.00773em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2831079999999999em;"><span></span></span></span></span></span></span></span></span></span>是cluster <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>ζ</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">\zeta_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07378em;">ζ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.07378em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>中节点i的半径，p是一个预设标量。在实验中，作者发现p=0.1效果最好。（<strong>没太懂这里的意义，R不是elementary cluster的协方差矩阵么</strong>）</p>
<h2 id="experiments">Experiments</h2>
<p><img src="https://jinyu-m.github.io/post-images/1610877518916.png" alt="" loading="lazy"><br>
OVV的词典会随着环境的增大而逐渐增大。<br>
<img src="https://jinyu-m.github.io/post-images/1615435162513.png" alt="" loading="lazy"><br>
可以看到，图像检索的时间基本稳定，没有随着环境规模变大而增长。词典更新的频率也逐渐降低。<br>
<img src="https://jinyu-m.github.io/post-images/1610877528466.png" alt="" loading="lazy"><br>
作者比较了incremental indexing和full indexing的表现（对应着image reindexing节），说明增量式的方法在大幅度减少计算消耗的同时，还保持了不错的表现。</p>
<hr>
<h1 id="dbow-tro-pdf">DBoW (TRO) <a href="https://doi.org/10.1109/TRO.2012.2197158">pdf</a></h1>
<h2 id="introduction-3"><em>Introduction</em></h2>
<p>贡献点可以总结为几点：<br>
1.使用了一种改进的FAST+BEIFF二进制特征；<br>
2.把邻近图像联系起来，组成island，防止过于靠近的图像被匹配到（算是一种temporal constrant）；<br>
3.在词典树中加入inverse index来实现快速的图像检索，加入direct index来保留图像间的correspondence，加快geometrical check的速度。</p>
<h2 id="image-database"><em>Image Database</em></h2>
<p>由于作者使用二进制描述子，所以构建了二进制词典树，使用K-means++ seeding初始化K-means的初始medians，medians中非二进制值得被置为0。<br>
计算两个BoW向量得相似度时使用了L1分数：<br>
<img src="https://jinyu-m.github.io/post-images/1610877562404.png" alt="" loading="lazy"></p>
<p>在词典树中，作者使用了inverse index table来保留该单词出现过的图像索引值。当一张新的图像加入database，inverse index table会随之更新。<br>
作者来使用了direct index table，对于每张图像，作者在direct index table中储存了该图像出现过的单词所属的位于l层的节点，以及该节点包含的局部特征。此结构可以用于在获得candidate loop时，准备进行geometrical check时计算同属于一个word或者同属于一个节点的特征的correspondence。</p>
<h2 id="loop-detection-algorithm"><em>Loop Detection Algorithm</em></h2>
<h3 id="database-query">Database query</h3>
<p>对于每个query图像，利用词典树，搜索到一系列匹配的candidates以及对应的分数，由于这些分数受query image和它其中的单词分布影响，所以作者对分数进行了归一化：<br>
<img src="https://jinyu-m.github.io/post-images/1610877572685.png" alt="" loading="lazy"></p>
<h3 id="match-grouping">Match grouping</h3>
<p>为了避免相邻的图像被匹配，作者将相邻图像构成了island，将其视为一个匹配。如果query匹配到的candidate的时间戳之间差距很小，那么就将这些candidate视为一个island，其匹配分数为：<br>
<img src="https://jinyu-m.github.io/post-images/1610877580156.png" alt="" loading="lazy"></p>
<p>具有最高匹配分数的island被挑选出来作为matching group，进入下一步的验证。</p>
<h3 id="temporal-consistency">Temporal consistency</h3>
<p>当获得最好的matching island后，对其进行时间一致性的检验，即其之前的k个query也必须被匹配到，当其通过检验后，挑选island中具有最高匹配分数的一个image作为当前query的匹配。</p>
<h3 id="efficient-geometrical-consistency">Efficient geometrical consistency</h3>
<p>作者的几何检验思路是计算匹配图像对的F矩阵，利用RANSAC，至少需要有12个匹配点对。为了加快特征匹配，作者用direct index去粗略搜索。</p>
<hr>
<h1 id="fast-and-effective-visual-place-recognition-using-binary-codes-and-disparity-information-iros-2014-pdf">Fast and Effective Visual Place Recognition using Binary Codes and Disparity Information (IROS 2014) <a href="https://www.researchgate.net/publication/263298223">pdf</a></h1>
<h2 id="abstract-3"><strong>Abstract</strong></h2>
<p>这篇工作提出了一个基于二进制code和视差信息的双目场景识别算法。算法（ABLE-S）在全局框架中使用Local Difference Binary（LDB）描述子来获得鲁棒的全局图像描述，该描述是基于图像像素对间亮度和梯度之间差异的。LDB相比其他描述子，如仅依赖于图像亮度的BRIEF，有更好的描述能力。除此之外，作者还讲视差信息加入了二进制描述子（D-LDB）。视差可以提供一些有用的信息，来解决场景识别中常见的问题，如perceptual aliasing。<br>
论文用KITTI数据集测试算法。并且，作者提供了一个回环的真值，以方便回环检测算法表现的比较。</p>
<h2 id="introduction-4"><strong>Introduction</strong></h2>
<p>作者提出FAB-MAP有一些缺陷，即需要事先训练环境的视觉词典和相关联的概率方法，使得算法无法适应实时的应用。<br>
在这篇论文中，作者提出了一个用于视觉回环检测和场景识别的算法，该算法使用基于像素对的亮度、梯度和视差比较的全局二进制描述子，如图1所示。作者将视差信息加入了LDB，得到了D-LDB。在实验中，作者证明了视差的加入提供了更准确的视觉定位，减少了视觉场景识别中的常见问题，如perceptual aliasing。最后的实验证明，ABLE-S算法获得了超过FAB-MAP、WI-SURF、BRIEF-Gist的表现，并且计算消耗更低。<br>
<img src="https://jinyu-m.github.io/post-images/1610877655376.png" alt="" loading="lazy"></p>
<h2 id="binary-descriptor"><strong>Binary Descriptor</strong></h2>
<p>二进制描述子最好的性质为可以用hamming距离进行高效的匹配。假设一个平滑后的图像块p，其中心为关键点(x,y)，那么二进制检测可以定义为：<br>
<img src="https://jinyu-m.github.io/post-images/1610877660015.png" alt="" loading="lazy"><br>
其中，f(i)是一个函数，返回p中特定pixel或cell的图像特征响应。f(i)可以采用如BRIEF、ORB和BRISK中二进制描述子一样的平滑后的图像灰度值。除此之外，f(i)也可以是如LDB和M-LDB中不同二进制比较结构的串联，比如平均图像灰度、p中特定cell的图像梯度Gx和Gy。<br>
<img src="https://jinyu-m.github.io/post-images/1610877671571.png" alt="" loading="lazy"></p>
<p>为了减少场景识别问题中perceptual aliasing等问题的干扰，作者拓展了LDB，加入了平均视差Davg的二进制比较结构：<br>
<img src="https://jinyu-m.github.io/post-images/1610877681169.png" alt="" loading="lazy"></p>
<p>最后，合成的描述子<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>d</mi><mi>n</mi></msub><mo>(</mo><mi>p</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">d_n(p)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathdefault">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathdefault">p</span><span class="mclose">)</span></span></span></span>为一个n次二进制检测的向量，n是描述子的维度，通常被矫正为：<br>
<img src="https://jinyu-m.github.io/post-images/1610877692854.png" alt="" loading="lazy"></p>
<h3 id="proposed-method"><strong>Proposed Method</strong></h3>
<h4 id="binary-code-calculation"><strong>Binary code calculation</strong></h4>
<p>在本文中，作者采用了LDB，因为LDB相对BRIEF加入了梯度信息。作者还加入了视差信息，得到D-LDB。视差是通过SGBM(Semi Global Block Matching)获得的。</p>
<p>作者将图像块的大小定义为64x64，在提取全局二进制描述子之前将图像缩放到这一尺寸。更小的图像块会削弱场景识别算法的有效性，更大的分辨率也没有得到更好的表现。另外，作者将二进制描述子的维度定义为256比特。描述子通过LDB的随机比特挑选方法来满足维度要求。</p>
<p>该全局描述子将缩放后图像块的中心作为关键点，来进行计算，没有显性的旋转和缩放。然而，可以采用其他替代方法，将图像划分为多个grids，将每个grid的中心视为关键点，然后计算每个grid的二进制描述子，拼接到一起得到最后的二进制code。这一方法可以考虑采用不同宽和高的grid(<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>g</mi><mi>w</mi></msub><mo>×</mo><msub><mi>g</mi><mi>h</mi></msub></mrow><annotation encoding="application/x-tex">g_w \times g_h</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7777700000000001em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.02691em;">w</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">h</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>)。</p>
<h4 id="binary-codes-matching"><strong>Binary codes matching</strong></h4>
<p>对要分析的m个场景，提取二进制描述子，构成向量v。计算二进制描述子之间的hamming距离，得到距离矩阵M</p>
<hr>
<h1 id="calc-pdf-code">CALC <a href="https://arxiv.org/abs/1805.07703.pdf">pdf</a> <a href="https://github.com/rpng/calc">code</a></h1>
<h2 id="abstract-4"><em>Abstract</em></h2>
<p>这篇论文提出了一种无监督的神经网络，采用autoencoder的结构，但是重建的不是原始图像，而是图像的HoG描述子。</p>
<h2 id="method"><em>Method</em></h2>
<p>这篇论文作者设计了一个可以将高维的原始图像信息映射到低维特征空间的网络，对场景变化不敏感，训练方法不需要标注图像。<br>
训练pipeline如下：<br>
<img src="https://jinyu-m.github.io/post-images/1610854867832.png" alt="" loading="lazy"></p>
<p>训练集中的每张图像被缩小到120x160，灰度图。通过projective transformations获得匹配图像。<br>
HOG特征对网络提供了一个先验的几何约束，网络可以获得光照不变性，通过projective transformations来获得HOG所不具备的视角不变性。<br>
获得训练的方法-projective transformations过程如下：<br>
<img src="https://jinyu-m.github.io/post-images/1610854876928.png" alt="" loading="lazy"></p>
<p>这个过程的目的是：根据一张真实图像I，通过随机的2D projective transformation获得一系列描述同场景、但视角不同的图像。<br>
对于每张图像，从其四角的某一区域内各随机选一个点，作为生成图像的四个角点，获得四个点后，就可以获得从原图到生成图像的homograph，矫正之后就生成了新图像。<br>
<img src="https://jinyu-m.github.io/post-images/1610854884737.png" alt="" loading="lazy"></p>
<h2 id="performance"><em>Performance</em></h2>
<p><img src="https://jinyu-m.github.io/post-images/1610854891056.png" alt="" loading="lazy"><br>
<img src="https://jinyu-m.github.io/post-images/1610854894727.png" alt="" loading="lazy"><br>
<img src="https://jinyu-m.github.io/post-images/1610854897698.png" alt="" loading="lazy"><br>
<img src="https://jinyu-m.github.io/post-images/1610854900621.png" alt="" loading="lazy"></p>
<h2 id="一点看法">一点看法</h2>
<p>这篇工作虽然说是无监督，但是其实用了HoG描述子去监督训练网络，算是自己制作了伪真值去训练网络，最后得到的网络效果超过了HoG，证明了数据集如果够丰富，神经网络的泛化能力还是很强的。有点像MagicPoint和SuperPoint的detector，虽然最初的annotated label是人工设置的角点，但是最后训练得到的网络却具备更泛化的能力。论文中projective transformation用于拓展数据集，让网络学习（小）视角不变性，简单有效，值得参考。</p>

              </div>
              <div class="toc-container">
                <ul class="markdownIt-TOC">
<li><a href="#%E5%86%99%E5%9C%A8%E5%89%8D%E9%9D%A2">写在前面</a></li>
<li><a href="#%E6%80%BB%E7%BB%93">总结</a>
<ul>
<li><a href="#iros-2009-online-visual-vocabulary-for-robot-navigation-and-mapping">[IROS 2009] <strong>Online Visual Vocabulary for Robot Navigation and Mapping</strong></a></li>
<li><a href="#tro-2012-automatic-visual-bag-of-words-for-online-robot-navigation-and-mapping">[TRO 2012] <strong>Automatic Visual Bag-of-Words for Online Robot Navigation and Mapping</strong></a></li>
</ul>
</li>
<li><a href="#%E7%9B%AE%E5%BD%95">目录</a></li>
<li><a href="#online-visual-vocabulary-for-robot-navigation-and-mapping-iros-2019-pdf">Online Visual Vocabulary for Robot Navigation and Mapping (IROS 2019) pdf</a>
<ul>
<li><a href="#abstract">Abstract</a></li>
<li><a href="#introduction">Introduction</a></li>
<li><a href="#visual-vocabulary">Visual Vocabulary</a>
<ul>
<li><a href="#vocabulary-building">Vocabulary Building</a></li>
<li><a href="#cluster-characterization">Cluster Characterization</a></li>
<li><a href="#cluster-merging">Cluster Merging</a></li>
<li><a href="#convergence-criterion">Convergence criterion</a></li>
<li><a href="#vocabulary-update">Vocabulary update</a></li>
<li><a href="#linear-discriminant-analysis-lda">Linear Discriminant Analysis (LDA)</a></li>
</ul>
</li>
<li><a href="#image-indexing">Image Indexing</a>
<ul>
<li><a href="#cluster-association">Cluster association</a></li>
<li><a href="#image-re-indexing">Image re-indexing</a></li>
<li><a href="#image-similarity">Image similarity</a></li>
<li><a href="#cross-over-detection">Cross-over detection</a></li>
</ul>
</li>
<li><a href="#experimental-results">Experimental Results</a></li>
</ul>
</li>
<li><a href="#automatic-visual-bag-of-words-for-online-robot-navigation-and-mapping-tro-2012-pdf">Automatic Visual Bag-of-Words for Online Robot Navigation and Mapping (TRO 2012) pdf</a>
<ul>
<li><a href="#abstract-2">Abstract</a></li>
<li><a href="#introduction-2">Introduction</a></li>
<li><a href="#visual-vocabulary-2">Visual Vocabulary</a>
<ul>
<li><a href="#agglomerative-clustering">Agglomerative clustering</a></li>
<li><a href="#vocabulary-building-2">Vocabulary building</a></li>
<li><a href="#cluster-characterization-2">Cluster characterization</a>
<ul>
<li><a href="#cluster-updating">Cluster updating</a></li>
</ul>
</li>
<li><a href="#cluster-merging-criterion">Cluster merging criterion</a></li>
<li><a href="#convergence-criterion-2">Convergence Criterion</a></li>
<li><a href="#adding-new-clusters">Adding New Clusters</a></li>
<li><a href="#linear-disciminant-analysis">Linear Disciminant Analysis</a></li>
<li><a href="#vocabulary-update-criterion">Vocabulary Update Criterion</a></li>
</ul>
</li>
<li><a href="#image-indexing-2">Image Indexing</a>
<ul>
<li><a href="#cluster-association-2">Cluster Association</a>
<ul>
<li><a href="#image-reindexing">Image Reindexing</a></li>
</ul>
</li>
<li><a href="#image-similarity-2">Image similarity</a></li>
</ul>
</li>
<li><a href="#increasing-vocabulary-efficiency">Increasing Vocabulary Efficiency</a></li>
<li><a href="#experiments">Experiments</a></li>
</ul>
</li>
<li><a href="#dbow-tro-pdf">DBoW (TRO) pdf</a>
<ul>
<li><a href="#introduction-3"><em>Introduction</em></a></li>
<li><a href="#image-database"><em>Image Database</em></a></li>
<li><a href="#loop-detection-algorithm"><em>Loop Detection Algorithm</em></a>
<ul>
<li><a href="#database-query">Database query</a></li>
<li><a href="#match-grouping">Match grouping</a></li>
<li><a href="#temporal-consistency">Temporal consistency</a></li>
<li><a href="#efficient-geometrical-consistency">Efficient geometrical consistency</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#fast-and-effective-visual-place-recognition-using-binary-codes-and-disparity-information-iros-2014-pdf">Fast and Effective Visual Place Recognition using Binary Codes and Disparity Information (IROS 2014) pdf</a>
<ul>
<li><a href="#abstract-3"><strong>Abstract</strong></a></li>
<li><a href="#introduction-4"><strong>Introduction</strong></a></li>
<li><a href="#binary-descriptor"><strong>Binary Descriptor</strong></a>
<ul>
<li><a href="#proposed-method"><strong>Proposed Method</strong></a>
<ul>
<li><a href="#binary-code-calculation"><strong>Binary code calculation</strong></a></li>
<li><a href="#binary-codes-matching"><strong>Binary codes matching</strong></a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><a href="#calc-pdf-code">CALC pdf code</a>
<ul>
<li><a href="#abstract-4"><em>Abstract</em></a></li>
<li><a href="#method"><em>Method</em></a></li>
<li><a href="#performance"><em>Performance</em></a></li>
<li><a href="#%E4%B8%80%E7%82%B9%E7%9C%8B%E6%B3%95">一点看法</a></li>
</ul>
</li>
</ul>

              </div>
            </div>
          </article>
        </div>

        
          <div class="next-post">
            <div class="next">下一篇</div>
            <a href="https://jinyu-m.github.io/post/fastap/">
              <h3 class="post-title">
                Loss Function
              </h3>
            </a>
          </div>
        

        
          
            <link rel="stylesheet" href="https://unpkg.com/gitalk/dist/gitalk.css">
<script src="https://unpkg.com/gitalk/dist/gitalk.min.js"></script>

<div id="gitalk-container"></div>

<script>

  var gitalk = new Gitalk({
    clientID: 'e0833a79ae313ee43ee5',
    clientSecret: 'b56f2b325b4ecd49f15ddec8d4795a0013debc77',
    repo: 'jinyu-m.github.io',
    owner: 'Jinyu-M',
    admin: ['Jinyu-M'],
    id: (location.pathname).substring(0, 49),      // Ensure uniqueness and length less than 50
    distractionFreeMode: false  // Facebook-like distraction free mode
  })

  gitalk.render('gitalk-container')

</script>

          

          
        

        <div class="site-footer">
  Powered by <a href="https://github.com/getgridea/gridea" target="_blank">Gridea</a>
  <a class="rss" href="https://jinyu-m.github.io/atom.xml" target="_blank">
    <i class="ri-rss-line"></i> RSS
  </a>
</div>

      </div>
    </div>

    <script>
      hljs.initHighlightingOnLoad()

      let mainNavLinks = document.querySelectorAll(".markdownIt-TOC a");

      // This should probably be throttled.
      // Especially because it triggers during smooth scrolling.
      // https://lodash.com/docs/4.17.10#throttle
      // You could do like...
      // window.addEventListener("scroll", () => {
      //    _.throttle(doThatStuff, 100);
      // });
      // Only not doing it here to keep this Pen dependency-free.

      window.addEventListener("scroll", event => {
        let fromTop = window.scrollY;

        mainNavLinks.forEach((link, index) => {
          let section = document.getElementById(decodeURI(link.hash).substring(1));
          let nextSection = null
          if (mainNavLinks[index + 1]) {
            nextSection = document.getElementById(decodeURI(mainNavLinks[index + 1].hash).substring(1));
          }
          if (section.offsetTop <= fromTop) {
            if (nextSection) {
              if (nextSection.offsetTop > fromTop) {
                link.classList.add("current");
              } else {
                link.classList.remove("current");    
              }
            } else {
              link.classList.add("current");
            }
          } else {
            link.classList.remove("current");
          }
        });
      });

    </script>
  </body>
</html>
